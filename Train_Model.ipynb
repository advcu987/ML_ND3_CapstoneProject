{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 151293 \n",
      "Validation size: 35876 \n",
      "Test size: 35659\n"
     ]
    }
   ],
   "source": [
    "# Source: \n",
    "# https://www.learnopencv.com/image-classification-using-transfer-learning-in-pytorch/\n",
    "\n",
    "# Applying Transforms to the Data\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "#         transforms.RandomRotation(degrees=15),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Set train and valid directory paths\n",
    "train_directory = '/home/advo/PycharmProjects/ML_ND3_CapstoneProject/Dataset_small/patches/train'\n",
    "valid_directory = '/home/advo/PycharmProjects/ML_ND3_CapstoneProject/Dataset_small/patches/valid'\n",
    "test_directory = '/home/advo/PycharmProjects/ML_ND3_CapstoneProject/Dataset_small/patches/test'\n",
    " \n",
    "# Batch size\n",
    "bs = 64\n",
    " \n",
    "# Number of classes\n",
    "num_classes = 2\n",
    " \n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    " \n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "test_data_size = len(data['test'])\n",
    " \n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data = torch.utils.data.DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data = torch.utils.data.DataLoader(data['valid'], batch_size=bs, shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(data['test'], batch_size=bs, shuffle=True)\n",
    " \n",
    "# Print the train, validation and test set data sizes\n",
    "print(f\"Train size: {train_data_size} \\nValidation size: {valid_data_size} \\nTest size: {test_data_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained AlexNet Model\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /home/advo/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "densenet = torchvision.models.densenet161(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model (alexnet/densenet)\n",
    "model = densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the parameters for the pretrained part\n",
    "# Source: https://pytorch.org/docs/master/notes/autograd.html\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: both models must be loaded, for this to work\n",
    "if model == densenet:\n",
    "    \n",
    "    # Update the classifier layer, in order to output the required number of classes specific to our problem\n",
    "    # Note: see model.eval() for details of each layer\n",
    "    model.classifier = nn.Linear(in_features=2208, out_features=num_classes, bias=True)\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Source: \n",
    "    # https://analyticsindiamag.com/implementing-alexnet-using-pytorch-as-a-transfer-learning-model-in-multi-class-classification/\n",
    "    # Updating the second classifier(reduce the number of outputs, to prevent overfitting)\n",
    "    alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "\n",
    "    # Updating the third and the last classifier that is the output layer of the network\n",
    "    # Binary classification , thus only 2 output nodes\n",
    "    alexnet.classifier[6] = nn.Linear(1024, num_classes)\n",
    "\n",
    "model_name = model.__class__.__name__\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function: Cross Entropy Loss\n",
    "\n",
    "Note: Improvement option by adding weight class check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: \n",
    "# https://github.com/choosehappy/PytorchDigitalPathology/blob/master/visualization_densenet/train_densenet.ipynb\n",
    "\n",
    "# we have the ability to weight individual classes, in this case we'll do so based on their presense in the trainingset\n",
    "# to avoid biasing any particular class\n",
    "# nclasses = dataset[\"train\"].classsizes.shape[0]\n",
    "# class_weight=dataset[\"train\"].classsizes\n",
    "# class_weight = torch.from_numpy(1-class_weight/class_weight.sum()).type('torch.FloatTensor').to(device)\n",
    "\n",
    "# print(class_weight) #show final used weights, make sure that they're reasonable before continouing\n",
    "\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(weight = class_weight)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: \n",
    "# https://github.com/choosehappy/PytorchDigitalPathology/blob/master/visualization_densenet/train_densenet.ipynb\n",
    "\n",
    "# adam is going to be the most robust, though perhaps not the best performing, typically a good place to start\n",
    "optimizer = optim.Adam(model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_data, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         output = alexnet(inputs)\n",
    "#         loss = criterion(output, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training of AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running on the following device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"You are running on the following device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print model and optimizer parameters before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "features.conv0.weight \t torch.Size([96, 3, 7, 7])\n",
      "features.norm0.weight \t torch.Size([96])\n",
      "features.norm0.bias \t torch.Size([96])\n",
      "features.norm0.running_mean \t torch.Size([96])\n",
      "features.norm0.running_var \t torch.Size([96])\n",
      "features.norm0.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer1.norm1.weight \t torch.Size([96])\n",
      "features.denseblock1.denselayer1.norm1.bias \t torch.Size([96])\n",
      "features.denseblock1.denselayer1.norm1.running_mean \t torch.Size([96])\n",
      "features.denseblock1.denselayer1.norm1.running_var \t torch.Size([96])\n",
      "features.denseblock1.denselayer1.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer1.conv1.weight \t torch.Size([192, 96, 1, 1])\n",
      "features.denseblock1.denselayer1.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer1.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer1.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer1.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer1.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer1.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock1.denselayer2.norm1.weight \t torch.Size([144])\n",
      "features.denseblock1.denselayer2.norm1.bias \t torch.Size([144])\n",
      "features.denseblock1.denselayer2.norm1.running_mean \t torch.Size([144])\n",
      "features.denseblock1.denselayer2.norm1.running_var \t torch.Size([144])\n",
      "features.denseblock1.denselayer2.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer2.conv1.weight \t torch.Size([192, 144, 1, 1])\n",
      "features.denseblock1.denselayer2.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer2.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer2.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer2.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer2.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer2.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock1.denselayer3.norm1.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm1.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm1.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm1.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer3.conv1.weight \t torch.Size([192, 192, 1, 1])\n",
      "features.denseblock1.denselayer3.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer3.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer3.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock1.denselayer4.norm1.weight \t torch.Size([240])\n",
      "features.denseblock1.denselayer4.norm1.bias \t torch.Size([240])\n",
      "features.denseblock1.denselayer4.norm1.running_mean \t torch.Size([240])\n",
      "features.denseblock1.denselayer4.norm1.running_var \t torch.Size([240])\n",
      "features.denseblock1.denselayer4.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer4.conv1.weight \t torch.Size([192, 240, 1, 1])\n",
      "features.denseblock1.denselayer4.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer4.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer4.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer4.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer4.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer4.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock1.denselayer5.norm1.weight \t torch.Size([288])\n",
      "features.denseblock1.denselayer5.norm1.bias \t torch.Size([288])\n",
      "features.denseblock1.denselayer5.norm1.running_mean \t torch.Size([288])\n",
      "features.denseblock1.denselayer5.norm1.running_var \t torch.Size([288])\n",
      "features.denseblock1.denselayer5.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer5.conv1.weight \t torch.Size([192, 288, 1, 1])\n",
      "features.denseblock1.denselayer5.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer5.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer5.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer5.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer5.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer5.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock1.denselayer6.norm1.weight \t torch.Size([336])\n",
      "features.denseblock1.denselayer6.norm1.bias \t torch.Size([336])\n",
      "features.denseblock1.denselayer6.norm1.running_mean \t torch.Size([336])\n",
      "features.denseblock1.denselayer6.norm1.running_var \t torch.Size([336])\n",
      "features.denseblock1.denselayer6.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer6.conv1.weight \t torch.Size([192, 336, 1, 1])\n",
      "features.denseblock1.denselayer6.norm2.weight \t torch.Size([192])\n",
      "features.denseblock1.denselayer6.norm2.bias \t torch.Size([192])\n",
      "features.denseblock1.denselayer6.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock1.denselayer6.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock1.denselayer6.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock1.denselayer6.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.transition1.norm.weight \t torch.Size([384])\n",
      "features.transition1.norm.bias \t torch.Size([384])\n",
      "features.transition1.norm.running_mean \t torch.Size([384])\n",
      "features.transition1.norm.running_var \t torch.Size([384])\n",
      "features.transition1.norm.num_batches_tracked \t torch.Size([])\n",
      "features.transition1.conv.weight \t torch.Size([192, 384, 1, 1])\n",
      "features.denseblock2.denselayer1.norm1.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm1.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm1.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm1.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer1.conv1.weight \t torch.Size([192, 192, 1, 1])\n",
      "features.denseblock2.denselayer1.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer1.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer1.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer2.norm1.weight \t torch.Size([240])\n",
      "features.denseblock2.denselayer2.norm1.bias \t torch.Size([240])\n",
      "features.denseblock2.denselayer2.norm1.running_mean \t torch.Size([240])\n",
      "features.denseblock2.denselayer2.norm1.running_var \t torch.Size([240])\n",
      "features.denseblock2.denselayer2.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer2.conv1.weight \t torch.Size([192, 240, 1, 1])\n",
      "features.denseblock2.denselayer2.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer2.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer2.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer2.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer2.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer2.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer3.norm1.weight \t torch.Size([288])\n",
      "features.denseblock2.denselayer3.norm1.bias \t torch.Size([288])\n",
      "features.denseblock2.denselayer3.norm1.running_mean \t torch.Size([288])\n",
      "features.denseblock2.denselayer3.norm1.running_var \t torch.Size([288])\n",
      "features.denseblock2.denselayer3.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer3.conv1.weight \t torch.Size([192, 288, 1, 1])\n",
      "features.denseblock2.denselayer3.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer3.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer3.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer3.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer3.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer3.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer4.norm1.weight \t torch.Size([336])\n",
      "features.denseblock2.denselayer4.norm1.bias \t torch.Size([336])\n",
      "features.denseblock2.denselayer4.norm1.running_mean \t torch.Size([336])\n",
      "features.denseblock2.denselayer4.norm1.running_var \t torch.Size([336])\n",
      "features.denseblock2.denselayer4.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer4.conv1.weight \t torch.Size([192, 336, 1, 1])\n",
      "features.denseblock2.denselayer4.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer4.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer4.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer4.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer4.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer4.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer5.norm1.weight \t torch.Size([384])\n",
      "features.denseblock2.denselayer5.norm1.bias \t torch.Size([384])\n",
      "features.denseblock2.denselayer5.norm1.running_mean \t torch.Size([384])\n",
      "features.denseblock2.denselayer5.norm1.running_var \t torch.Size([384])\n",
      "features.denseblock2.denselayer5.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer5.conv1.weight \t torch.Size([192, 384, 1, 1])\n",
      "features.denseblock2.denselayer5.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer5.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer5.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer5.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer5.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer5.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer6.norm1.weight \t torch.Size([432])\n",
      "features.denseblock2.denselayer6.norm1.bias \t torch.Size([432])\n",
      "features.denseblock2.denselayer6.norm1.running_mean \t torch.Size([432])\n",
      "features.denseblock2.denselayer6.norm1.running_var \t torch.Size([432])\n",
      "features.denseblock2.denselayer6.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer6.conv1.weight \t torch.Size([192, 432, 1, 1])\n",
      "features.denseblock2.denselayer6.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer6.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer6.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer6.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer6.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer6.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer7.norm1.weight \t torch.Size([480])\n",
      "features.denseblock2.denselayer7.norm1.bias \t torch.Size([480])\n",
      "features.denseblock2.denselayer7.norm1.running_mean \t torch.Size([480])\n",
      "features.denseblock2.denselayer7.norm1.running_var \t torch.Size([480])\n",
      "features.denseblock2.denselayer7.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer7.conv1.weight \t torch.Size([192, 480, 1, 1])\n",
      "features.denseblock2.denselayer7.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer7.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer7.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer7.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer7.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer7.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer8.norm1.weight \t torch.Size([528])\n",
      "features.denseblock2.denselayer8.norm1.bias \t torch.Size([528])\n",
      "features.denseblock2.denselayer8.norm1.running_mean \t torch.Size([528])\n",
      "features.denseblock2.denselayer8.norm1.running_var \t torch.Size([528])\n",
      "features.denseblock2.denselayer8.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer8.conv1.weight \t torch.Size([192, 528, 1, 1])\n",
      "features.denseblock2.denselayer8.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer8.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer8.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer8.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer8.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer8.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer9.norm1.weight \t torch.Size([576])\n",
      "features.denseblock2.denselayer9.norm1.bias \t torch.Size([576])\n",
      "features.denseblock2.denselayer9.norm1.running_mean \t torch.Size([576])\n",
      "features.denseblock2.denselayer9.norm1.running_var \t torch.Size([576])\n",
      "features.denseblock2.denselayer9.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer9.conv1.weight \t torch.Size([192, 576, 1, 1])\n",
      "features.denseblock2.denselayer9.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer9.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer9.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer9.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer9.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer9.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer10.norm1.weight \t torch.Size([624])\n",
      "features.denseblock2.denselayer10.norm1.bias \t torch.Size([624])\n",
      "features.denseblock2.denselayer10.norm1.running_mean \t torch.Size([624])\n",
      "features.denseblock2.denselayer10.norm1.running_var \t torch.Size([624])\n",
      "features.denseblock2.denselayer10.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer10.conv1.weight \t torch.Size([192, 624, 1, 1])\n",
      "features.denseblock2.denselayer10.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer10.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer10.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer10.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer10.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer10.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer11.norm1.weight \t torch.Size([672])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.denseblock2.denselayer11.norm1.bias \t torch.Size([672])\n",
      "features.denseblock2.denselayer11.norm1.running_mean \t torch.Size([672])\n",
      "features.denseblock2.denselayer11.norm1.running_var \t torch.Size([672])\n",
      "features.denseblock2.denselayer11.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer11.conv1.weight \t torch.Size([192, 672, 1, 1])\n",
      "features.denseblock2.denselayer11.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer11.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer11.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer11.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer11.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer11.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock2.denselayer12.norm1.weight \t torch.Size([720])\n",
      "features.denseblock2.denselayer12.norm1.bias \t torch.Size([720])\n",
      "features.denseblock2.denselayer12.norm1.running_mean \t torch.Size([720])\n",
      "features.denseblock2.denselayer12.norm1.running_var \t torch.Size([720])\n",
      "features.denseblock2.denselayer12.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer12.conv1.weight \t torch.Size([192, 720, 1, 1])\n",
      "features.denseblock2.denselayer12.norm2.weight \t torch.Size([192])\n",
      "features.denseblock2.denselayer12.norm2.bias \t torch.Size([192])\n",
      "features.denseblock2.denselayer12.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock2.denselayer12.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock2.denselayer12.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock2.denselayer12.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.transition2.norm.weight \t torch.Size([768])\n",
      "features.transition2.norm.bias \t torch.Size([768])\n",
      "features.transition2.norm.running_mean \t torch.Size([768])\n",
      "features.transition2.norm.running_var \t torch.Size([768])\n",
      "features.transition2.norm.num_batches_tracked \t torch.Size([])\n",
      "features.transition2.conv.weight \t torch.Size([384, 768, 1, 1])\n",
      "features.denseblock3.denselayer1.norm1.weight \t torch.Size([384])\n",
      "features.denseblock3.denselayer1.norm1.bias \t torch.Size([384])\n",
      "features.denseblock3.denselayer1.norm1.running_mean \t torch.Size([384])\n",
      "features.denseblock3.denselayer1.norm1.running_var \t torch.Size([384])\n",
      "features.denseblock3.denselayer1.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer1.conv1.weight \t torch.Size([192, 384, 1, 1])\n",
      "features.denseblock3.denselayer1.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer1.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer1.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer1.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer1.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer1.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer2.norm1.weight \t torch.Size([432])\n",
      "features.denseblock3.denselayer2.norm1.bias \t torch.Size([432])\n",
      "features.denseblock3.denselayer2.norm1.running_mean \t torch.Size([432])\n",
      "features.denseblock3.denselayer2.norm1.running_var \t torch.Size([432])\n",
      "features.denseblock3.denselayer2.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer2.conv1.weight \t torch.Size([192, 432, 1, 1])\n",
      "features.denseblock3.denselayer2.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer2.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer2.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer2.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer2.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer2.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer3.norm1.weight \t torch.Size([480])\n",
      "features.denseblock3.denselayer3.norm1.bias \t torch.Size([480])\n",
      "features.denseblock3.denselayer3.norm1.running_mean \t torch.Size([480])\n",
      "features.denseblock3.denselayer3.norm1.running_var \t torch.Size([480])\n",
      "features.denseblock3.denselayer3.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer3.conv1.weight \t torch.Size([192, 480, 1, 1])\n",
      "features.denseblock3.denselayer3.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer3.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer3.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer3.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer3.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer3.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer4.norm1.weight \t torch.Size([528])\n",
      "features.denseblock3.denselayer4.norm1.bias \t torch.Size([528])\n",
      "features.denseblock3.denselayer4.norm1.running_mean \t torch.Size([528])\n",
      "features.denseblock3.denselayer4.norm1.running_var \t torch.Size([528])\n",
      "features.denseblock3.denselayer4.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer4.conv1.weight \t torch.Size([192, 528, 1, 1])\n",
      "features.denseblock3.denselayer4.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer4.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer4.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer4.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer4.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer4.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer5.norm1.weight \t torch.Size([576])\n",
      "features.denseblock3.denselayer5.norm1.bias \t torch.Size([576])\n",
      "features.denseblock3.denselayer5.norm1.running_mean \t torch.Size([576])\n",
      "features.denseblock3.denselayer5.norm1.running_var \t torch.Size([576])\n",
      "features.denseblock3.denselayer5.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer5.conv1.weight \t torch.Size([192, 576, 1, 1])\n",
      "features.denseblock3.denselayer5.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer5.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer5.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer5.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer5.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer5.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer6.norm1.weight \t torch.Size([624])\n",
      "features.denseblock3.denselayer6.norm1.bias \t torch.Size([624])\n",
      "features.denseblock3.denselayer6.norm1.running_mean \t torch.Size([624])\n",
      "features.denseblock3.denselayer6.norm1.running_var \t torch.Size([624])\n",
      "features.denseblock3.denselayer6.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer6.conv1.weight \t torch.Size([192, 624, 1, 1])\n",
      "features.denseblock3.denselayer6.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer6.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer6.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer6.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer6.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer6.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer7.norm1.weight \t torch.Size([672])\n",
      "features.denseblock3.denselayer7.norm1.bias \t torch.Size([672])\n",
      "features.denseblock3.denselayer7.norm1.running_mean \t torch.Size([672])\n",
      "features.denseblock3.denselayer7.norm1.running_var \t torch.Size([672])\n",
      "features.denseblock3.denselayer7.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer7.conv1.weight \t torch.Size([192, 672, 1, 1])\n",
      "features.denseblock3.denselayer7.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer7.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer7.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer7.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer7.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer7.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer8.norm1.weight \t torch.Size([720])\n",
      "features.denseblock3.denselayer8.norm1.bias \t torch.Size([720])\n",
      "features.denseblock3.denselayer8.norm1.running_mean \t torch.Size([720])\n",
      "features.denseblock3.denselayer8.norm1.running_var \t torch.Size([720])\n",
      "features.denseblock3.denselayer8.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer8.conv1.weight \t torch.Size([192, 720, 1, 1])\n",
      "features.denseblock3.denselayer8.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer8.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer8.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer8.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer8.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer8.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer9.norm1.weight \t torch.Size([768])\n",
      "features.denseblock3.denselayer9.norm1.bias \t torch.Size([768])\n",
      "features.denseblock3.denselayer9.norm1.running_mean \t torch.Size([768])\n",
      "features.denseblock3.denselayer9.norm1.running_var \t torch.Size([768])\n",
      "features.denseblock3.denselayer9.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer9.conv1.weight \t torch.Size([192, 768, 1, 1])\n",
      "features.denseblock3.denselayer9.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer9.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer9.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer9.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer9.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer9.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer10.norm1.weight \t torch.Size([816])\n",
      "features.denseblock3.denselayer10.norm1.bias \t torch.Size([816])\n",
      "features.denseblock3.denselayer10.norm1.running_mean \t torch.Size([816])\n",
      "features.denseblock3.denselayer10.norm1.running_var \t torch.Size([816])\n",
      "features.denseblock3.denselayer10.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer10.conv1.weight \t torch.Size([192, 816, 1, 1])\n",
      "features.denseblock3.denselayer10.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer10.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer10.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer10.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer10.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer10.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer11.norm1.weight \t torch.Size([864])\n",
      "features.denseblock3.denselayer11.norm1.bias \t torch.Size([864])\n",
      "features.denseblock3.denselayer11.norm1.running_mean \t torch.Size([864])\n",
      "features.denseblock3.denselayer11.norm1.running_var \t torch.Size([864])\n",
      "features.denseblock3.denselayer11.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer11.conv1.weight \t torch.Size([192, 864, 1, 1])\n",
      "features.denseblock3.denselayer11.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer11.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer11.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer11.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer11.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer11.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer12.norm1.weight \t torch.Size([912])\n",
      "features.denseblock3.denselayer12.norm1.bias \t torch.Size([912])\n",
      "features.denseblock3.denselayer12.norm1.running_mean \t torch.Size([912])\n",
      "features.denseblock3.denselayer12.norm1.running_var \t torch.Size([912])\n",
      "features.denseblock3.denselayer12.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer12.conv1.weight \t torch.Size([192, 912, 1, 1])\n",
      "features.denseblock3.denselayer12.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer12.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer12.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer12.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer12.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer12.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer13.norm1.weight \t torch.Size([960])\n",
      "features.denseblock3.denselayer13.norm1.bias \t torch.Size([960])\n",
      "features.denseblock3.denselayer13.norm1.running_mean \t torch.Size([960])\n",
      "features.denseblock3.denselayer13.norm1.running_var \t torch.Size([960])\n",
      "features.denseblock3.denselayer13.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer13.conv1.weight \t torch.Size([192, 960, 1, 1])\n",
      "features.denseblock3.denselayer13.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer13.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer13.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer13.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer13.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer13.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer14.norm1.weight \t torch.Size([1008])\n",
      "features.denseblock3.denselayer14.norm1.bias \t torch.Size([1008])\n",
      "features.denseblock3.denselayer14.norm1.running_mean \t torch.Size([1008])\n",
      "features.denseblock3.denselayer14.norm1.running_var \t torch.Size([1008])\n",
      "features.denseblock3.denselayer14.norm1.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.denseblock3.denselayer14.conv1.weight \t torch.Size([192, 1008, 1, 1])\n",
      "features.denseblock3.denselayer14.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer14.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer14.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer14.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer14.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer14.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer15.norm1.weight \t torch.Size([1056])\n",
      "features.denseblock3.denselayer15.norm1.bias \t torch.Size([1056])\n",
      "features.denseblock3.denselayer15.norm1.running_mean \t torch.Size([1056])\n",
      "features.denseblock3.denselayer15.norm1.running_var \t torch.Size([1056])\n",
      "features.denseblock3.denselayer15.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer15.conv1.weight \t torch.Size([192, 1056, 1, 1])\n",
      "features.denseblock3.denselayer15.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer15.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer15.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer15.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer15.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer15.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer16.norm1.weight \t torch.Size([1104])\n",
      "features.denseblock3.denselayer16.norm1.bias \t torch.Size([1104])\n",
      "features.denseblock3.denselayer16.norm1.running_mean \t torch.Size([1104])\n",
      "features.denseblock3.denselayer16.norm1.running_var \t torch.Size([1104])\n",
      "features.denseblock3.denselayer16.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer16.conv1.weight \t torch.Size([192, 1104, 1, 1])\n",
      "features.denseblock3.denselayer16.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer16.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer16.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer16.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer16.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer16.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer17.norm1.weight \t torch.Size([1152])\n",
      "features.denseblock3.denselayer17.norm1.bias \t torch.Size([1152])\n",
      "features.denseblock3.denselayer17.norm1.running_mean \t torch.Size([1152])\n",
      "features.denseblock3.denselayer17.norm1.running_var \t torch.Size([1152])\n",
      "features.denseblock3.denselayer17.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer17.conv1.weight \t torch.Size([192, 1152, 1, 1])\n",
      "features.denseblock3.denselayer17.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer17.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer17.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer17.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer17.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer17.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer18.norm1.weight \t torch.Size([1200])\n",
      "features.denseblock3.denselayer18.norm1.bias \t torch.Size([1200])\n",
      "features.denseblock3.denselayer18.norm1.running_mean \t torch.Size([1200])\n",
      "features.denseblock3.denselayer18.norm1.running_var \t torch.Size([1200])\n",
      "features.denseblock3.denselayer18.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer18.conv1.weight \t torch.Size([192, 1200, 1, 1])\n",
      "features.denseblock3.denselayer18.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer18.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer18.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer18.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer18.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer18.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer19.norm1.weight \t torch.Size([1248])\n",
      "features.denseblock3.denselayer19.norm1.bias \t torch.Size([1248])\n",
      "features.denseblock3.denselayer19.norm1.running_mean \t torch.Size([1248])\n",
      "features.denseblock3.denselayer19.norm1.running_var \t torch.Size([1248])\n",
      "features.denseblock3.denselayer19.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer19.conv1.weight \t torch.Size([192, 1248, 1, 1])\n",
      "features.denseblock3.denselayer19.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer19.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer19.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer19.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer19.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer19.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer20.norm1.weight \t torch.Size([1296])\n",
      "features.denseblock3.denselayer20.norm1.bias \t torch.Size([1296])\n",
      "features.denseblock3.denselayer20.norm1.running_mean \t torch.Size([1296])\n",
      "features.denseblock3.denselayer20.norm1.running_var \t torch.Size([1296])\n",
      "features.denseblock3.denselayer20.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer20.conv1.weight \t torch.Size([192, 1296, 1, 1])\n",
      "features.denseblock3.denselayer20.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer20.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer20.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer20.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer20.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer20.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer21.norm1.weight \t torch.Size([1344])\n",
      "features.denseblock3.denselayer21.norm1.bias \t torch.Size([1344])\n",
      "features.denseblock3.denselayer21.norm1.running_mean \t torch.Size([1344])\n",
      "features.denseblock3.denselayer21.norm1.running_var \t torch.Size([1344])\n",
      "features.denseblock3.denselayer21.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer21.conv1.weight \t torch.Size([192, 1344, 1, 1])\n",
      "features.denseblock3.denselayer21.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer21.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer21.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer21.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer21.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer21.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer22.norm1.weight \t torch.Size([1392])\n",
      "features.denseblock3.denselayer22.norm1.bias \t torch.Size([1392])\n",
      "features.denseblock3.denselayer22.norm1.running_mean \t torch.Size([1392])\n",
      "features.denseblock3.denselayer22.norm1.running_var \t torch.Size([1392])\n",
      "features.denseblock3.denselayer22.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer22.conv1.weight \t torch.Size([192, 1392, 1, 1])\n",
      "features.denseblock3.denselayer22.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer22.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer22.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer22.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer22.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer22.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer23.norm1.weight \t torch.Size([1440])\n",
      "features.denseblock3.denselayer23.norm1.bias \t torch.Size([1440])\n",
      "features.denseblock3.denselayer23.norm1.running_mean \t torch.Size([1440])\n",
      "features.denseblock3.denselayer23.norm1.running_var \t torch.Size([1440])\n",
      "features.denseblock3.denselayer23.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer23.conv1.weight \t torch.Size([192, 1440, 1, 1])\n",
      "features.denseblock3.denselayer23.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer23.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer23.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer23.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer23.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer23.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer24.norm1.weight \t torch.Size([1488])\n",
      "features.denseblock3.denselayer24.norm1.bias \t torch.Size([1488])\n",
      "features.denseblock3.denselayer24.norm1.running_mean \t torch.Size([1488])\n",
      "features.denseblock3.denselayer24.norm1.running_var \t torch.Size([1488])\n",
      "features.denseblock3.denselayer24.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer24.conv1.weight \t torch.Size([192, 1488, 1, 1])\n",
      "features.denseblock3.denselayer24.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer24.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer24.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer24.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer24.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer24.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer25.norm1.weight \t torch.Size([1536])\n",
      "features.denseblock3.denselayer25.norm1.bias \t torch.Size([1536])\n",
      "features.denseblock3.denselayer25.norm1.running_mean \t torch.Size([1536])\n",
      "features.denseblock3.denselayer25.norm1.running_var \t torch.Size([1536])\n",
      "features.denseblock3.denselayer25.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer25.conv1.weight \t torch.Size([192, 1536, 1, 1])\n",
      "features.denseblock3.denselayer25.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer25.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer25.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer25.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer25.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer25.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer26.norm1.weight \t torch.Size([1584])\n",
      "features.denseblock3.denselayer26.norm1.bias \t torch.Size([1584])\n",
      "features.denseblock3.denselayer26.norm1.running_mean \t torch.Size([1584])\n",
      "features.denseblock3.denselayer26.norm1.running_var \t torch.Size([1584])\n",
      "features.denseblock3.denselayer26.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer26.conv1.weight \t torch.Size([192, 1584, 1, 1])\n",
      "features.denseblock3.denselayer26.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer26.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer26.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer26.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer26.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer26.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer27.norm1.weight \t torch.Size([1632])\n",
      "features.denseblock3.denselayer27.norm1.bias \t torch.Size([1632])\n",
      "features.denseblock3.denselayer27.norm1.running_mean \t torch.Size([1632])\n",
      "features.denseblock3.denselayer27.norm1.running_var \t torch.Size([1632])\n",
      "features.denseblock3.denselayer27.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer27.conv1.weight \t torch.Size([192, 1632, 1, 1])\n",
      "features.denseblock3.denselayer27.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer27.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer27.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer27.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer27.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer27.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer28.norm1.weight \t torch.Size([1680])\n",
      "features.denseblock3.denselayer28.norm1.bias \t torch.Size([1680])\n",
      "features.denseblock3.denselayer28.norm1.running_mean \t torch.Size([1680])\n",
      "features.denseblock3.denselayer28.norm1.running_var \t torch.Size([1680])\n",
      "features.denseblock3.denselayer28.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer28.conv1.weight \t torch.Size([192, 1680, 1, 1])\n",
      "features.denseblock3.denselayer28.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer28.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer28.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer28.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer28.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer28.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer29.norm1.weight \t torch.Size([1728])\n",
      "features.denseblock3.denselayer29.norm1.bias \t torch.Size([1728])\n",
      "features.denseblock3.denselayer29.norm1.running_mean \t torch.Size([1728])\n",
      "features.denseblock3.denselayer29.norm1.running_var \t torch.Size([1728])\n",
      "features.denseblock3.denselayer29.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer29.conv1.weight \t torch.Size([192, 1728, 1, 1])\n",
      "features.denseblock3.denselayer29.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer29.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer29.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer29.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer29.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer29.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer30.norm1.weight \t torch.Size([1776])\n",
      "features.denseblock3.denselayer30.norm1.bias \t torch.Size([1776])\n",
      "features.denseblock3.denselayer30.norm1.running_mean \t torch.Size([1776])\n",
      "features.denseblock3.denselayer30.norm1.running_var \t torch.Size([1776])\n",
      "features.denseblock3.denselayer30.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer30.conv1.weight \t torch.Size([192, 1776, 1, 1])\n",
      "features.denseblock3.denselayer30.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer30.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer30.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer30.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer30.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer30.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer31.norm1.weight \t torch.Size([1824])\n",
      "features.denseblock3.denselayer31.norm1.bias \t torch.Size([1824])\n",
      "features.denseblock3.denselayer31.norm1.running_mean \t torch.Size([1824])\n",
      "features.denseblock3.denselayer31.norm1.running_var \t torch.Size([1824])\n",
      "features.denseblock3.denselayer31.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer31.conv1.weight \t torch.Size([192, 1824, 1, 1])\n",
      "features.denseblock3.denselayer31.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer31.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer31.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer31.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer31.norm2.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.denseblock3.denselayer31.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer32.norm1.weight \t torch.Size([1872])\n",
      "features.denseblock3.denselayer32.norm1.bias \t torch.Size([1872])\n",
      "features.denseblock3.denselayer32.norm1.running_mean \t torch.Size([1872])\n",
      "features.denseblock3.denselayer32.norm1.running_var \t torch.Size([1872])\n",
      "features.denseblock3.denselayer32.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer32.conv1.weight \t torch.Size([192, 1872, 1, 1])\n",
      "features.denseblock3.denselayer32.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer32.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer32.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer32.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer32.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer32.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer33.norm1.weight \t torch.Size([1920])\n",
      "features.denseblock3.denselayer33.norm1.bias \t torch.Size([1920])\n",
      "features.denseblock3.denselayer33.norm1.running_mean \t torch.Size([1920])\n",
      "features.denseblock3.denselayer33.norm1.running_var \t torch.Size([1920])\n",
      "features.denseblock3.denselayer33.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer33.conv1.weight \t torch.Size([192, 1920, 1, 1])\n",
      "features.denseblock3.denselayer33.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer33.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer33.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer33.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer33.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer33.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer34.norm1.weight \t torch.Size([1968])\n",
      "features.denseblock3.denselayer34.norm1.bias \t torch.Size([1968])\n",
      "features.denseblock3.denselayer34.norm1.running_mean \t torch.Size([1968])\n",
      "features.denseblock3.denselayer34.norm1.running_var \t torch.Size([1968])\n",
      "features.denseblock3.denselayer34.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer34.conv1.weight \t torch.Size([192, 1968, 1, 1])\n",
      "features.denseblock3.denselayer34.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer34.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer34.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer34.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer34.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer34.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer35.norm1.weight \t torch.Size([2016])\n",
      "features.denseblock3.denselayer35.norm1.bias \t torch.Size([2016])\n",
      "features.denseblock3.denselayer35.norm1.running_mean \t torch.Size([2016])\n",
      "features.denseblock3.denselayer35.norm1.running_var \t torch.Size([2016])\n",
      "features.denseblock3.denselayer35.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer35.conv1.weight \t torch.Size([192, 2016, 1, 1])\n",
      "features.denseblock3.denselayer35.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer35.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer35.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer35.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer35.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer35.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock3.denselayer36.norm1.weight \t torch.Size([2064])\n",
      "features.denseblock3.denselayer36.norm1.bias \t torch.Size([2064])\n",
      "features.denseblock3.denselayer36.norm1.running_mean \t torch.Size([2064])\n",
      "features.denseblock3.denselayer36.norm1.running_var \t torch.Size([2064])\n",
      "features.denseblock3.denselayer36.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer36.conv1.weight \t torch.Size([192, 2064, 1, 1])\n",
      "features.denseblock3.denselayer36.norm2.weight \t torch.Size([192])\n",
      "features.denseblock3.denselayer36.norm2.bias \t torch.Size([192])\n",
      "features.denseblock3.denselayer36.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock3.denselayer36.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock3.denselayer36.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock3.denselayer36.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.transition3.norm.weight \t torch.Size([2112])\n",
      "features.transition3.norm.bias \t torch.Size([2112])\n",
      "features.transition3.norm.running_mean \t torch.Size([2112])\n",
      "features.transition3.norm.running_var \t torch.Size([2112])\n",
      "features.transition3.norm.num_batches_tracked \t torch.Size([])\n",
      "features.transition3.conv.weight \t torch.Size([1056, 2112, 1, 1])\n",
      "features.denseblock4.denselayer1.norm1.weight \t torch.Size([1056])\n",
      "features.denseblock4.denselayer1.norm1.bias \t torch.Size([1056])\n",
      "features.denseblock4.denselayer1.norm1.running_mean \t torch.Size([1056])\n",
      "features.denseblock4.denselayer1.norm1.running_var \t torch.Size([1056])\n",
      "features.denseblock4.denselayer1.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer1.conv1.weight \t torch.Size([192, 1056, 1, 1])\n",
      "features.denseblock4.denselayer1.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer1.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer1.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer1.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer1.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer1.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer2.norm1.weight \t torch.Size([1104])\n",
      "features.denseblock4.denselayer2.norm1.bias \t torch.Size([1104])\n",
      "features.denseblock4.denselayer2.norm1.running_mean \t torch.Size([1104])\n",
      "features.denseblock4.denselayer2.norm1.running_var \t torch.Size([1104])\n",
      "features.denseblock4.denselayer2.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer2.conv1.weight \t torch.Size([192, 1104, 1, 1])\n",
      "features.denseblock4.denselayer2.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer2.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer2.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer2.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer2.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer2.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer3.norm1.weight \t torch.Size([1152])\n",
      "features.denseblock4.denselayer3.norm1.bias \t torch.Size([1152])\n",
      "features.denseblock4.denselayer3.norm1.running_mean \t torch.Size([1152])\n",
      "features.denseblock4.denselayer3.norm1.running_var \t torch.Size([1152])\n",
      "features.denseblock4.denselayer3.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer3.conv1.weight \t torch.Size([192, 1152, 1, 1])\n",
      "features.denseblock4.denselayer3.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer3.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer3.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer3.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer3.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer3.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer4.norm1.weight \t torch.Size([1200])\n",
      "features.denseblock4.denselayer4.norm1.bias \t torch.Size([1200])\n",
      "features.denseblock4.denselayer4.norm1.running_mean \t torch.Size([1200])\n",
      "features.denseblock4.denselayer4.norm1.running_var \t torch.Size([1200])\n",
      "features.denseblock4.denselayer4.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer4.conv1.weight \t torch.Size([192, 1200, 1, 1])\n",
      "features.denseblock4.denselayer4.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer4.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer4.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer4.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer4.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer4.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer5.norm1.weight \t torch.Size([1248])\n",
      "features.denseblock4.denselayer5.norm1.bias \t torch.Size([1248])\n",
      "features.denseblock4.denselayer5.norm1.running_mean \t torch.Size([1248])\n",
      "features.denseblock4.denselayer5.norm1.running_var \t torch.Size([1248])\n",
      "features.denseblock4.denselayer5.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer5.conv1.weight \t torch.Size([192, 1248, 1, 1])\n",
      "features.denseblock4.denselayer5.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer5.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer5.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer5.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer5.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer5.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer6.norm1.weight \t torch.Size([1296])\n",
      "features.denseblock4.denselayer6.norm1.bias \t torch.Size([1296])\n",
      "features.denseblock4.denselayer6.norm1.running_mean \t torch.Size([1296])\n",
      "features.denseblock4.denselayer6.norm1.running_var \t torch.Size([1296])\n",
      "features.denseblock4.denselayer6.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer6.conv1.weight \t torch.Size([192, 1296, 1, 1])\n",
      "features.denseblock4.denselayer6.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer6.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer6.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer6.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer6.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer6.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer7.norm1.weight \t torch.Size([1344])\n",
      "features.denseblock4.denselayer7.norm1.bias \t torch.Size([1344])\n",
      "features.denseblock4.denselayer7.norm1.running_mean \t torch.Size([1344])\n",
      "features.denseblock4.denselayer7.norm1.running_var \t torch.Size([1344])\n",
      "features.denseblock4.denselayer7.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer7.conv1.weight \t torch.Size([192, 1344, 1, 1])\n",
      "features.denseblock4.denselayer7.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer7.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer7.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer7.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer7.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer7.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer8.norm1.weight \t torch.Size([1392])\n",
      "features.denseblock4.denselayer8.norm1.bias \t torch.Size([1392])\n",
      "features.denseblock4.denselayer8.norm1.running_mean \t torch.Size([1392])\n",
      "features.denseblock4.denselayer8.norm1.running_var \t torch.Size([1392])\n",
      "features.denseblock4.denselayer8.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer8.conv1.weight \t torch.Size([192, 1392, 1, 1])\n",
      "features.denseblock4.denselayer8.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer8.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer8.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer8.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer8.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer8.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer9.norm1.weight \t torch.Size([1440])\n",
      "features.denseblock4.denselayer9.norm1.bias \t torch.Size([1440])\n",
      "features.denseblock4.denselayer9.norm1.running_mean \t torch.Size([1440])\n",
      "features.denseblock4.denselayer9.norm1.running_var \t torch.Size([1440])\n",
      "features.denseblock4.denselayer9.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer9.conv1.weight \t torch.Size([192, 1440, 1, 1])\n",
      "features.denseblock4.denselayer9.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer9.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer9.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer9.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer9.norm2.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.denseblock4.denselayer9.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer10.norm1.weight \t torch.Size([1488])\n",
      "features.denseblock4.denselayer10.norm1.bias \t torch.Size([1488])\n",
      "features.denseblock4.denselayer10.norm1.running_mean \t torch.Size([1488])\n",
      "features.denseblock4.denselayer10.norm1.running_var \t torch.Size([1488])\n",
      "features.denseblock4.denselayer10.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer10.conv1.weight \t torch.Size([192, 1488, 1, 1])\n",
      "features.denseblock4.denselayer10.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer10.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer10.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer10.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer10.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer10.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer11.norm1.weight \t torch.Size([1536])\n",
      "features.denseblock4.denselayer11.norm1.bias \t torch.Size([1536])\n",
      "features.denseblock4.denselayer11.norm1.running_mean \t torch.Size([1536])\n",
      "features.denseblock4.denselayer11.norm1.running_var \t torch.Size([1536])\n",
      "features.denseblock4.denselayer11.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer11.conv1.weight \t torch.Size([192, 1536, 1, 1])\n",
      "features.denseblock4.denselayer11.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer11.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer11.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer11.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer11.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer11.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer12.norm1.weight \t torch.Size([1584])\n",
      "features.denseblock4.denselayer12.norm1.bias \t torch.Size([1584])\n",
      "features.denseblock4.denselayer12.norm1.running_mean \t torch.Size([1584])\n",
      "features.denseblock4.denselayer12.norm1.running_var \t torch.Size([1584])\n",
      "features.denseblock4.denselayer12.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer12.conv1.weight \t torch.Size([192, 1584, 1, 1])\n",
      "features.denseblock4.denselayer12.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer12.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer12.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer12.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer12.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer12.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer13.norm1.weight \t torch.Size([1632])\n",
      "features.denseblock4.denselayer13.norm1.bias \t torch.Size([1632])\n",
      "features.denseblock4.denselayer13.norm1.running_mean \t torch.Size([1632])\n",
      "features.denseblock4.denselayer13.norm1.running_var \t torch.Size([1632])\n",
      "features.denseblock4.denselayer13.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer13.conv1.weight \t torch.Size([192, 1632, 1, 1])\n",
      "features.denseblock4.denselayer13.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer13.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer13.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer13.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer13.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer13.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer14.norm1.weight \t torch.Size([1680])\n",
      "features.denseblock4.denselayer14.norm1.bias \t torch.Size([1680])\n",
      "features.denseblock4.denselayer14.norm1.running_mean \t torch.Size([1680])\n",
      "features.denseblock4.denselayer14.norm1.running_var \t torch.Size([1680])\n",
      "features.denseblock4.denselayer14.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer14.conv1.weight \t torch.Size([192, 1680, 1, 1])\n",
      "features.denseblock4.denselayer14.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer14.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer14.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer14.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer14.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer14.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer15.norm1.weight \t torch.Size([1728])\n",
      "features.denseblock4.denselayer15.norm1.bias \t torch.Size([1728])\n",
      "features.denseblock4.denselayer15.norm1.running_mean \t torch.Size([1728])\n",
      "features.denseblock4.denselayer15.norm1.running_var \t torch.Size([1728])\n",
      "features.denseblock4.denselayer15.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer15.conv1.weight \t torch.Size([192, 1728, 1, 1])\n",
      "features.denseblock4.denselayer15.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer15.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer15.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer15.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer15.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer15.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer16.norm1.weight \t torch.Size([1776])\n",
      "features.denseblock4.denselayer16.norm1.bias \t torch.Size([1776])\n",
      "features.denseblock4.denselayer16.norm1.running_mean \t torch.Size([1776])\n",
      "features.denseblock4.denselayer16.norm1.running_var \t torch.Size([1776])\n",
      "features.denseblock4.denselayer16.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer16.conv1.weight \t torch.Size([192, 1776, 1, 1])\n",
      "features.denseblock4.denselayer16.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer16.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer16.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer16.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer16.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer16.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer17.norm1.weight \t torch.Size([1824])\n",
      "features.denseblock4.denselayer17.norm1.bias \t torch.Size([1824])\n",
      "features.denseblock4.denselayer17.norm1.running_mean \t torch.Size([1824])\n",
      "features.denseblock4.denselayer17.norm1.running_var \t torch.Size([1824])\n",
      "features.denseblock4.denselayer17.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer17.conv1.weight \t torch.Size([192, 1824, 1, 1])\n",
      "features.denseblock4.denselayer17.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer17.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer17.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer17.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer17.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer17.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer18.norm1.weight \t torch.Size([1872])\n",
      "features.denseblock4.denselayer18.norm1.bias \t torch.Size([1872])\n",
      "features.denseblock4.denselayer18.norm1.running_mean \t torch.Size([1872])\n",
      "features.denseblock4.denselayer18.norm1.running_var \t torch.Size([1872])\n",
      "features.denseblock4.denselayer18.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer18.conv1.weight \t torch.Size([192, 1872, 1, 1])\n",
      "features.denseblock4.denselayer18.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer18.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer18.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer18.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer18.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer18.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer19.norm1.weight \t torch.Size([1920])\n",
      "features.denseblock4.denselayer19.norm1.bias \t torch.Size([1920])\n",
      "features.denseblock4.denselayer19.norm1.running_mean \t torch.Size([1920])\n",
      "features.denseblock4.denselayer19.norm1.running_var \t torch.Size([1920])\n",
      "features.denseblock4.denselayer19.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer19.conv1.weight \t torch.Size([192, 1920, 1, 1])\n",
      "features.denseblock4.denselayer19.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer19.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer19.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer19.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer19.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer19.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer20.norm1.weight \t torch.Size([1968])\n",
      "features.denseblock4.denselayer20.norm1.bias \t torch.Size([1968])\n",
      "features.denseblock4.denselayer20.norm1.running_mean \t torch.Size([1968])\n",
      "features.denseblock4.denselayer20.norm1.running_var \t torch.Size([1968])\n",
      "features.denseblock4.denselayer20.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer20.conv1.weight \t torch.Size([192, 1968, 1, 1])\n",
      "features.denseblock4.denselayer20.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer20.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer20.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer20.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer20.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer20.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer21.norm1.weight \t torch.Size([2016])\n",
      "features.denseblock4.denselayer21.norm1.bias \t torch.Size([2016])\n",
      "features.denseblock4.denselayer21.norm1.running_mean \t torch.Size([2016])\n",
      "features.denseblock4.denselayer21.norm1.running_var \t torch.Size([2016])\n",
      "features.denseblock4.denselayer21.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer21.conv1.weight \t torch.Size([192, 2016, 1, 1])\n",
      "features.denseblock4.denselayer21.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer21.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer21.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer21.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer21.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer21.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer22.norm1.weight \t torch.Size([2064])\n",
      "features.denseblock4.denselayer22.norm1.bias \t torch.Size([2064])\n",
      "features.denseblock4.denselayer22.norm1.running_mean \t torch.Size([2064])\n",
      "features.denseblock4.denselayer22.norm1.running_var \t torch.Size([2064])\n",
      "features.denseblock4.denselayer22.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer22.conv1.weight \t torch.Size([192, 2064, 1, 1])\n",
      "features.denseblock4.denselayer22.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer22.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer22.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer22.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer22.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer22.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer23.norm1.weight \t torch.Size([2112])\n",
      "features.denseblock4.denselayer23.norm1.bias \t torch.Size([2112])\n",
      "features.denseblock4.denselayer23.norm1.running_mean \t torch.Size([2112])\n",
      "features.denseblock4.denselayer23.norm1.running_var \t torch.Size([2112])\n",
      "features.denseblock4.denselayer23.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer23.conv1.weight \t torch.Size([192, 2112, 1, 1])\n",
      "features.denseblock4.denselayer23.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer23.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer23.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer23.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer23.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer23.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.denseblock4.denselayer24.norm1.weight \t torch.Size([2160])\n",
      "features.denseblock4.denselayer24.norm1.bias \t torch.Size([2160])\n",
      "features.denseblock4.denselayer24.norm1.running_mean \t torch.Size([2160])\n",
      "features.denseblock4.denselayer24.norm1.running_var \t torch.Size([2160])\n",
      "features.denseblock4.denselayer24.norm1.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer24.conv1.weight \t torch.Size([192, 2160, 1, 1])\n",
      "features.denseblock4.denselayer24.norm2.weight \t torch.Size([192])\n",
      "features.denseblock4.denselayer24.norm2.bias \t torch.Size([192])\n",
      "features.denseblock4.denselayer24.norm2.running_mean \t torch.Size([192])\n",
      "features.denseblock4.denselayer24.norm2.running_var \t torch.Size([192])\n",
      "features.denseblock4.denselayer24.norm2.num_batches_tracked \t torch.Size([])\n",
      "features.denseblock4.denselayer24.conv2.weight \t torch.Size([48, 192, 3, 3])\n",
      "features.norm5.weight \t torch.Size([2208])\n",
      "features.norm5.bias \t torch.Size([2208])\n",
      "features.norm5.running_mean \t torch.Size([2208])\n",
      "features.norm5.running_var \t torch.Size([2208])\n",
      "features.norm5.num_batches_tracked \t torch.Size([])\n",
      "classifier.weight \t torch.Size([2, 2208])\n",
      "classifier.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DenseNet\n",
      "Epoch : 000 \n",
      "Training: Loss: 0.6767, Accuracy: 57.2769%, \n",
      "Validation : Loss : 5.6540, Accuracy: 35.4053%, \n",
      " Time (train+val): 31074.5262s\n",
      "  **\n",
      "Saved model DenseNet with loss 5.654006976881399\n"
     ]
    }
   ],
   "source": [
    "# history = []\n",
    "# # Initialize the variable storing accuracy and loss (with max/min values)\n",
    "# history.append([1.0, 1.0, 0.0, 0.0])\n",
    "# best_loss_on_val = np.Infinity\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "#     print(\"Epoch: {}/{}\".format(epoch, epochs))\n",
    "     \n",
    "    # Set to training mode\n",
    "    model.train()\n",
    "     \n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    " \n",
    "    # Iterate through all batches of training data\n",
    "    for i, (inputs, labels) in enumerate(train_data):\n",
    " \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "         \n",
    "        # Clean existing gradients\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "#         print(\"predictions\")\n",
    "#         print(outputs)\n",
    "         \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "         \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "         \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "         \n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "         \n",
    "        # Compute the accuracy\n",
    "        ret, predictions = torch.max(outputs.data, 1)\n",
    "#         print(\"ret\")\n",
    "#         print(ret)\n",
    "#         print(\"predictions\")\n",
    "#         print(predictions)\n",
    "\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "#         print(\"correct counts\")\n",
    "#         print(correct_counts)\n",
    "         \n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "#         print(\"acc\")\n",
    "#         print(acc)\n",
    "         \n",
    "        # Compute total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "         \n",
    "#         print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "        # Break \"train_data batch\" for loop\n",
    "#         break\n",
    "    \n",
    "        \n",
    "\n",
    "    # Validation is carried out in each epoch immediately after the training loop\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Set to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        # Iterate through all batches of validation data\n",
    "        for j, (inputs, labels) in enumerate(valid_data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "\n",
    "#             print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "            # Break \"valid_data batch\" for loop\n",
    "#             break\n",
    "\n",
    "    # Find average training loss and training accuracy\n",
    "    avg_train_loss = train_loss/train_data_size\n",
    "    avg_train_acc = train_acc/float(train_data_size)\n",
    "\n",
    "    # Find average training loss and training accuracy\n",
    "    avg_valid_loss = valid_loss/valid_data_size\n",
    "    avg_valid_acc = valid_acc/float(valid_data_size)\n",
    "\n",
    "    history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "    epoch_end = time.time()\n",
    "\n",
    "    print(f\"Model: {model_name} \\n\")\n",
    "    print(\"Epoch : {:03d} \\nTraining: Loss: {:.4f}, Accuracy: {:.4f}%, \\nValidation : Loss : {:.4f}, Accuracy: {:.4f}%, \\nTime (train+val): {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "\n",
    "    \n",
    "    # Source: https://github.com/choosehappy/PytorchDigitalPathology/blob/master/classification_lymphoma_densenet/train_densenet.ipynb\n",
    "    # If current loss is the best we've seen, save model state with all variables\n",
    "    # necessary for recreation\n",
    "    if avg_valid_loss < best_loss_on_val:\n",
    "        best_loss_on_val = avg_valid_loss\n",
    "        print(\"  **\")\n",
    "        state = {'epoch': epoch + 1,\n",
    "         'model_dict': model.state_dict(),\n",
    "         'optim_dict': optimizer.state_dict(),\n",
    "         'best_loss_on_val': best_loss_on_val}\n",
    "\n",
    "        torch.save(state, f\"outputs/{model_name}_best_model.pth\")\n",
    "        print(f\"Saved model {model_name} with loss {avg_valid_loss}\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "    \n",
    "    # Stop \"epoch\" for\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: DenseNet\n",
    "Epoch : 000 \n",
    "Training: Loss: 0.6769, Accuracy: 57.1705%, \n",
    "Validation : Loss : 5.7904, Accuracy: 35.1516%, \n",
    " Time (train+val): 33245.9189s\n",
    "  **\n",
    "Saved model DenseNet with loss 5.790416442187604\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the accuracy and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAGsCAYAAABti4tLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABdZ0lEQVR4nO3deVxU9f4/8Ncs7MM2M8omigzjLm64YZkIlakZyli31dLu7Zt2rbwtYiqpWZR2Wy1bvFZWv0wwU8sWKvOWG6RYKiqbioIig4rsDHN+f3Sd21xc0Jj5DHNez8ejh87MGc7r7RC+PKtCkiQJRERERORylKIDEBEREdGFsagRERERuSgWNSIiIiIXxaJGRERE5KJY1IiIiIhcFIsaERERkYtSiw7gKKWlpQ5fh16vR0VFhcPX44rkPDsg7/k5uzxnB+Q9v5xnB+Q9vzNmDw8Pv+hr3KJGRERE5KJY1IiIiIhcFIsaERERkYty22PUiIiIRJMkCfX19bBarVAoFKLjXLWTJ0+ioaFBdAwh2mp2SZKgVCrh7e19Rd8LLGpEREQOUl9fDw8PD6jV7fuvW7VaDZVKJTqGEG05u8ViQX19PXx8fFr9Hu76JCIichCr1druSxq1HbVaDavVekXvYVEjIiJykPa8u5Mc40q/J1jUiIiIiFwUixoRERHZGI1GAMCJEyfw17/+9YLLmEwm7Nmz55Jf55133kFdXZ3t8d13342zZ8+2XVCZYFEjIiKiFkJDQ/HOO+9c9fvfffddu6K2atUqBAYGtkU0p5Ak6YqPJ3MEFjUiIiI39eyzz+K9996zPX7xxRexfPly1NTU4NZbb8WNN96IxMREfP311y3eW1JSgtGjRwMA6urq8OCDD+K6667DtGnTUF9fb1tu9uzZuOmmm5CQkIClS5cCAFasWIGTJ09i8uTJMJlMAIChQ4eisrISAPDWW29h9OjRGD16tK0MlpSU4LrrrsPjjz+OhIQE3H777XZF77xvvvkG48ePxw033IDbbrsNp06dAgDU1NTg0UcfRWJiIpKSkvDFF18AAH744QfceOONSEpKwq233mr353De6NGjUVJSgpKSElx77bWYOXMmRo8ejdLSUjzxxBMt5gOA3NxcTJgwAUlJSRg3bhyqq6sxadIk7N2717ZMcnIy9u3b19qP64J4KgoREZETzN82H/vN+9v0a/bS9cLC4Qsv+vqECROQlpaGe++9FwCwYcMGfPTRR/Dy8sKKFSvg7++PyspK3HzzzbjhhhsueqD7+++/Dx8fH/z444/Yv38/xowZY3vtySefRHBwMJqbm3Hbbbdh//79mDZtGt5++22sWbMGWq3W7mv9+uuv+PTTT7Fx40ZIkoTx48dj+PDhCAwMRHFxMZYtW4YlS5bggQcewJdffomUlBS79w8ZMgQbNmyAQqHAxx9/jDfeeANpaWl4+eWX4e/vj++++w4AcObMGZjNZjz++ONYu3YtOnfujNOnT1/2z7S4uBgvv/wyBg0aBABITU2Fv7+/3XwxMTF48MEH8eabb6J///44d+4cvL298Ze//AWffvop+vTpg8LCQjQ0NKB3796XXeelsKgRERG5qT59+qCiogInTpyA2WxGYGAgIiIi0NTUhPT0dOzYsQMKhQInTpzAqVOn0LFjxwt+nW3btuG+++4DAPTq1Qs9e/a0vXa+/DU3N+PkyZPIz89Hr169Lppp586dGDNmDHx9fQEAN910E3bs2IEbbrgBkZGR6NOnDwAgNjYWJSUlLd5fVlaGBx98EOXl5WhsbETnzp0BAP/+97/xxhtv2JYLCgrCN998g2HDhtmWCQ4OvuyfWadOnWwlDQDWr1+PDz74wG4+hUKBjh07on///gAAf39/AMDNN9+MV155BfPmzcPq1attW/D+DBY1IiIiJ7jUli9HGj9+PL744guUl5djwoQJAIC1a9fCbDZj06ZN8PDwwNChQ6/q6vtHjx7FW2+9hS+++AJBQUF45JFH7HaLXikvLy/b71Uq1QW/1rx58/C3v/0NN9xwA7Zu3Yp//vOfV7welUpld/zZH2c/XyCB3+d74403Wj2fj48Prr32Wnz99dfYsGEDNm3adMXZ/hePUSO6Aucaz+FI1RFIkiQ6ChFRq0yYMAGff/45vvjiC4wfPx4AcO7cOej1enh4eODnn3/GsWPHLvk1hg8fjnXr1gEADhw4gLy8PNvX8fHxQUBAAE6dOoUffvjB9h6NRoPq6uoWX2vo0KH4+uuvUVdXh9raWnz11VcYOnRoq+epqqpCaGgoAGDNmjW250eOHGl3PN6ZM2cwaNAgbN++HUePHgUA267PyMhI/PbbbwCA3377zfb6/zp37hx8fX1bzGcwGFBeXo7c3FwAQHV1NSwWCwDgjjvuwPz589GvXz8EBQW1eq6L4RY1ov+ot9SjrKYMpTWlOF59HKXVpSitKf39uf/8vqqxCgDw1ti3MD5ivODERESX1717d9TU1CA0NBQhISEAgEmTJmHKlClITExEbGwsYmJiLvk1pkyZgpkzZ+K6666D0WhEbGwsAKB3797o06cPRo4cifDwcAwePNj2njvvvBN33nknQkJCkJGRYXu+b9++mDx5MsaNGwcAuP3229GnT58L7ua8kH/84x944IEHEBgYiBEjRtje9/DDD2POnDkYPXo0lEolZs2ahbFjx+KFF17A/fffD6vVCr1ej08++QRjx45FRkYGEhISMGDAAERHR19wXb1790bfvn1bzOfp6Yk333wTc+fORX19Pby9vbF69Wqo1WrExsZCo9Hgtttua9U8l6OQ3HTTQGlpqcPXodfrUVFR4fD1uKL2NrvFasHJ2pO2wlVa/Z8yVvPfx+Z6c4v36bx1CNeEI9wvHBGaCIT7hePDAx8izD8MGWMzLrAm99fePvu2JOfZAXnPf7Wz19bW2u1Ka6/UarVti5HcXOnsJ06cgMlkwpYtW6BUttxxeaHvifDw8Iuvv/VR/5zc3FysXLkSVqsViYmJSE5ObrHM1q1bsWbNGigUCnTp0gUPP/wwDh8+bLtonlKpxKRJkxAfH++s2NQOWCUrKuoqbIXrQkWsvLYcVsn+ejgBngEI9wtHuCYcsfpYWxE7X8zC/MLgrfa+4PqezX4WxWeL0TWwq7PGJCIiF7dmzRo8//zzSEtLu2BJuxpOKWpWqxUrVqzA3LlzodPpkJqairi4OHTq1Mm2TFlZGdatW4dFixZBo9HYrl7s6emJhx56CGFhYaisrMTs2bPRr18/+Pn5OSM6CSZJEs40nLEvYed//5/HJ2pOoNHaaPc+b5W3rXCNjBhpK2ARfhG25zWemqvKNDFmIp7Lfg5rC9biH4P+0RZjEhGRG5g8eTImT57cpl/TKUWtoKDAbt94fHw8srOz7Yrad999hxtvvBEaze9/eZ6/evEfNwdqtVoEBgaiqqqKRc1N1DTV2G0Fu1Ahq7XU2r1HrVAjzC8M4ZpwDOo4yFa8/vhrsFeww26GHK4JR0JUAjLyMzBr4CzedJmILspNjy6iP+FKvyecUtQqKyuh0+lsj3U6HfLz8+2WOX9M2bx582C1WjF58mTb9UnOKygogMVisRW+P8rKykJWVhYAID09HXq9vo2naEmtVjtlPa6oNbM3WBpw/NxxHDt3DCVnS37/taoEx6qO4di5YzhWdQyn6+0vPqiAAqGaUEQGRCI2NBZj/ceiU0AnRAZEopN/J3QK6IQQvxColCpHjndZd8fejfvW34dD9YcwInKE0CzOxu97ec4OyHv+q51doVDAarXCw8PDAamcS62W7/mHbTV7U1MTNBqNXSe67LrbZM1twGq1oqysDGlpaaisrERaWhqWLl1q23J2+vRpvPbaa5gxY8YF9/smJSUhKSnJ9tgZB7zK+cDaYG0w9h3dd+EtYf/59VTdqZbv8wq2bfkapB/UYktYiG8IPFWeF19xA3C64fJXlna0CcYJ8FH7YEXOCnT36S46jlPJ+ftezrMD8p7/ameXJAn19fWora1t11vfvby8ruo6a+6grWaXJAlKpRLe3t4tvpeEn0yg1WphNv/3jDqz2dzilhJarRZGoxFqtRodO3ZEWFgYysrKEBMTg9raWqSnp+P2229Ht27dnBFZ1iRJgrnefMFdkecvW3Gy9iSapWa792k8NLbC1VvX+/cCdr6E/ed5H7WPoKnalsZTg7FRY7GhaAMWDF/gNnMRUdtSKBTw8Wn/Px9Y0sXN7pSiZjAYUFZWhvLycmi1WmzduhUzZ860W2bIkCH46aefkJCQgKqqKpSVlSEkJAQWiwVLly7FyJEjMWzYMGfEdXtVjVV21wn731/LasrQ0Gz/rwcvldfvx4X5hSM+PB4xHWIQpAz672UrNOEI8AwQNJEYpm4mZBZk4tsj32KCYYLoOERE5IacUtRUKhWmTp2KxYsXw2q1IiEhAZGRkVi9ejUMBgPi4uLQr18/7NmzB48++iiUSiXuuusu+Pv7Y8uWLcjLy8O5c+ewefNmAMCMGTMQFRXljOjtTp2l7vdLU9QcR1l12QWLWHWT/ZWiVQoVQnxDEKGJQL8O/XBT1E0tdknqvHV2m+1F/wvDFYwIG4FQv1BkFmSyqBERkUPwgrd/grPLSpO1CSdqTtgKl+06YX8oYhc6fquDT4f/Fq//2RUZ7vf7cWFXenC+3Iva+fmf3fkslv+6HLvu3AW9jzwOspbzZy/n2QF5zy/n2QF5z++M2YUfo0aXZ5WsKK8tb3nR1j9sGSuvLYcE+14d5BVk2yU5sOPAFhdtDfULhZfK6yJrpT8rJSYFy/Ysw7rCdbi/z/2i4xARkZthUXMCSZJwuuH0BY8JO79V7ETNCVgk+1tU+Kp9bYUrITjB/lZGmt+vnO/nwevJidRd2x199X2RkZ/BokZERG2ORa0NnGs81/Kq+f/za31zvd17PJWetou2DgkdYrdL8nwRC/QMbNenc8uFyWhC2rY0HKg8gB7aHqLjEBGRG2FRuwqSJOG+b+5DaV0pSs6WoKqxyu51pUKJjr4dEeEXgd663ri+8/Utrp6v99FDqWib+4CRWMmGZCzcvhCZ+Zl4auhTouMQEZEbYVG7CgqFAharBdFB0RjacegFL9qqVvKPVi70PnokRCZgbcFazB48W/hdE4iIyH2wTVylD2/6UNZnwZA9k9GErKNZ+LnsZ4yMGCk6DhERuQnueyNqA9d3vh4BngHIOJQhOgoREbkRFjWiNuCt9sbN0Tfjy8NfoqapRnQcIiJyEyxqRG3EZDShzlKHL4u/FB2FiIjcBIsaURsZHDIYnf07IyOfuz+JiKhtsKgRtRGFQgGT0YSfS39GabXjb2FGRETuj0WNqA2lGFMgQcJnBZ+JjkJERG6ARY2oDUUFRGFwyGBk5GdAkqTLv4GIiOgSWNSI2pjJaMKhM4fwW8VvoqMQEVE7x6JG1MbGR4+Hp9KTJxUQEdGfxqJG1MaCvIJwfZfr8VnhZ2iyNomOQ0RE7RiLGpEDmIwmVNZX4oeSH0RHISKidoxFjcgBEiIToPXWcvcnERH9KSxqRA7gofTARMNEZB3NwpmGM6LjEBFRO8WiRuQgJqMJDc0N2Fi0UXQUIiJqp1jUiBykr74vugV14+5PIiK6aixqRA6iUCiQYkxB9slsHK46LDoOERG1QyxqRA40MWYiFFAgMz9TdBQiImqHWNSIHChCE4ER4SN4SykiIroqLGpEDmYymnD03FFkn8wWHYWIiNoZFjUiBxvbdSx81D48qYCIiK4YixqRg/l5+GFs1FhsKNqAeku96DhERNSOsKgROYGpmwlVjVX49ui3oqMQEVE7wqJG5AQjwkYg1DeUuz+JiOiKsKgROYFKqcKkmEn4oeQHVNRViI5DRETtBIsakZOkGFPQLDVjXeE60VGIiKidYFEjcpIe2h7oq+/Li98SEVGrsagROZHJaMKvFb/iYOVB0VGIiKgdYFEjcqJkQzJUChUyC7hVjYiILo9FjciJ9D56JEQmILMgE83WZtFxiIjIxamdtaLc3FysXLkSVqsViYmJSE5ObrHM1q1bsWbNGigUCnTp0gUPP/wwAGDz5s1Yu3YtAGDSpEkYNWqUs2ITtbmUmBRkHc3Cz2U/Y2TESNFxiIjIhTmlqFmtVqxYsQJz586FTqdDamoq4uLi0KlTJ9syZWVlWLduHRYtWgSNRoOzZ88CAKqrq5GRkYH09HQAwOzZsxEXFweNRuOM6ERt7vou1yPAMwAZhzJY1IiI6JKcsuuzoKAAoaGhCAkJgVqtRnx8PLKz7W9Q/d133+HGG2+0FbDAwEAAv2+Ji42NhUajgUajQWxsLHJzc50Rm8ghfNQ+uDn6Znx5+EvUNNWIjkNERC7MKVvUKisrodPpbI91Oh3y8/PtliktLQUAzJs3D1arFZMnT0b//v1bvFer1aKysrLFOrKyspCVlQUASE9Ph16vd8QodtRqtVPW44rkPDvw5+efFjcNHx34CD9V/IQ7+97ZhskcT86fvZxnB+Q9v5xnB+Q9v+jZnXaM2uVYrVaUlZUhLS0NlZWVSEtLw9KlS1v9/qSkJCQlJdkeV1Q4/urver3eKetxRXKeHfjz83fz7obO/p2xcvdK3Bh2Yxsmczw5f/Zynh2Q9/xynh2Q9/zOmD08PPyirzll16dWq4XZbLY9NpvN0Gq1LZaJi4uDWq1Gx44dERYWhrKyshbvraysbPFeovZGoVDAZDThp+M/obS6VHQcIiJyUU4pagaDAWVlZSgvL4fFYsHWrVsRFxdnt8yQIUOwb98+AEBVVRXKysoQEhKC/v37Y8+ePaiurkZ1dTX27NmD/v37OyM2kUNNipkECRI+K/hMdBQiInJRTtn1qVKpMHXqVCxevBhWqxUJCQmIjIzE6tWrYTAYEBcXh379+mHPnj149NFHoVQqcdddd8Hf3x8AkJKSgtTUVACAyWTiGZ/kFroGdkVcSBwy8jMwvd90KBQK0ZGIiMjFKCRJkkSHcITzJyc4EvfZy3N2oO3mX5W3CrN/mo1NyZsQ2yG2DZI5npw/eznPDsh7fjnPDsh7flkco0ZEF3Zz9M3wVHoioyBDdBQiInJBLGpEAgV5BeH6LtdjXcE6NFmbRMchIiIXw6JGJJjJaIK53ozNJZtFRyEiIhfDokYkWEJkArTeWmTkc/cnERHZY1EjEsxD6YFkQzK+PfotzjScER2HiIhcCIsakQswGU1oaG7AxqKNoqMQEZELYVEjcgGx+lgYg4zc/UlERHZY1IhcwPlbSmWfzMbhqsOi4xARkYtgUSNyERNjJkIBBdbmrxUdhYiIXASLGpGLiNBEYET4CGTkZ8BNbxhCRERXiEWNyIWYjCYcOXcEOSdzREchIiIXwKJG5ELGdh0LH7UP1uSvER2FiIhcAIsakQvx8/DDTVE3YUPRBtRb6kXHISIiwVjUiFzMZONkVDVW4duj34qOQkREgrGoEbmYEeEjEOobisz8TNFRiIhIMBY1IhejUqowKWYSfij5ARV1FaLjEBGRQCxqRC4oxZgCi2TB54Wfi45CREQCsagRuaAe2h7oq+/LW0oREckcixqRi0qJScGvFb/iYOVB0VGIiEgQFjUiF5VsSIZKoUJmAU8qICKSKxY1IhfVwbcDRnUahbUFa9FsbRYdh4iIBGBRI3JhJqMJZTVl2Fq2VXQUIiISgEWNyIVd3+V6BHgG8KQCIiKZYlEjcmE+ah/cHH0zviz+EjVNNaLjEBGRk7GoEbm4lJgU1FpqsenwJtFRiIjIyVjUiFzc4NDB6Ozfmbs/iYhkiEWNyMUpFUqkGFPw0/GfUFpdKjoOERE5EYsaUTuQEpMCCRLWFa4THYWIiJyIRY2oHega2BVxIXFYc2gNJEkSHYeIiJyERY2onTAZTTh05hD2mveKjkJERE7CokbUTtwcfTM8lZ5Yk79GdBQiInISFjWidiLIKwhJXZKwrmAdmqxNouMQEZETsKgRtSOTjZNhrjdjc8lm0VGIiMgJWNSI2pFRnUZB661FZkGm6ChEROQELGpE7YinyhPJhmR8c+QbnG04KzoOERE5mNpZK8rNzcXKlSthtVqRmJiI5ORku9c3b96MVatWQavVAgDGjBmDxMREAMCHH36IXbt2QZIk9O3bF/fddx8UCoWzohO5FJPRhH/t+xc2Fm/EnT3uFB2HiIgcyClFzWq1YsWKFZg7dy50Oh1SU1MRFxeHTp062S0XHx+PadOm2T138OBBHDx4EEuXLgUAzJs3D/v370fv3r2dEZ3I5cTqY2EMMiLjUAaLGhGRm3PKrs+CggKEhoYiJCQEarUa8fHxyM7ObtV7FQoFGhsbYbFY0NTUhObmZgQGBjo4MZHrUigUMBlN2HlyJw5XHRYdh4iIHMgpW9QqKyuh0+lsj3U6HfLz81sst2PHDuTl5SEsLAxTpkyBXq9Ht27d0Lt3b/ztb3+DJEkYM2ZMiy1xAJCVlYWsrCwAQHp6OvR6veMG+g+1Wu2U9bgiOc8OiJ9/2pBpSM9Ox1fHv8Lc6LlOXbfo2UWS8+yAvOeX8+yAvOcXPbvTjlG7nEGDBmHEiBHw8PDAt99+i2XLliEtLQ0nTpzA8ePHsXz5cgDAokWLkJeXh549e9q9PykpCUlJSbbHFRUVDs+s1+udsh5XJOfZAfHz+8AH8eHxWPXrKjzQ4wGnHrMpenaR5Dw7IO/55Tw7IO/5nTF7eHj4RV9zyq5PrVYLs9lse2w2m20nDZzn7+8PDw8PAEBiYiKKiooAADt37oTRaIS3tze8vb0xYMAAHDp0yBmxiVyayWjC4arDyCnPER2FiIgcxClFzWAwoKysDOXl5bBYLNi6dSvi4uLsljl9+rTt9zk5Obbdm3q9Hnl5eWhubobFYsH+/fsRERHhjNhELm1s1Fj4qH2QcShDdBQiInIQp+z6VKlUmDp1KhYvXgyr1YqEhARERkZi9erVMBgMiIuLw6ZNm5CTkwOVSgWNRoPp06cDAIYNG4a9e/fiscceAwD079+/RckjkiONpwY3Rd2EDUUbsGD4AnirvUVHIiKiNqaQJEkSHcIRSktLHb4O7rOX5+yA68y/5dgW3L7pdryV+BbGR493yjpdZXYR5Dw7IO/55Tw7IO/5ZXGMGhE5xojwEQj1DUVGPnd/EhG5IxY1onZMpVRhYsxE/FDyAyrq5PmvXSIid8aiRtTOmYwmWCQLPi/8XHQUIiJqYy5zHTUiujo9tD3QR9cHmfmZmNZn2uXfQEREFyRJEk43nEbh2UIUnS1C0dkiBPoFYnqv6cIysagRuQGT0YSntz+NQ6cPoVtwN9FxiIhcWk1TDYrPFtsVsuKzxSiuKsaZhjO25dQKNYZ3Gs6iRkR/TrIhGYt2LEJmfiZSh6SKjkNEJFxDcwOOVh1FcVWxrYyd/+9k7Um7ZSM0EYgOjMYthlsQHRiN6MBodA3oikj/SIR2DBV6xiuLGpEb6ODbAaM6jUJmQSaeiHsCKqVKdCQiIodrtjajtKbUbqvY+d+XVJfAKllty+q8dYgOjMaoTqNsZSw6MBpdArrAR+0jcIpLY1EjchMpxhR89/132Fq2FddGXCs6DhFRm5AkCRV1FS22ihVXFeNw1WE0NDfYltV4aBAdGI3+HftjknGS3daxQK9AgVNcPRY1IjdxQ5cb4O/hj4z8DBY1Imp3qhqr7LaI/fG/6qZq23KeSk9EBUQhOjAaoyNH220d6+DTAQqFQuAUbY9FjchN+Kh9cHP0zVhXuA7PjXgOvh6+oiMREdmps9ThSNWRFrspi6qK7K4FqYACkf6RiA6MRlxIHLoGdLWVsQhNhKwO72BRI3IjJqMJHx/8GJsOb0KKMUV0HCKSIYvVgmPVx+x3U/6nlB2vPg4J/71zZUefjogOjMYNnW/4fRdl4O+FrLN/Z96/+D9Y1IjcyODQwejs3xkZ+RksakTkMJIk4WTtyQvupjx67iiarE22ZQM8AxAdGI0hoUPsdlNGBUTB39Nf4BTtA4sakRtRKpRIMabg5V0vo6ymDGF+YaIjEVE7drr+NIrOFqGirAJ7ju+x20JWa6m1Leet8kZUQBS6B3fHTVE32RUyrbfW7Y4bcyYWNSI3kxKTgpd2vYTPCj7D9H7iLtJIRO1DbVOt7Vpj/3sw/+mG07blVAqV7bixYWHDbEXMEGhAmF8YlAreldIRWNSI3EzXwK4Y1HEQ1hxagwdjH+S/ZIkITdYmHK062uLyFkVni1BWU2a3bKhfKKIDojGu6zjbMWODogbB3+IPT5WnoAnki0WNyA2ZjCak/pyKvea96KvvKzoOETmBVbKirKbsgseNlZwrQbPUbFs2yCsI0YHRGBE+wnadseig33/18/Br8bX1Or3Qq/PLGYsakRu6OfpmpG1LQ0Z+BosakRuRJAmV9ZW2S1rY3afybDHqm+tty/qofdA1oCv66PpgQvSE/178NbArtN5agVPQlWBRI3JDwd7BSOqShHWF6zB36Fx4KD1ERyKiK1DdWN3iHpXnjx8723jWtpxaoUbngM6IDozGtRHX2h3EH+obykMf3ACLGpGbmmycjC+Lv8SPx35EUuck0XGI6H+cv2n4hW6N1JqbhkcHRiPSPxJqJf8qd2f8dInc1KhOo6D11iIjP4NFjUiQZmszjlcfb7F1rOhsEY5VH7voTcPPH8R//npjrnzTcHIsFjUiN+Wp8kSyIRkfHfgIZxvOttsbEhO5OkmScKruVItdlEVni3C46jAarY22Zf08/BAdGI0BHQcgxZhiuzVS18CuCPIKEjcEuSwWNSI3lmJMwb/2/Qsbizfizh53io5D1K6dbTh70ePG/njTcA+lh+2m4YmdE+1ujdTRpyOPG6MrwqJG5Mb66fshJigGmfmZLGpEV+nrw18j9eNUnKz573FjCijQSdMJ0YHRmGycbHfcmNxuGk6OxaJG5MYUCgVMRhPSs9NxpOoIugR0ER2JqF2paarB7J9mQ+urxf2977eVMd40nJyF93sgcnOTYiZBAQXWFqwVHYWo3Vm2ZxnK68rx1ti3ML3fdIyJGoNuwd1Y0shpWNSI3FyEJgLx4fHIyM+AJEmi4xC1G8erj+OtX9/CLYZbMKzTMNFxSKZY1IhkwGQ04XDVYeSU54iOQtRupGenQ4KEOYPniI5CMsaiRiQDY6PGwkftg4xDGaKjELULu8t3Y23BWvy171/Ryb+T6DgkYyxqRDKg8dTgpqibsKFoA+ot9Zd/A5GMSZKEBdsXQO+jx0P9HhIdh2SORY1IJkxGE842nsV3Jd+JjkLk0jYWb0T2yWw8EfcE/D39RcchmWNRI5KJa8KvQYhvCDLyufuT6GLqLfVYvGMxemp74i/d/iI6DhGLGpFcqJQqTIqZhO+Pfg9znVl0HCKX9K99/0JJdQnmD5vPi9aSS2BRI5IRk9EEi2TB54Wfi45C5HIq6irwyu5XkBiZiJERI0XHIQLAokYkKz20PdBH14e7P4kuYOkvS1FnqcP8YfNFRyGyYVEjkpkUYwr2VOzBodOHREchchkHKg/gowMf4Z6e9yAmKEZ0HCIbp93rMzc3FytXroTVakViYiKSk5PtXt+8eTNWrVoFrVYLABgzZgwSExMBABUVFVi+fDnM5t+Pq0lNTUXHjh2dFZ3IrSQbkvHMjmeQmZ+J1CGpouMQuYRFOxbB38MfswbNEh2FyI5TiprVasWKFSswd+5c6HQ6pKamIi4uDp062V9EMD4+HtOmTWvx/tdffx2TJk1CbGws6uvroVAonBGbyC119O2I6zpdh8yCTDw5+EkoFdywTvL2fcn32HxsM9KGpUHrrRUdh8iOU35CFxQUIDQ0FCEhIVCr1YiPj0d2dnar3nvs2DE0NzcjNjYWAODt7Q0vLy9HxiVyeyajCWU1ZdhaulV0FCKhmqxNWLh9IaIConBvr3tFxyFqwSlb1CorK6HT6WyPdTod8vPzWyy3Y8cO5OXlISwsDFOmTIFer0dpaSn8/PywdOlSlJeXo2/fvrjzzjuhVNp3zKysLGRlZQEA0tPTodfrHTsUALVa7ZT1uCI5zw60//nvCLwDs3+ejY0lG5HcL/mK3tveZ/8z5Dw74J7zL/9lOfLP5OPTlE8RHhJ+0eXccfYrIef5Rc/utGPULmfQoEEYMWIEPDw88O2332LZsmVIS0uD1WpFXl4eXnjhBej1erz00kvYvHkzRo8ebff+pKQkJCUl2R5XVFQ4PLNer3fKelyRnGcH3GP+8VHjkZmXifmD5sPXw7fV73OH2a+WnGcH3G/+sw1n8fSPT2N42HDEB8dfcjZ3m/1KyXl+Z8weHn7xfyQ4ZdenVqu1nQgAAGaz2XbSwHn+/v7w8PAAACQmJqKoqMj23qioKISEhEClUmHIkCG214jo6pmMJtRaarHp8CbRUYiEeDX3VZxpOIO0YWk89plcllOKmsFgQFlZGcrLy2GxWLB161bExcXZLXP69Gnb73NycmwnGsTExKC2thZVVVUAgL1797Y4CYGIrtzg0MGI1ETymmokS4erDmPF3hWY3G0y+ur7io5DdFFO2fWpUqkwdepULF68GFarFQkJCYiMjMTq1athMBgQFxeHTZs2IScnByqVChqNBtOnTwcAKJVK3H333Vi4cCEkSUJ0dLTdLk4iujpKhRIpxhS8mvsqymrKEOYXJjoSkdMs3rkYaqUaT8Y9KToK0SUpJEmSRIdwhNLSUoevg/vs5Tk74D7zF50twrWfXou5Q+biwX4Ptuo97jL71ZDz7ID7zL+9bDtSNqbgsUGP4dGBj7bqPe4y+9WS8/yyOEaNiFxTdGA0BnUchDX5a+Cm/2YjsmOVrFiwfQFC/ULxf7H/JzoO0WWxqBHJnMlowsHTB7HPvE90FCKHy8zPxK8VvyJ1cCp81D6i4xBdFosakczdHH0zPJWeWJO/RnQUIoeqbapFek46+un7YVLMJNFxiFqFRY1I5oK9g5HUJQnrCtehydokOg6Rwyz/dTlO1JxA2rA03jqN2g1+pxIRTDEmVNRV4MdjP4qOQuQQZTVleOPXNzCu6zgMDRsqOg5Rq7GoERESIhMQ7BWMzPxM0VGIHOL57OfRbG3GU0OeEh2F6Iq0qqgdPnzYwTGISCRPlSeSDcn4+sjXONtwVnQcojb166lfsSZ/Dab1mYYuAV1ExyG6Iq0qaosWLcLjjz+O9evX291BgIjch6mbCQ3NDfii+AvRUYjajCRJWLB9AbTeWswcMFN0HKIr1qqi9vbbb+PWW29FQUEBZs6ciWeeeQZbtmxBQ0ODo/MRkZP00/dDTFAMbylFbmXT4U3YfmI7Hhv0GAI8A0THIbpirbqFlEqlwuDBgzF48GDU1tZi27ZtWL9+Pd59910MGTIESUlJ6NGjh6OzEpEDKRQKmIwmpGen40jVEe4ionavobkBi3cuRregbrizx52i4xBdlSs6maC+vh47d+7E1q1bYTabER8fj9DQULz22mt49913HZWRiJxkUswkKKDA2oK1oqMQ/Wkr963E4arDmD9sPtRKp9zamqjNteo7d9euXdiyZQt2796NHj16YPTo0XjyySfh6ekJABgzZgwefPBB3H///Q4NS0SOFaGJwPCw4cjIz8AjAx6BQqEQHYnoqlTWV+KV3a8goVMCEiITRMchumqtKmofffQRrrvuOkyZMgXBwcEtXtdoNLj33nvbOhsRCWDqZsKsH2fhl/JfEBcSJzoO0VV58ZcXUdNUg3lD54mOQvSntGrX54svvogJEyZcsKSdl5iY2GahiEiccVHj4K3y5kkF1G7ln87HqrxVuLPHneiu7S46DtGf0qqitnTpUuTl5dk9l5eXhxdffNEhoYhIHI2nBmO7jsX6wvVoaOaZ3dT+LNyxEL5qXzw26DHRUYj+tFYVtf3796N7d/t/lXTr1g379u1zSCgiEstkNOFs41lkHc0SHYXoivx47Ed8X/I9Hh7wMHQ+OtFxiP60VhU1Dw8P1NfX2z1XX18PlUrlkFBEJNY14dcgxDeEuz+pXbFYLVi4fSE6+3fG1D5TRcchahOtKmr9+vXD22+/jdraWgBAbW0tVqxYgf79+zsyGxEJolKqMDFmIr4/+j3MdWbRcYha5ZODn+DA6QN4ashT8FJ5iY5D1CZaVdTuuece1NXVYerUqbj//vsxdepU1NbW8kxPIjdmMppgkSxYX7RedBSiyzrXeA5LflmCISFDMK7rONFxiNpMqy7PodFokJqaitOnT8NsNkOv1yMoKMjB0YhIpJ7anuit642M/Azc1/s+0XGILun13NdRUVeB9298n9f/I7dyRXcmCA4OhsFgQEBAAKxWK6xWq6NyEZELMBlNyD2Vi/zT+aKjEF1UybkSvLP3HaTEpKB/h/6i4xC1qVZtUausrMSKFSuQl5eHmpoau9dWr17tkGBEJF6yIRnP7HgGGQUZSB2cKjoO0QU9u/NZKKDA7MGzRUchanOt2qL29ttvQ61WY/78+fD29sbzzz+PuLg4/PWvf3V0PiISqKNvR1zX6Tpk5mfCKnELOrme7JPZWF+0Hg/2exDhmnDRcYjaXKuK2qFDh/Dggw8iKioKCoUCUVFRePDBB7Fx40ZH5yMiwUxGE8pqyrC1dKvoKER2rJIVC7YtQIhvCB6MfVB0HCKHaFVRUyqVtmum+fn5oaqqCl5eXqisrHRoOCIS74YuN8Dfw5/XVCOX83nh59h9ajeeHPwk/Dz8RMchcohWFbWYmBjs3r0bwO/XVHvppZewdOlSGAwGh4YjIvF81D4YHz0eXx7+ErVNtaLjEAEA6ix1eHbns+ij64PJxsmi4xA5TKuK2t///nf06tULAHDvvfeiT58+iIyMxMyZMx0ajohcg8loQk1TDb468pXoKEQAgLd/exulNaVIG5YGpeKKLmBA1K5c9rvbarVi5cqV8PL6/SrPnp6eSElJwV133YXg4GCHByQi8YaEDkGkJhIZh7j7k8Q7WXsSr+e+jjFdxiA+PF50HCKHumxRUyqV+PXXX3kBQSIZUyqUSDGm4N+l/8bxc8dFxyGZW5KzBE3WJswdOld0FCKHa9X24nHjxuHTTz+FxWJxdB4iclEpxhRYJSs+2feJ6CgkY3vNe/HJwU9wX+/70DWwq+g4RA7XqgvefvXVVzhz5gy++OILBAQE2L325ptvOiQYEbmW6MBoDOo4CB/t/Qj3GO7hVnZyOkmSsHD7QgR5BeHhAQ+LjkPkFK0qan//+98dnYOI2oEUYwrm/DwH+yr3oY+uj+g4JDPfHv0WP5f+jGfin0GQV5DoOERO0aqidv6MTyKStwnRE5C2LQ0ZhzLQZziLGjlPY3MjFm5fiJigGNzV8y7RcYicplVF7VL387ztttvaLAwRubZg72CMM47DZ4WfYe7QuVArW/UjhOhP+yDvAxRXFeP9G9+Hh9JDdBwip2nVyQRms9nuv8LCQmzYsAEnT550dD4icjF39rkTFXUV+PHYj6KjkEycrj+Nl3a9hGsjrkViZKLoOERO1ap/Dk+fPr3Fc7m5ufjpp59avaLc3FysXLkSVqsViYmJSE5Otnt98+bNWLVqFbRaLQBgzJgxSEz87/+QtbW1mDVrFgYPHoxp06a1er1E1LbGGMYg2CsYGfkZSOzMvzTJ8V7a/RKqGquQNiyNJ7GQ7Fz1fovY2Fi89NJLrVrWarVixYoVmDt3LnQ6HVJTUxEXF4dOnTrZLRcfH3/RErZ69Wr07NnzauMSURvxVHki2ZCMjw9+jLMNZxHoFSg6ErmxwjOFeH/f+7i9++3oqeXfASQ/rdr1efLkSbv/jh49ik8++QR6vb5VKykoKEBoaChCQkKgVqsRHx+P7OzsVocsKirC2bNn0a9fv1a/h4gcJ8WYgobmBnxR/IXoKOTmntn5DLzUXnh80OOioxAJ0aotav97T09PT0907doVM2bMaNVKKisrodPpbI91Oh3y8/NbLLdjxw7k5eUhLCwMU6ZMgV6vh9VqxQcffIC///3v+O233y66jqysLGRlZQEA0tPTW10i/wy1Wu2U9bgiOc8OyHt+tVqNpJ5J6Pbvblh/eD1mXiOfe/7K+XMHnD//D4d/wDdHvsGi6xahZ2exW9P42ct3ftGz/+mzPtvKoEGDMGLECHh4eODbb7/FsmXLkJaWhm+++QYDBgywK3oXkpSUhKSkJNvjiooKR0eGXq93ynpckZxnB+Q9v16vh9lsxsToiXg+53nsKtqFzgGdRcdyCjl/7oBz52+2NmPW17PQSdMJd0TfIfzPnZ+9fOd3xuzh4eEXfa1Vuz4PHz7cImRFRQUOHz7cqgBarRZms9n22Gw2204aOM/f3x8eHr+fcp2YmIiioiIAwKFDh/DVV19hxowZWLVqFbZs2YKPPvqoVeslIsdJMaYAADILMgUnIXf06aFPsb9yP+YMmQNvtbfoOETCtKqovfbaa2hubrZ7zmKx4PXXX2/VSgwGA8rKylBeXg6LxYKtW7ciLi7ObpnTp0/bfp+Tk2M70WDmzJl48803sWzZMtx9990YOXIk7rzzzlatl4gcJ0ITgfiweGTkZ0CSJNFxyI1UN1bjhZwXMKjjIEyIniA6DpFQrdr1WVFRgZCQELvnQkNDcerUqVatRKVSYerUqVi8eDGsVisSEhIQGRmJ1atXw2AwIC4uDps2bUJOTg5UKhU0Gs0FLwlCRK7F1M2EWT/Owi/lvyAuJO7ybyBqhWV7lqG8rhzvXv8uL8dBsteqoqbValFUVITo6Gjbc0VFRQgODm71igYOHIiBAwfaPffHuxrccccduOOOOy75NUaNGoVRo0a1ep1E5FjjosZhzk9zkJGfwaJGbeJ49XG8/dvbSDYkY1DIINFxiIRrVVEbN24clixZggkTJiAkJAQnT57Ehg0bMGnSJEfnIyIXpvHU4Kaom7ChaAMWDF8AL5WX6EjUzj238zkAwJwhcwQnIXINrSpqSUlJ8PPzw/fffw+z2QydTod77rkHw4YNc3Q+InJxJqMJnxV+hu+OfoexXceKjkPt2K7yXfis8DP8vf/fEaGJEB2HyCW0+s4Ew4cPx/Dhwx2ZhYjaoWsirkGIbwgy8jNY1OiqSZKEBdsXoINPBzzU7yHRcYhcRqvO+vzXv/6FgwcP2j138OBBvPfee47IRETtiFqpxsSYifju6HeorK8UHYfaqQ1FG5BzMgdPxD0BjadGdBwil9Gqovbzzz/DYDDYPRcdHX1FN2UnIvdlMppgkSz4vPBz0VGoHaq31OPZnc+ip7Ynbut22+XfQCQjrSpqCoUCVqvV7jmr1cprJxERAKCntid663ojIz9DdBRqh1bsXYGS6hKkDUuDSqkSHYfIpbSqqPXo0QOffPKJraxZrVZ8+umn6NGjh0PDEVH7YTKakHsqFwVnCkRHoXbkVO0pvJr7Kq7vfD2ujbhWdBwil9Oqonbffffht99+wwMPPIDU1FQ88MAD+O233zB16lRH5yOidiLZkAylQsmtanRFlv6yFPWWeswdOld0FCKX1KqzPnU6HZ5//nkUFBTAbDYjMDAQ2dnZmDNnDt566y1HZySidqCjb0eM6jQKmfmZeCLuCSgVrfp3IMlYXmUePj74Me7rdR9igmJExyFySa3+SVpdXY2CggJ89tlnWLBgAYqLi3Hvvfc6MBoRtTcmowmlNaXYVrZNdBRycZIkYeH2hQjwDMCjAx8VHYfIZV1yi5rFYkFOTg42b96MPXv2IDQ0FCNGjEBFRQUeffRRBAYGOisnEbUDN3S5Af4e/sjIz8CI8BGi45AL+77ke2w5vgVPD3sawd6tvx0hkdxcsqj99a9/hVKpxHXXXYdbb73Vdq/Pb775xinhiKh98VH7YHz0eKwvWo/F8Yvh6+ErOhK5oCZrExbuWIiuAV0xpdcU0XGIXNold3126dIFNTU1KCgoQGFhIaqrq52Vi4jaKZPRhJqmGnx15CvRUchFfZT3EQrOFGDe0HnwVHmKjkPk0i65Re3pp5/GqVOn8OOPP2LDhg1YuXIlYmNj0dDQgObmZmdlJKJ2ZEjoEERqIpGZn4lJMZNExyEXc6bhDJb+shTxYfG4ocsNouMQubzLnkzQoUMHmEwmvPrqq5g/fz6Cg4OhUCjw+OOP48MPP3RGRiJqR5QKJSYZJ2HL8S04UXNCdBxyMa/ufhVnGs4gbXgaFAqF6DhELu+Kzp/v0aMHHnjgAbz99tu47777cPToUUflIqJ2LCUmBVbJinWF60RHIRdSfLYY/9r3L9zW7Tb00fURHYeoXbiqCx15enrimmuuwZw5c9o6DxG5AUOQAQM7DsSaQ2t4qzmyeXbns/BQeuCJwU+IjkLUbvCKlETkECajCQdOH8C+yn2io5AL2Fa2DV8e/hIz+s1AiG+I6DhE7QaLGhE5xIToCfBQeiDjEG8pJXdWyYoF2xcgzC8MD8Q+IDoOUbvCokZEDhHsHYzrO1+PdYXrYLFaRMchgTLyM/BbxW+YM2QOfNQ+ouMQtSssakTkMCnGFJyqO4Utx7eIjkKC1DbV4vns59G/Q38kG5JFxyFqd1jUiMhhRkeORpBXEDLyuftTrt789U2cqD2Bp4c9DaWCf+UQXSn+X0NEDuOp8kSyIRlfH/4aVY1VouOQk5XVlOGNPW/g5uibMTh0sOg4RO0SixoROZTJaEJ9cz2+KPpCdBRysvTsdFglK+YM5qWciK4WixoROVT/Dv1hCDRw96fM7Dm1Bxn5Gfhr37+ic0Bn0XGI2i0WNSJyKIVCAZPRhO0ntuNoFe9mIgeSJGHB9gXQeevw9/5/Fx2HqF1jUSMih0sxpgAAMgsyBSchZ/jy8JfYcWIHHo97HP6e/qLjELVrLGpE5HARmggMDxuOzPxM3lLKzTU0N2DxjsXoHtwdt3e/XXQconaPRY2InGKycTKKq4qxq3yX6CjkQCv3rcSRc0eQNiwNaqVadByido9FjYicYmzXsfBWefOkAjdmrjPj5V0vY3TkaFzX6TrRcYjcAosaETmFv6c/boq6CeuL1qOhuUF0HHKAF3e9iFpLLeYNnSc6CpHbYFEjIqcxGU0403AG3x39TnQUamOHTh/Ch3kf4q6ed6FbcDfRcYjcBosaETnNNRHXIMQ3hLs/3dCiHYvg5+GHfwz8h+goRG6FRY2InEatVGNizER8X/I9KusrRcehNrK5ZDO+L/keDw94GDofneg4RG6FRY2InColJgVN1iasL1wvOgq1AYvVgoU7FiIqIAr39b5PdBwit+O0c6dzc3OxcuVKWK1WJCYmIjk52e71zZs3Y9WqVdBqtQCAMWPGIDExEYcPH8Y777yDuro6KJVKTJo0CfHx8c6KTURtrJeuF3ppeyEjPwP39r5XdBz6k/7fwf+Hg6cP4p2kd+Cl8hIdh8jtOKWoWa1WrFixAnPnzoVOp0Nqairi4uLQqVMnu+Xi4+Mxbdo0u+c8PT3x0EMPISwsDJWVlZg9ezb69esHPz8/Z0QnIgcwGU1YuGMhCs4UICYoRnQcukpVjVVYkrMEw0KH4aaom0THIXJLTtn1WVBQgNDQUISEhECtViM+Ph7Z2dmtem94eDjCwsIAAFqtFoGBgaiqqnJkXCJysIkxE6FUKHlSQTv32u7XYK43I21YGhQKheg4RG7JKVvUKisrodP99wBTnU6H/Pz8Fsvt2LEDeXl5CAsLw5QpU6DX6+1eLygogMViQUhISIv3ZmVlISsrCwCQnp7e4r2OoFarnbIeVyTn2QF5z98Ws+uhx/Vdr8e6onV4YcwLUCrax+Gycv7cAfv5i88U49197+KuPndhdM/RgpM5Hj97+c4venaXub/HoEGDMGLECHh4eODbb7/FsmXLkJaWZnv99OnTeO211zBjxgwolS1/qCclJSEpKcn2uKKiwuGZ9Xq9U9bjiuQ8OyDv+dtq9luibsHXRV9jw28bMCJ8RBskczw5f+6A/fyPZT0GJZR4JPYRWfyZ8LOX7/zOmD08PPyirznln7FarRZms9n22Gw2204aOM/f3x8eHh4AgMTERBQVFdleq62tRXp6Om6//XZ068YLKRK5gxu63AB/D39k5meKjkJXKPtENjYWb8T0ftMR5hcmOg6RW3NKUTMYDCgrK0N5eTksFgu2bt2KuLg4u2VOnz5t+31OTo7tRAOLxYKlS5di5MiRGDZsmDPiEpET+Kh9MK7rOGws3og6S53oONRKVsmKp7c/jVDfUDwY+6DoOERuzym7PlUqFaZOnYrFixfDarUiISEBkZGRWL16NQwGA+Li4rBp0ybk5ORApVJBo9Fg+vTpAICtW7ciLy8P586dw+bNmwEAM2bMQFRUlDOiE5EDmbqZ8MmhT/DV4a8wMWai6DjUCusK1yH3VC5euu4l+Hr4io5D5PYUkiRJokM4QmlpqcPXwX328pwdkPf8bTm7VbJi+CfDERMUg49u+qhNvqYjyflzBwDfQF/0erMX9D56fJn8Zbs5CaQtyP2zl/P8sjhGjYjoQpQKJVKMKdhyfAtO1JwQHYcu45Wdr6CspgxPD3taViWNSCT+n0ZEQqXEpMAqWbGucJ3oKHQJJ2pOYMm2JRgbNRbDwni8MJGzsKgRkVCGIAMGdhzIi9+6uCU5S9DY3Iinhj4lOgqRrLCoEZFwKcYU5FXmYZ95n+godAF7K/Zi9aHVmBE3A1EBUaLjEMkKixoRCTchegI8lB7cquaCJEnCgu0LEOQVhNQRqaLjEMkOixoRCaf11iKpcxI+K/gMFqtFdBz6g2+OfIOtZVvx2KDHEOQdJDoOkeywqBGRSzAZTThVdwpbjm8RHYX+o7G5EYt2LIIxyIi7et4lOg6RLLGoEZFLGB05GkFeQdz96ULe3/8+iquKMW/oPKiVLnNraCJZYVEjIpfgqfJEsiEZXx/+GlWNVaLjyF5lfSVe2vUSrou4DqMjR4uOQyRbLGpE5DJMRhPqm+vxZfGXoqPI3su7Xsa5pnOYP2w+FAqF6DhEssWiRkQuo3+H/ogOjObuT8EKzhTg/f3v447ud6CHtofoOESyxqJGRC5DoVDAZDRhW9k2lJwrER1Htp7Z8Qy81d54bNBjoqMQyR6LGhG5lJSYFABAZn6m4CTy9O/j/8a3R7/FzP4z0cG3g+g4RLLHokZELqWTfycMDxuOjPwMSJIkOo6sNFubsWD7AkRqIjGtzzTRcYgILGpE5IImGyejuKoYu8p3iY4iK6sPrUZeZR7mDJkDb7W36DhEBBY1InJBY7uOhbfKmycVOFF1YzVeyHkBcSFxuDn6ZtFxiOg/WNSIyOX4e/rjpqibsL5oPRqaG0THkYXX97yOU3Wn8PSwp3k5DiIXwqJGRC4pxZiCMw1n8P3R70VHcXvHzh3D27+9jUkxkzCg4wDRcYjoD1jUiMglXRtxLTr6dOTuTyd4Lvs5KKDA7MGzRUchov/BokZELkmtVGNizER8V/IdKusrRcdxW7+c/AXrCtfhgdgHEKGJEB2HiP4HixoRuSyT0YQmaxPWF64XHcUtSZKEBdsXoKNPR8zoN0N0HCK6ABY1InJZvXS90Evbi7s/HWR90Xr8Uv4Lnhz8JPw8/ETHIaILYFEjIpdmMpqw+9RuFJwpEB3FrdRb6vHszmfRW9cbk42TRcchootgUSMilzYxZiKUCiVvKdXG3tn7Do5VH8P8ofOhUqpExyGii2BRIyKX1tG3I66LuA6ZBZmwSlbRcdzCqdpTeC33NdzQ5QZcE3GN6DhEdAksakTk8kxGE45XH8f2su2io7iFJb8sQYOlAXOHzBUdhYgug0WNiFzejVE3QuOh4UkFbWC/eT/+38H/hym9p8AQZBAdh4gug0WNiFyej9oH47uOx8bijaiz1ImO025JkoSFOxYiwDMAjw54VHQcImoFFjUiahdM3UyoaarBV4e/Eh2l3fqu5Dv8+/i/MWvgLAR7B4uOQ0StwKJGRO3C0NCh6KTpxLM/r1KTtQkLty9EdGA07ul1j+g4RNRKLGpE1C4oFUpMipmEH4//iJO1J0XHaXc+zPsQhWcLMW/oPHgoPUTHIaJWYlEjonYjxZgCq2TFZwWfiY7SrpxpOIOlvyzFiPARuL7z9aLjENEVYFEjonYjJigGAzoO4NmfV+iV3a/gbMNZpA1Lg0KhEB2HiK4AixoRtSsmowl5lXnYZ94nOkq7UHS2CCv3rcRfuv8FvXW9RcchoivEokZE7cqE6AnwUHpwq1orPbvzWXgoPfBE3BOioxDRVVA7a0W5ublYuXIlrFYrEhMTkZycbPf65s2bsWrVKmi1WgDAmDFjkJiYaHtt7dq1AIBJkyZh1KhRzopNRC5G661FUuckrCtYh6eGPAW10mk/xtqdraVbsenwJjwR9wQ6+nYUHYeIroJTfsJZrVasWLECc+fOhU6nQ2pqKuLi4tCpUye75eLj4zFt2jS756qrq5GRkYH09HQAwOzZsxEXFweNRuOM6ETkgkxGEzYd3oR/H/83EiITRMdxSVbJigXbFyDcLxx/6/s30XGI6Co5ZddnQUEBQkNDERISArVajfj4eGRnZ7fqvbm5uYiNjYVGo4FGo0FsbCxyc3MdG5iIXNroyNEI8gri7s9LWJO/BnvNezFnyBz4qH1ExyGiq+SULWqVlZXQ6XS2xzqdDvn5+S2W27FjB/Ly8hAWFoYpU6ZAr9e3eK9Wq0VlZWWL92ZlZSErKwsAkJ6eDr1e74BJ7KnVaqesxxXJeXZA3vO7yuy39b4N7//6Pjz9PRHgFeCUdbrK7JdT3ViNJb8swZDwIbh/6P1tdqZne5nfEeQ8OyDv+UXP7jIHdwwaNAgjRoyAh4cHvv32WyxbtgxpaWmtfn9SUhKSkpJsjysqKhwR045er3fKelyRnGcH5D2/q8w+PnI83tr1Fj7I+QB/6f4Xp6zTVWa/nKW/LEVZdRmWj14Os9ncZl+3vczvCHKeHZD3/M6YPTw8/KKvOWXXp1artfthYTabbScNnOfv7w8Pj9+vlp2YmIiioqILvreysrLFe4lIfgZ0GIDowGju/vwfpdWleHPPm5gQPQFxIXGi4xDRn+SUomYwGFBWVoby8nJYLBZs3boVcXH2P0BOnz5t+31OTo7tRIP+/ftjz549qK6uRnV1Nfbs2YP+/fs7IzYRuTCFQgGT0YRtZdtQcq5EdByXkZ6dDgkS5gyZIzoKEbUBp+z6VKlUmDp1KhYvXgyr1YqEhARERkZi9erVMBgMiIuLw6ZNm5CTkwOVSgWNRoPp06cDADQaDVJSUpCamgoAMJlMPOOTiAAAKTEpeCHnBawtWIuHBzwsOo5wuadykVmQiYf6PYRI/0jRcYioDSgkSZJEh3CE0tJSh6+D++zlOTsg7/ldbXbTRhNO1p7ElslbHH57JFeb/Y8kScKkDZNQVFWEn279Cf6e/m2+Dlee39HkPDsg7/llcYwaEZGjmIwmFJ0twu5Tu0VHEeqL4i+w8+ROPD7ocYeUNCISg0WNiNq1cV3HwVvlLeuTChqaG7B452L01PbE7d1vFx2HiNoQixoRtWv+nv4YEzUGnxd+jobmBtFxhPjX3n/h6LmjmD90PlRKleg4RNSGWNSIqN0zGU0403AG3x/9XnQUpzPXmfHK7leQGJmIkZ1Gio5DRG2MRY2I2r1rI65FR5+Ostz9ufSXpai11GLe0HmioxCRA7CoEVG7p1aqMTFmIr4r+Q6V9S1vMeeuDlYexIcHPsQ9Pe+BMdgoOg4ROQCLGhG5BZPRhCZrE9YXrRcdxWkW7VgEjYcGswbNEh2FiByERY2I3EIvXS/01PaUze7PH0p+wA/HfsAjAx6B1pu31SNyVyxqROQ2TEYTdpfvRsGZAtFRHMpitWDh9oWICojCfb3vEx2HiByIRY2I3MbEmIlQKpTIzM8UHcWhPjrwEQ6dOYS5Q+bCU+UpOg4RORCLGhG5jRDfEFwXcR0yCzJhlayi4zhEVWMVlv6yFMPDhmNM1BjRcYjIwVjUiMitmIwmHK8+jh0ndoiO4hCv7n4Vp+tPI21YmsPvbUpE4rGoEZFbuTHqRmg8NMg45H4nFRypOoIVe1dgcrfJ6KvvKzoOETkBixoRuRUftQ/GdR2HjcUbUWepEx2nTS3euRgqpQpPxj0pOgoROQmLGhG5HZPRhOqmanx9+GvRUdrMzhM78UXxF5jRbwZC/UJFxyEiJ2FRIyK3MyxsGCI0EW5zTTWrZMXT255GqF8oHuj7gOg4RORELGpE5HaUCiVSYlLw4/EfcbL2pOg4f9pnBZ9hT8UepA5Oha+Hr+g4RORELGpE5JZSjCmwSlZ8VvCZ6Ch/Sp2lDs9lP4d++n6YFDNJdBwicjIWNSJySzFBMRjQcUC7v/jt8l+Xo6ymDGnD0qBU8Ec2kdzw/3oiclsmown7K/djn3mf6ChX5UTNCSzbswxju47F0LChouMQkQAsakTktiZET4CH0qPdblV7IecFNFubMXfIXNFRiEgQFjUicltaby0SIxPxWcFnsFgtouNckd8qfsOnhz7FtD7T0CWgi+g4RCQIixoRuTWT0YTyunL8+/i/RUdpNUmSsGD7AgR7B2PmgJmi4xCRQCxqROTWRncejSCvoHZ1TbWvj3yNbWXb8NigxxDgGSA6DhEJxKJGRG7NS+WFWwy34KvDX+Fc4znRcS6rsbkRi3YsQregbrizx52i4xCRYCxqROT2TEYT6pvr8WXxl6KjXNZ7+9/D4arDmD9sPtRKteg4RCQYixoRub0BHQYgOjAaa/LXiI5ySZX1lXh518sY1WkUEiITRMchIhfAokZEbk+hUCAlJgXbyrbh2LljouNc1Eu7XsK5pnOYP3S+6ChE5CJY1IhIFlKMKQCAzALXvKZawZkCvL//fdzZ405013YXHYeIXASLGhHJQqR/JIaHDUdGfgYkSRIdp4VFOxbBV+2LxwY9JjoKEbkQFjUikg2T0YSis0XYfWq36Ch2thzfgqyjWZg5YCb0PnrRcYjIhbCoEZFsjOs6Dt4qb5e6pVSztRkLty9EZ//OmNZnmug4RORiWNSISDb8Pf0xJmoM1hWuQ2Nzo+g4AIBPDn2CvMo8PDXkKXipvETHISIXw6JGRLJiMppwpuEMvi/5XnQUVDdW44WcFzAkZAjGdR0nOg4RuSAWNSKSlWsjrkUHnw4ucUup1/a8hoq6CqQNT4NCoRAdh4hckNMue52bm4uVK1fCarUiMTERycnJF1xu+/bt+Oc//4nnnnsOBoMBFosFy5cvR3FxMaxWK0aOHImJEyc6KzYRuRm1Uo2JMROxct9KVNZXQuutFZLj2LljeOe3dzApZhL6d+gvJAMRuT6nbFGzWq1YsWIF5syZg5deegk///wzjh1redHJuro6bNq0CUaj0fbc9u3bYbFY8OKLLyI9PR1ZWVkoLy93RmwiclMmowlN1iasL1ovLMOz2c9CAQVmD54tLAMRuT6nFLWCggKEhoYiJCQEarUa8fHxyM7ObrHc6tWrccstt8DDw8Pu+fr6ejQ3N6OxsRFqtRq+vr7OiE1Ebqq3rjd6ansK2/2ZczIHnxd+jv+L/T9EaCKEZCCi9sEpuz4rKyuh0+lsj3U6HfLz8+2WKSoqQkVFBQYOHIj16//7r9xhw4YhJycHf/vb39DY2IgpU6ZAo9G0WEdWVhaysrIAAOnp6dDrHX8tIrVa7ZT1uCI5zw7Ie353mX1K/ymY/f1sVCoq0U3XrVXvaYvZJUnCs188izBNGOaNngeNZ8ufZ67KXT77qyHn2QF5zy96dqcdo3YpVqsVH3zwAaZPn97itYKCAiiVSrz11luoqanB/Pnz0bdvX4SEhNgtl5SUhKSkJNvjiooKh+fW6/VOWY8rkvPsgLznd5fZbwi7AXMUc/Bu9rt4Iu6JVr2nLWZfV7AOO0p34J8j/4n6qnrUo/5PfT1ncpfP/mrIeXZA3vM7Y/bw8PCLvuaUXZ9arRZms9n22Gw2Q6v97wG89fX1KCkpwYIFCzBjxgzk5+fjhRdeQGFhIX766Sf0798farUagYGB6N69OwoLC50Rm4jcWIhvCEZGjERmfiasktUp66yz1OHZ7GfRR9cHk7tNdso6iah9c0pRMxgMKCsrQ3l5OSwWC7Zu3Yq4uDjb676+vlixYgWWLVuGZcuWwWg04oknnoDBYIBer8fevXsB/F7o8vPzERHBYzqI6M8zGU04Vn0MO07scMr63vntHRyvPo60YWlQKnh1JCK6PKfs+lSpVJg6dSoWL14Mq9WKhIQEREZGYvXq1TAYDHal7X+NGTMGb7zxBmbNmgVJkpCQkIAuXbo4IzYRubkxUWPg5+GHjEMZGB423KHrKq8tx+t7XseYLmMQHx7v0HURkftw2jFqAwcOxMCBA+2eu+222y647NNPP237vbe3N2bNmuXIaEQkUz5qH4zvOh4bizfimRHPwEft47B1LclZgsbmRjw19CmHrYOI3A+3vRORrJmMJlQ3VeObI984bB37zPvw/w7+P9zb615EB0Y7bD1E5H5Y1IhI1oaFDUOEJsJh11STJAkLty9EoFcgHhn4iEPWQUTui0WNiGRNqVAiJSYFm49tRnlt29/1JOtoFn4q/Qn/GPgPBHkFtfnXJyL3xqJGRLKXYkyBVbLis4LP2vTrNlmbsGjHIhgCDbi7191t+rWJSB5Y1IhI9mKCYjCgw4A23/25av8qFJ4txLyh8+Ch9Lj8G4iI/geLGhERfj+pYH/lfuwz72uTr3em4Qxe3PUiro24Fkmdky7/BiKiC2BRIyICMMEwAR5KD2TmZ7bJ13t518uoaqzC/KHzoVAo2uRrEpH8sKgREQHQemuRGJmIzwo+g8Vq+VNfq+hsEd7b/x5u7347eul6tVFCIpIjFjUiov8wGU0oryvHT8d/+lNf55kdz8BT5YnHBj3WRsmISK5Y1IiI/mN059EI8gr6UycV/Fz6M74+8jX+3v/v6OjbsQ3TEZEcsagREf2Hl8oLE6InYNPhTTjXeO6K399sbcaC7QsQoYnA/X3ud0BCIpIbFjUioj8wGU2ob67Hl8VfXvF7M/IzsM+8D08Necqh9w0lIvlgUSMi+oOBHQeia0BXrMlfc0Xvq2mqQXp2OgZ2HIgJ0RMclI6I5IZFjYjoDxQKBUxGE7aVbcOxc8da/b439ryB8rpyPD3saV6Og4jaDIsaEdH/SDGmAADWFqxt1fLHq49j+a/LkWxIxqCQQY6MRkQyw6JGRPQ/Iv0jMTxsODLyMyBJ0mWXT89OBwCkDk51dDQikhkWNSKiC0iJSUHh2ULknsq95HK7y3djbcFa/LXvX9HJv5NzwhGRbLCoERFdwLjocfBWeV/ymmqSJGHB9gXo4NMBD/V7yInpiEguWNSIiC4gwDMAN0bdiHWF69DY3HjBZTYWb0T2yWw8EfcENJ4aJyckIjlgUSMiugiT0YQzDWfwfcn3LV6rt9Tj2Z3Poqe2J27rdpuAdEQkByxqREQXMTJiJDr4dEBmfmaL1/617184eu4o5g+bD5VSJSAdEckBixoR0UWolWpMjJmIb49+i9P1p23PV9RV4NXdryKpcxJGRowUmJCI3B2LGhHRJZiMJjRZm7C+aL3tuaW/LEWdpQ7zhs4TmIyI5IBFjYjoEnrreqOntqft7M8DlQfw0YGPcE+vexATFCM4HRG5OxY1IqLLMBlN2FW+C4fMh7BoxyIEeAbg0YGPio5FRDLAokZEdBnJhmQoFUo8uOlBbD62GY8MeARab63oWEQkAyxqRESXEeoXipERI/FTyU/oGtAVU3pNER2JiGSCRY2IqBXOXytt3tB58FR5Ck5DRHKhFh2AiKg9uDn6ZoyIGQGdpBMdhYhkhFvUiIhaQaFQoLuuu+gYRCQzLGpERERELopFjYiIiMhFsagRERERuSgWNSIiIiIXxaJGRERE5KKcdnmO3NxcrFy5ElarFYmJiUhOTr7gctu3b8c///lPPPfcczAYDACAI0eO4O2330ZdXR0UCgWee+45eHryOkZERETk3pxS1KxWK1asWIG5c+dCp9MhNTUVcXFx6NSpk91ydXV12LRpE4xGo+255uZmvPbaa3jooYcQFRWFc+fOQa3m5d+IiIjI/Tll12dBQQFCQ0MREhICtVqN+Ph4ZGdnt1hu9erVuOWWW+Dh4WF7bs+ePejcuTOioqIAAP7+/lAquceWiIiI3J9TNk1VVlZCp/vv1bx1Oh3y8/PtlikqKkJFRQUGDhyI9evX254vKyuDQqHA4sWLUVVVhfj4eNxyyy0t1pGVlYWsrCwAQHp6OvR6vYOm+S+1Wu2U9bgiOc8OyHt+zi7P2QF5zy/n2QF5zy96dpfYh2i1WvHBBx9g+vTpLV5rbm7GgQMH8Nxzz8HLywsLFy5EdHQ0+vbta7dcUlISkpKSbI8rKiocnluv1ztlPa5IzrMD8p6fs8tzdkDe88t5dkDe8ztj9vDw8Iu+5pSiptVqYTabbY/NZjO0Wq3tcX19PUpKSrBgwQIAwJkzZ/DCCy/giSeegE6nQ8+ePREQEAAAGDBgAIqLi1sUNSIiIiJ345SiZjAYUFZWhvLycmi1WmzduhUzZ860ve7r64sVK1bYHj/99NO4++67YTAYEBISgvXr16OhoQFqtRp5eXkYN26cM2ITERERCeWUoqZSqTB16lQsXrwYVqsVCQkJiIyMxOrVq2EwGBAXF3fR92o0GowbNw6pqalQKBQYMGAABg4c6IzYREREREIpJEmSRIdwhNLSUoevg/vs5Tk7IO/5Obs8ZwfkPb+cZwfkPb/oY9R4nQsiIiIiF+W2W9SIiIiI2jtuUfsTZs+eLTqCMHKeHZD3/JxdvuQ8v5xnB+Q9v+jZWdSIiIiIXBSLGhEREZGLYlH7E/54JwS5kfPsgLzn5+zyJef55Tw7IO/5Rc/OkwmIiIiIXBS3qBERERG5KBY1IiIiIhfllFtItXe5ublYuXIlrFYrEhMTkZycbPd6U1MTXn/9dRQVFcHf3x+PPPIIOnbsKCZsG7vc7Js3b8aqVaug1WoBAGPGjEFiYqKApG3vjTfewK5duxAYGIgXX3yxxeuSJGHlypXYvXs3vLy8MH36dERHRwtI2vYuN/u+ffvwwgsv2L7Phw4dCpPJ5OyYDlFRUYFly5bhzJkzUCgUSEpKwtixY+2WcefPvjXzu+vn39jYiLS0NFgsFjQ3N2PYsGG49dZb7ZZx15/3rZndnX/en2e1WjF79mxotdoWl+UQ9tlLdEnNzc3SQw89JJ04cUJqamqSHnvsMamkpMRuma+++kp66623JEmSpJ9++kn65z//KSJqm2vN7D/88IP07rvvCkroWPv27ZMKCwulWbNmXfD1X375RVq8eLFktVqlgwcPSqmpqU5O6DiXm33v3r3Sc8895+RUzlFZWSkVFhZKkiRJtbW10syZM1t837vzZ9+a+d3187darVJdXZ0kSZLU1NQkpaamSgcPHrRbxl1/3rdmdnf+eX/ehg0bpJdffvmC39+iPnvu+ryMgoIChIaGIiQkBGq1GvHx8cjOzrZbJicnB6NGjQIADBs2DHv37oXkBudotGZ2d9arVy9oNJqLvp6Tk4ORI0dCoVCgW7duqKmpwenTp52Y0HEuN7s7Cw4Otm0d8/HxQUREBCorK+2WcefPvjXzuyuFQgFvb28AQHNzM5qbm6FQKOyWcdef962Z3d2ZzWbs2rXrolsJRX323PV5GZWVldDpdLbHOp0O+fn5F11GpVLB19cX586dQ0BAgFOztrXWzA4AO3bsQF5eHsLCwjBlyhTo9XpnxhSmsrLSbladTofKykoEBwcLTOU8hw4dwuOPP47g4GDcfffdiIyMFB2pzZWXl6O4uBgxMTF2z8vls7/Y/ID7fv5WqxVPPvkkTpw4gRtvvBFGo9HudXf9eQ9cfnbAvX/ev/fee7jrrrtQV1d3wddFffbcokZ/yqBBg7Bs2TIsXboUsbGxWLZsmehI5ARdu3bFG2+8gSVLlmDMmDFYsmSJ6Ehtrr6+Hi+++CLuvfde+Pr6io7jdJea350/f6VSiSVLlmD58uUoLCzE0aNHRUdymsvN7s4/73/55RcEBga65LGmLGqXodVqYTabbY/NZrPtQMoLLdPc3Iza2lr4+/s7NacjtGZ2f39/eHh4AAASExNRVFTk1IwiabVaVFRU2B5f6M/HXfn6+tp2kwwcOBDNzc2oqqoSnKrtWCwWvPjii7j22msxdOjQFq+7+2d/ufnd/fMHAD8/P/Tu3Ru5ubl2z7vrz/s/utjs7vzz/uDBg8jJycGMGTPw8ssvY+/evXj11VftlhH12bOoXYbBYEBZWRnKy8thsViwdetWxMXF2S0zaNAgbN68GQCwfft29O7d2y327bdm9j8el5OTk4NOnTo5O6YwcXFx2LJlCyRJwqFDh+Dr6+t2u74u5syZM7ZjMwoKCmC1Wt3mLytJkrB8+XJERERg/PjxF1zGnT/71szvrp9/VVUVampqAPx+FuSvv/6KiIgIu2Xc9ed9a2Z355/3d9xxB5YvX45ly5bhkUceQZ8+fTBz5ky7ZUR99rwzQSvs2rUL77//PqxWKxISEjBp0iSsXr0aBoMBcXFxaGxsxOuvv47i4mJoNBo88sgjCAkJER27TVxu9o8//hg5OTlQqVTQaDS4//77W/zP3V69/PLL2L9/P86dO4fAwEDceuutsFgsAIAbbrgBkiRhxYoV2LNnDzw9PTF9+nQYDAbBqdvG5Wb/6quv8M0330ClUsHT0xP33HMPunfvLjh12zhw4ADmz5+Pzp07234I33777bYtaO7+2bdmfnf9/I8cOYJly5bBarVCkiQMHz4cJpNJFj/vWzO7O/+8/6N9+/Zhw4YNmD17tkt89ixqRERERC6Kuz6JiIiIXBSLGhEREZGLYlEjIiIiclEsakREREQuikWNiIiIyEWxqBERtZFbb70VJ06cEB2DiNwI7/VJRG5rxowZOHPmDJTK//6bdNSoUZg2bZrAVERErceiRkRu7cknn0RsbKzoGEREV4VFjYhkZ/Pmzfjuu+8QFRWFLVu2IDg4GNOmTUPfvn0BAJWVlXjnnXdw4MABaDQa3HLLLUhKSgIAWK1WrFu3Dj/88APOnj2LsLAwPP7449Dr9QCAX3/9Fc8++yyqqqpwzTXXYNq0aVAoFDhx4gTefPNNHD58GGq1Gn369MGjjz4q7M+AiNoHFjUikqX8/HwMHToUK1aswM6dO7F06VIsW7YMGo0Gr7zyCiIjI/HWW2+htLQUixYtQmhoKPr06YONGzfi559/RmpqKsLCwnDkyBF4eXnZvu6uXbvw3HPPoa6uDk8++STi4uLQv39/fPLJJ+jXrx/S0tJgsVjc6obWROQ4LGpE5NaWLFkClUple3zXXXdBrVYjMDAQ48aNg0KhQHx8PDZs2IBdu3ahV69eOHDgAGbPng1PT09ERUUhMTERP/74I/r06YPvvvsOd911F8LDwwEAUVFRdutLTk6Gn58f/Pz80Lt3bxw+fBj9+/eHWq3GqVOncPr0aeh0OvTo0cOZfwxE1E6xqBGRW3v88cdbHKO2efNmaLVa203HAaBDhw6orKzE6dOnodFo4OPjY3tNr9ejsLAQAGA2my95I+agoCDb7728vFBfXw/g94L4ySefYM6cOfDz88P48eMxevTothiRiNwYixoRyVJlZSUkSbKVtYqKCsTFxSE4OBjV1dWoq6uzlbWKigpotVoAgE6nw8mTJ9G5c+crWl9QUBD+7//+DwBw4MABLFq0CL169UJoaGgbTkVE7obXUSMiWTp79iw2bdoEi8WCbdu24fjx4xgwYAD0ej26d++Ojz/+GI2NjThy5Ah++OEHXHvttQCAxMRErF69GmVlZZAkCUeOHMG5c+cuu75t27bBbDYDAPz8/ADAboseEdGFcIsaEbm1559/3u46arGxsRg8eDCMRiPKysowbdo0BAUFYdasWfD39wcAPPzww3jnnXfwwAMPQKPRYPLkybbdp+PHj0dTUxOeeeYZnDt3DhEREXjssccum6OwsBDvvfceamtrERQUhPvuu++Su1CJiABAIUmSJDoEEZEznb88x6JFi0RHISK6JO76JCIiInJRLGpERERELoq7PomIiIhcFLeoEREREbkoFjUiIiIiF8WiRkREROSiWNSIiIiIXBSLGhEREZGL+v+n6dtuVU1MegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# accuracy plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(len(history_loaded)), [x[3] for x in history_loaded] , color='green', label='validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('outputs/initial_validation_accuracy.png')\n",
    "plt.show()\n",
    " \n",
    "# loss plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(len(history_loaded)), [x[1] for x in history_loaded], color='orange', label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('outputs/initial_training_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print model and optimizer parameters after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in alexnet.state_dict():\n",
    "    print(param_tensor, \"\\t\", alexnet.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source:\n",
    "# https://debuggercafe.com/effective-model-saving-and-resuming-training-in-pytorch/\n",
    "# save model checkpoint\n",
    "torch.save({\n",
    "            'epoch': epochs,\n",
    "            'model_state_dict': alexnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion,\n",
    "            }, 'outputs/alexnet_trained.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the model before loading the previously saved one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "alexnet_loaded = torchvision.models.alexnet(pretrained=True)\n",
    "# Initialize optimizer  before loading optimizer state_dict\n",
    "optimizer_loaded = optim.Adam(alexnet_loaded.parameters()) \n",
    "\n",
    "# Updating the second classifier\n",
    "alexnet_loaded.classifier[4] = nn.Linear(4096,1024)\n",
    "\n",
    "#Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
    "# AdVo: i will have a binary classification , thus only 2 output nodes\n",
    "alexnet_loaded.classifier[6] = nn.Linear(1024, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained optimizer state_dict loaded...\n",
      "Trained model loss function loaded...\n",
      "Previously trained for 5 number of epochs...\n"
     ]
    }
   ],
   "source": [
    "# load the model checkpoint\n",
    "checkpoint = torch.load('outputs/alexnet_trained.pth')\n",
    "\n",
    "# load model weights state_dict\n",
    "alexnet_loaded.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('Previously trained model weights state_dict loaded...')\n",
    "\n",
    "# load trained optimizer state_dict\n",
    "optimizer_loaded.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "print('Previously trained optimizer state_dict loaded...')\n",
    "\n",
    "epochs = checkpoint['epoch']\n",
    "\n",
    "# load the criterion\n",
    "criterion_loaded = checkpoint['loss']\n",
    "print('Trained model loss function loaded...')\n",
    "\n",
    "print(f\"Previously trained for {epochs} number of epochs...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print loaded model and optimizer parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "features.0.weight \t torch.Size([64, 3, 11, 11])\n",
      "features.0.bias \t torch.Size([64])\n",
      "features.3.weight \t torch.Size([192, 64, 5, 5])\n",
      "features.3.bias \t torch.Size([192])\n",
      "features.6.weight \t torch.Size([384, 192, 3, 3])\n",
      "features.6.bias \t torch.Size([384])\n",
      "features.8.weight \t torch.Size([256, 384, 3, 3])\n",
      "features.8.bias \t torch.Size([256])\n",
      "features.10.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.10.bias \t torch.Size([256])\n",
      "classifier.1.weight \t torch.Size([4096, 9216])\n",
      "classifier.1.bias \t torch.Size([4096])\n",
      "classifier.4.weight \t torch.Size([1024, 4096])\n",
      "classifier.4.bias \t torch.Size([1024])\n",
      "classifier.6.weight \t torch.Size([2, 1024])\n",
      "classifier.6.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 18912, 'exp_avg': tensor([[[[-4.3817e-04, -1.0656e-05,  2.5779e-04,  ...,  1.2989e-04,\n",
      "            2.9456e-04, -8.4409e-07],\n",
      "          [-7.1292e-04, -3.8711e-04, -2.1601e-04,  ...,  1.5448e-04,\n",
      "            4.1421e-04,  2.1780e-04],\n",
      "          [-3.9727e-04, -2.1969e-04, -1.8690e-04,  ...,  5.0571e-04,\n",
      "            8.3630e-04,  4.7896e-04],\n",
      "          ...,\n",
      "          [ 1.3489e-04,  3.6661e-04,  3.3216e-04,  ...,  1.5301e-03,\n",
      "            1.4050e-03,  3.3465e-04],\n",
      "          [ 1.2646e-04,  2.5738e-04,  4.9834e-04,  ...,  1.6945e-03,\n",
      "            1.4686e-03,  4.6216e-04],\n",
      "          [-7.7169e-04, -7.2158e-04, -3.1886e-04,  ...,  7.6729e-04,\n",
      "            6.2005e-04, -3.0995e-04]],\n",
      "\n",
      "         [[-7.5966e-04, -5.2229e-04, -2.7816e-04,  ..., -1.7770e-04,\n",
      "           -5.6976e-05, -2.8213e-04],\n",
      "          [-9.1194e-04, -7.3015e-04, -6.4620e-04,  ..., -1.3632e-04,\n",
      "            1.8265e-05, -2.1457e-04],\n",
      "          [-6.7915e-04, -6.1369e-04, -6.0961e-04,  ...,  1.2639e-04,\n",
      "            2.6301e-04, -5.5065e-06],\n",
      "          ...,\n",
      "          [-1.7736e-04,  1.8056e-05,  1.4869e-04,  ...,  1.4643e-03,\n",
      "            1.3224e-03,  2.6588e-04],\n",
      "          [-1.9687e-04, -3.7625e-05,  2.3188e-04,  ...,  1.4995e-03,\n",
      "            1.2628e-03,  2.7155e-04],\n",
      "          [-8.6148e-04, -8.0403e-04, -4.7547e-04,  ...,  5.5935e-04,\n",
      "            4.7892e-04, -2.9395e-04]],\n",
      "\n",
      "         [[-2.4049e-04, -2.2625e-05,  2.4430e-04,  ...,  3.1722e-04,\n",
      "            4.4752e-04,  8.2685e-05],\n",
      "          [-3.3392e-04, -2.0544e-04, -2.4448e-05,  ...,  3.7028e-04,\n",
      "            4.6364e-04,  8.4020e-05],\n",
      "          [-8.7285e-05, -9.3513e-06,  6.8498e-05,  ...,  6.5429e-04,\n",
      "            7.1475e-04,  3.2342e-04],\n",
      "          ...,\n",
      "          [ 3.1436e-04,  4.6661e-04,  6.4620e-04,  ...,  1.6845e-03,\n",
      "            1.6076e-03,  6.2209e-04],\n",
      "          [ 2.6860e-04,  3.6451e-04,  6.2801e-04,  ...,  1.6988e-03,\n",
      "            1.5432e-03,  5.9641e-04],\n",
      "          [-5.5934e-04, -4.8928e-04, -1.4701e-04,  ...,  7.5834e-04,\n",
      "            7.1804e-04, -2.0377e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.6456e-04, -1.9416e-04, -2.4409e-04,  ...,  3.6516e-04,\n",
      "            4.1845e-04,  5.4591e-04],\n",
      "          [-8.4212e-05, -1.0575e-04, -1.8155e-04,  ..., -2.0263e-05,\n",
      "            5.1189e-05,  1.8059e-04],\n",
      "          [ 3.5903e-05, -2.5067e-05, -1.7139e-04,  ..., -3.6279e-04,\n",
      "           -3.0134e-04, -3.5513e-05],\n",
      "          ...,\n",
      "          [-2.5528e-04, -2.3689e-04, -1.9684e-04,  ..., -5.9576e-04,\n",
      "           -5.9046e-04, -3.7928e-04],\n",
      "          [ 4.2591e-05, -3.9521e-05, -1.5987e-04,  ..., -5.5207e-04,\n",
      "           -5.7566e-04, -6.8845e-04],\n",
      "          [ 2.6062e-04, -4.2672e-05, -2.4691e-04,  ..., -4.7159e-04,\n",
      "           -6.5220e-04, -7.7278e-04]],\n",
      "\n",
      "         [[-3.1906e-04, -3.3074e-04, -2.9984e-04,  ...,  5.6797e-05,\n",
      "            6.3396e-05,  2.9862e-04],\n",
      "          [-1.7336e-04, -1.8443e-04, -2.7958e-04,  ..., -2.4193e-04,\n",
      "           -1.9767e-04, -2.1232e-05],\n",
      "          [-1.1151e-04, -2.7874e-04, -5.0814e-04,  ..., -4.4003e-04,\n",
      "           -4.2098e-04, -2.1757e-04],\n",
      "          ...,\n",
      "          [-4.3303e-04, -5.5391e-04, -6.5488e-04,  ..., -8.7163e-04,\n",
      "           -9.4403e-04, -9.0319e-04],\n",
      "          [-2.2739e-04, -3.9580e-04, -5.7658e-04,  ..., -7.2251e-04,\n",
      "           -8.9399e-04, -1.1004e-03],\n",
      "          [-2.5129e-05, -3.2962e-04, -5.3141e-04,  ..., -6.9925e-04,\n",
      "           -8.7471e-04, -1.0649e-03]],\n",
      "\n",
      "         [[-3.7663e-05, -1.0461e-04, -8.0843e-05,  ...,  3.3596e-04,\n",
      "            2.9955e-04,  4.3923e-04],\n",
      "          [ 9.3255e-05,  6.9197e-06, -1.0958e-04,  ...,  6.8410e-05,\n",
      "            8.7798e-05,  2.1715e-04],\n",
      "          [ 7.6078e-05, -5.9683e-05, -2.2030e-04,  ..., -1.6389e-04,\n",
      "           -1.4351e-04,  5.3598e-05],\n",
      "          ...,\n",
      "          [-2.1480e-04, -3.5957e-04, -4.5366e-04,  ..., -5.3135e-04,\n",
      "           -5.9926e-04, -6.5072e-04],\n",
      "          [-9.3669e-05, -2.8954e-04, -4.4297e-04,  ..., -4.5357e-04,\n",
      "           -5.4024e-04, -7.5027e-04],\n",
      "          [ 1.4075e-04, -1.1195e-04, -3.1944e-04,  ..., -4.3633e-04,\n",
      "           -4.9059e-04, -6.7111e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1438e-03,  1.2566e-03,  1.4258e-03,  ...,  1.0255e-03,\n",
      "            1.0585e-03,  7.5312e-04],\n",
      "          [ 1.4244e-03,  1.4336e-03,  1.7089e-03,  ...,  1.2569e-03,\n",
      "            1.1727e-03,  6.1264e-04],\n",
      "          [ 1.2944e-03,  1.2310e-03,  1.5885e-03,  ...,  1.4859e-03,\n",
      "            1.2761e-03,  8.4878e-04],\n",
      "          ...,\n",
      "          [-1.8589e-04, -9.1218e-05,  1.6287e-04,  ...,  6.9396e-04,\n",
      "            8.7452e-04,  9.9820e-04],\n",
      "          [-2.6781e-04, -2.7514e-04,  4.8710e-05,  ...,  6.1400e-04,\n",
      "            9.3411e-04,  9.0003e-04],\n",
      "          [-1.0888e-04, -2.5402e-04,  5.1087e-05,  ...,  6.9079e-04,\n",
      "            1.1450e-03,  6.9274e-04]],\n",
      "\n",
      "         [[ 5.0083e-04,  6.9061e-04,  9.3059e-04,  ...,  5.2106e-04,\n",
      "            4.0955e-04,  1.4512e-04],\n",
      "          [ 8.3996e-04,  9.5693e-04,  1.1639e-03,  ...,  7.6143e-04,\n",
      "            6.2312e-04,  1.5467e-04],\n",
      "          [ 8.0385e-04,  7.0065e-04,  8.4914e-04,  ...,  9.7641e-04,\n",
      "            7.7419e-04,  3.4231e-04],\n",
      "          ...,\n",
      "          [-6.0785e-04, -5.8856e-04, -4.1739e-04,  ..., -4.4946e-05,\n",
      "            7.0398e-05,  1.0994e-04],\n",
      "          [-4.9035e-04, -5.8285e-04, -3.8576e-04,  ..., -8.1263e-05,\n",
      "            1.3039e-04,  6.1665e-06],\n",
      "          [-4.1269e-04, -5.1629e-04, -3.2069e-04,  ...,  1.6516e-04,\n",
      "            4.3890e-04, -2.9060e-06]],\n",
      "\n",
      "         [[ 9.1567e-04,  1.1387e-03,  1.4033e-03,  ...,  8.4277e-04,\n",
      "            7.7994e-04,  6.1892e-04],\n",
      "          [ 1.1490e-03,  1.3295e-03,  1.4769e-03,  ...,  9.9082e-04,\n",
      "            9.0491e-04,  7.0779e-04],\n",
      "          [ 1.3013e-03,  1.1745e-03,  1.2688e-03,  ...,  1.1141e-03,\n",
      "            9.2155e-04,  7.7723e-04],\n",
      "          ...,\n",
      "          [ 5.5093e-06, -7.1090e-05,  1.7355e-04,  ...,  3.1580e-04,\n",
      "            4.1129e-04,  6.2746e-04],\n",
      "          [ 5.4099e-05, -7.1801e-05,  2.3852e-04,  ...,  2.8877e-04,\n",
      "            4.4294e-04,  5.7536e-04],\n",
      "          [ 1.0027e-04, -6.0361e-05,  1.9480e-04,  ...,  4.0096e-04,\n",
      "            6.0552e-04,  4.6834e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.2063e-04, -6.0854e-04, -6.0721e-04,  ..., -3.3238e-04,\n",
      "           -2.3078e-04, -1.7505e-04],\n",
      "          [-3.9942e-04, -5.3208e-04, -5.6945e-04,  ..., -2.5204e-04,\n",
      "           -1.6124e-04, -7.9505e-05],\n",
      "          [-1.8112e-04, -3.1376e-04, -3.6660e-04,  ..., -6.1786e-05,\n",
      "            2.2966e-06,  2.4462e-05],\n",
      "          ...,\n",
      "          [ 4.4278e-05,  1.0359e-04,  1.2903e-04,  ..., -2.8503e-06,\n",
      "            1.7807e-05, -2.2408e-05],\n",
      "          [-5.6894e-07,  5.8250e-05,  9.4355e-05,  ...,  5.2076e-05,\n",
      "            5.8577e-05, -6.4010e-05],\n",
      "          [ 4.6836e-04,  4.7080e-04,  4.8440e-04,  ...,  3.9934e-04,\n",
      "            3.4200e-04,  1.5002e-04]],\n",
      "\n",
      "         [[-2.1138e-04, -3.1031e-04, -3.7513e-04,  ..., -1.5677e-04,\n",
      "           -8.6049e-05, -4.1602e-05],\n",
      "          [-1.5173e-04, -2.3714e-04, -3.0956e-04,  ..., -1.0718e-04,\n",
      "           -3.5568e-05,  2.0577e-05],\n",
      "          [-7.4513e-05, -1.4806e-04, -1.9618e-04,  ...,  2.9573e-05,\n",
      "            6.7700e-05,  7.9441e-05],\n",
      "          ...,\n",
      "          [ 2.5199e-04,  2.8569e-04,  3.4098e-04,  ...,  1.5214e-04,\n",
      "            1.4231e-04,  4.5651e-05],\n",
      "          [ 1.8078e-04,  2.3874e-04,  2.9085e-04,  ...,  1.8030e-04,\n",
      "            1.5012e-04,  2.8863e-05],\n",
      "          [ 4.8969e-04,  5.0016e-04,  5.1503e-04,  ...,  4.7428e-04,\n",
      "            4.0157e-04,  2.1635e-04]],\n",
      "\n",
      "         [[-2.4922e-04, -3.2040e-04, -3.3257e-04,  ..., -1.8663e-04,\n",
      "           -1.2837e-04, -1.0209e-04],\n",
      "          [-2.1661e-04, -2.7203e-04, -2.7508e-04,  ..., -1.3099e-04,\n",
      "           -8.4613e-05, -4.9566e-05],\n",
      "          [-1.3192e-04, -1.5843e-04, -1.4697e-04,  ...,  4.7104e-06,\n",
      "            4.4689e-05,  2.3310e-05],\n",
      "          ...,\n",
      "          [ 1.5767e-04,  1.6571e-04,  2.5799e-04,  ...,  1.3085e-04,\n",
      "            1.2151e-04,  4.2169e-05],\n",
      "          [ 1.3052e-04,  1.5157e-04,  2.4856e-04,  ...,  7.8888e-05,\n",
      "            5.4953e-05,  1.1291e-05],\n",
      "          [ 4.2127e-04,  4.2565e-04,  4.6855e-04,  ...,  3.9395e-04,\n",
      "            3.7091e-04,  2.1982e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1238e-04,  3.2160e-04,  2.8090e-04,  ..., -2.7351e-04,\n",
      "           -5.0954e-04, -4.1376e-04],\n",
      "          [ 2.9046e-04,  3.9076e-04,  3.4604e-04,  ...,  1.0713e-04,\n",
      "           -3.4091e-04, -2.6493e-04],\n",
      "          [ 8.5620e-04,  1.1894e-03,  1.3517e-03,  ...,  5.1840e-04,\n",
      "            2.0734e-04, -6.5381e-05],\n",
      "          ...,\n",
      "          [ 3.1049e-04,  3.9864e-04,  5.2684e-04,  ...,  5.2193e-04,\n",
      "            1.6856e-04, -4.3092e-04],\n",
      "          [ 2.3966e-04,  3.6277e-04,  5.6567e-04,  ...,  3.7101e-04,\n",
      "            6.0180e-05, -4.5363e-04],\n",
      "          [-8.3369e-04, -6.9912e-04, -6.1809e-04,  ..., -1.1463e-03,\n",
      "           -1.0825e-03, -1.5002e-03]],\n",
      "\n",
      "         [[ 1.0081e-04,  1.0671e-04,  4.6804e-05,  ..., -3.2563e-04,\n",
      "           -5.5661e-04, -8.0815e-04],\n",
      "          [ 1.0391e-04,  1.8016e-04,  1.1455e-04,  ..., -1.0281e-04,\n",
      "           -5.4600e-04, -7.0288e-04],\n",
      "          [ 4.3082e-04,  6.9320e-04,  8.6008e-04,  ...,  1.5228e-05,\n",
      "           -3.4023e-04, -5.7665e-04],\n",
      "          ...,\n",
      "          [ 6.1871e-04,  6.8057e-04,  7.5218e-04,  ...,  3.2388e-04,\n",
      "            1.2566e-04, -2.8877e-04],\n",
      "          [ 2.5949e-04,  4.7962e-04,  7.3529e-04,  ...,  2.4170e-04,\n",
      "            4.6579e-05, -2.7530e-04],\n",
      "          [-4.6367e-04, -3.2905e-04, -1.8385e-04,  ..., -7.1937e-04,\n",
      "           -6.4313e-04, -9.1602e-04]],\n",
      "\n",
      "         [[ 2.0738e-04,  3.1225e-04,  3.4789e-04,  ..., -3.4907e-05,\n",
      "           -2.8907e-04, -5.2058e-04],\n",
      "          [ 1.3546e-04,  3.4878e-04,  4.4192e-04,  ...,  8.1437e-05,\n",
      "           -2.9167e-04, -4.3171e-04],\n",
      "          [ 4.5572e-04,  6.9124e-04,  1.1409e-03,  ...,  3.2340e-04,\n",
      "            1.0823e-04, -3.1536e-04],\n",
      "          ...,\n",
      "          [ 5.2611e-04,  5.1698e-04,  6.5328e-04,  ...,  4.7978e-04,\n",
      "            2.9265e-04, -2.9602e-04],\n",
      "          [ 3.4059e-04,  3.9579e-04,  5.8305e-04,  ...,  3.3679e-04,\n",
      "            1.6376e-04, -3.2893e-04],\n",
      "          [-5.0818e-04, -4.4607e-04, -5.1731e-04,  ..., -8.8262e-04,\n",
      "           -7.9458e-04, -1.1084e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3983e-04,  3.4568e-04,  3.5409e-04,  ...,  3.7123e-04,\n",
      "            4.0857e-04,  4.0264e-04],\n",
      "          [ 2.9563e-04,  3.2795e-04,  3.7592e-04,  ...,  4.2943e-04,\n",
      "            4.4007e-04,  4.0672e-04],\n",
      "          [-2.4208e-04, -2.2353e-04, -1.6791e-04,  ..., -2.7462e-05,\n",
      "           -4.9006e-05, -1.1197e-04],\n",
      "          ...,\n",
      "          [ 1.4007e-06,  4.5509e-05,  6.1367e-05,  ...,  2.0572e-04,\n",
      "            3.8977e-05, -4.1371e-05],\n",
      "          [ 6.3282e-05,  4.5305e-05,  7.8695e-05,  ...,  1.7275e-04,\n",
      "            4.0413e-05, -4.7975e-05],\n",
      "          [ 2.0145e-05,  2.1353e-05,  1.8873e-04,  ...,  9.6914e-05,\n",
      "           -1.4873e-06, -5.6753e-05]],\n",
      "\n",
      "         [[ 2.8010e-04,  2.6344e-04,  2.6156e-04,  ...,  2.5735e-04,\n",
      "            2.8345e-04,  2.9959e-04],\n",
      "          [ 2.3767e-04,  2.4882e-04,  2.8035e-04,  ...,  3.2706e-04,\n",
      "            3.4297e-04,  3.3699e-04],\n",
      "          [-3.1081e-04, -3.1006e-04, -2.6567e-04,  ..., -1.7216e-05,\n",
      "           -2.4996e-05, -7.2342e-05],\n",
      "          ...,\n",
      "          [ 3.9120e-05,  1.1623e-04,  1.9606e-04,  ...,  1.8274e-04,\n",
      "            5.7256e-05, -1.3929e-05],\n",
      "          [ 1.4193e-04,  1.6734e-04,  2.4354e-04,  ...,  1.5833e-04,\n",
      "            6.6555e-05,  5.0662e-06],\n",
      "          [ 5.9748e-05,  9.0564e-05,  2.1771e-04,  ...,  8.9840e-05,\n",
      "            3.8567e-05, -8.3484e-06]],\n",
      "\n",
      "         [[ 3.9140e-04,  3.8196e-04,  3.5094e-04,  ...,  3.8486e-04,\n",
      "            3.9736e-04,  4.0107e-04],\n",
      "          [ 3.6574e-04,  3.6017e-04,  3.6985e-04,  ...,  4.2428e-04,\n",
      "            4.2805e-04,  4.1933e-04],\n",
      "          [-1.9269e-04, -2.1000e-04, -1.7242e-04,  ..., -1.0413e-05,\n",
      "           -2.2394e-05, -5.0535e-05],\n",
      "          ...,\n",
      "          [ 3.5944e-05,  6.6964e-05,  1.1633e-04,  ...,  2.0247e-04,\n",
      "            9.8824e-05,  1.4972e-05],\n",
      "          [ 9.0590e-05,  1.1473e-04,  1.9420e-04,  ...,  1.6996e-04,\n",
      "            9.8408e-05,  3.2996e-05],\n",
      "          [ 4.7948e-05,  9.7435e-05,  2.0884e-04,  ...,  9.4580e-05,\n",
      "            5.7982e-05,  1.4963e-05]]]]), 'exp_avg_sq': tensor([[[[1.1202e-04, 1.1295e-04, 1.2335e-04,  ..., 1.2629e-04,\n",
      "           1.2077e-04, 1.2992e-04],\n",
      "          [1.0944e-04, 1.1294e-04, 1.2813e-04,  ..., 1.3167e-04,\n",
      "           1.2733e-04, 1.4100e-04],\n",
      "          [1.2868e-04, 1.3170e-04, 1.4837e-04,  ..., 1.4828e-04,\n",
      "           1.4389e-04, 1.4502e-04],\n",
      "          ...,\n",
      "          [1.1774e-04, 1.2843e-04, 1.4330e-04,  ..., 1.7919e-04,\n",
      "           1.7382e-04, 1.5715e-04],\n",
      "          [1.2241e-04, 1.2457e-04, 1.3699e-04,  ..., 1.7783e-04,\n",
      "           1.7478e-04, 1.4912e-04],\n",
      "          [1.3554e-04, 1.2619e-04, 1.4093e-04,  ..., 1.7086e-04,\n",
      "           1.6995e-04, 1.4469e-04]],\n",
      "\n",
      "         [[1.0523e-04, 1.0627e-04, 1.0619e-04,  ..., 1.0384e-04,\n",
      "           9.9245e-05, 1.0256e-04],\n",
      "          [1.0543e-04, 1.0865e-04, 1.1200e-04,  ..., 1.0837e-04,\n",
      "           1.0491e-04, 1.0936e-04],\n",
      "          [1.0690e-04, 1.1059e-04, 1.1716e-04,  ..., 1.0880e-04,\n",
      "           1.0489e-04, 1.0861e-04],\n",
      "          ...,\n",
      "          [1.0939e-04, 1.1515e-04, 1.1646e-04,  ..., 1.1489e-04,\n",
      "           1.1611e-04, 1.0842e-04],\n",
      "          [1.1439e-04, 1.1384e-04, 1.1395e-04,  ..., 1.1843e-04,\n",
      "           1.1969e-04, 1.0812e-04],\n",
      "          [1.2304e-04, 1.1892e-04, 1.2149e-04,  ..., 1.2382e-04,\n",
      "           1.2100e-04, 1.1395e-04]],\n",
      "\n",
      "         [[8.0803e-05, 7.9634e-05, 9.2031e-05,  ..., 9.2936e-05,\n",
      "           8.9565e-05, 9.8856e-05],\n",
      "          [7.9724e-05, 8.0003e-05, 9.4913e-05,  ..., 9.8714e-05,\n",
      "           9.7108e-05, 1.0511e-04],\n",
      "          [9.0551e-05, 9.0247e-05, 1.0424e-04,  ..., 1.1160e-04,\n",
      "           1.1037e-04, 1.1419e-04],\n",
      "          ...,\n",
      "          [8.3565e-05, 8.8034e-05, 1.0367e-04,  ..., 1.4786e-04,\n",
      "           1.4360e-04, 1.2666e-04],\n",
      "          [8.7010e-05, 8.7952e-05, 1.0276e-04,  ..., 1.4369e-04,\n",
      "           1.4455e-04, 1.2386e-04],\n",
      "          [1.0163e-04, 9.8916e-05, 1.1319e-04,  ..., 1.3678e-04,\n",
      "           1.3582e-04, 1.2165e-04]]],\n",
      "\n",
      "\n",
      "        [[[7.0197e-06, 6.6507e-06, 6.4542e-06,  ..., 9.9780e-06,\n",
      "           1.1013e-05, 1.1827e-05],\n",
      "          [7.4421e-06, 6.9376e-06, 6.5403e-06,  ..., 9.4418e-06,\n",
      "           1.1715e-05, 1.2214e-05],\n",
      "          [8.8110e-06, 8.3963e-06, 7.1111e-06,  ..., 7.3744e-06,\n",
      "           9.3447e-06, 9.8037e-06],\n",
      "          ...,\n",
      "          [9.3523e-06, 9.7194e-06, 1.0498e-05,  ..., 9.2170e-06,\n",
      "           9.4856e-06, 9.7015e-06],\n",
      "          [1.3178e-05, 1.3793e-05, 1.3229e-05,  ..., 1.0640e-05,\n",
      "           1.1192e-05, 1.2160e-05],\n",
      "          [1.3855e-05, 1.3908e-05, 1.3012e-05,  ..., 1.2272e-05,\n",
      "           1.2355e-05, 1.1471e-05]],\n",
      "\n",
      "         [[4.6093e-06, 4.7279e-06, 4.3478e-06,  ..., 1.0834e-05,\n",
      "           1.1387e-05, 1.0840e-05],\n",
      "          [3.7020e-06, 4.2956e-06, 3.9853e-06,  ..., 1.0832e-05,\n",
      "           1.1812e-05, 1.0831e-05],\n",
      "          [3.3772e-06, 3.3215e-06, 3.3925e-06,  ..., 9.9687e-06,\n",
      "           1.1015e-05, 1.0451e-05],\n",
      "          ...,\n",
      "          [3.4544e-06, 3.3591e-06, 3.5058e-06,  ..., 8.4603e-06,\n",
      "           6.8529e-06, 3.7719e-06],\n",
      "          [7.0446e-06, 5.8846e-06, 5.0365e-06,  ..., 1.0894e-05,\n",
      "           1.1934e-05, 6.9883e-06],\n",
      "          [9.8793e-06, 9.2792e-06, 8.1537e-06,  ..., 1.4052e-05,\n",
      "           1.3490e-05, 8.2890e-06]],\n",
      "\n",
      "         [[5.0239e-06, 4.9590e-06, 4.5449e-06,  ..., 6.8627e-06,\n",
      "           7.0467e-06, 6.7782e-06],\n",
      "          [5.0997e-06, 4.8447e-06, 4.4273e-06,  ..., 5.6148e-06,\n",
      "           6.1946e-06, 6.3178e-06],\n",
      "          [5.2996e-06, 4.9048e-06, 4.3921e-06,  ..., 3.7060e-06,\n",
      "           4.2729e-06, 5.5673e-06],\n",
      "          ...,\n",
      "          [6.0346e-06, 5.8564e-06, 5.9903e-06,  ..., 8.3257e-06,\n",
      "           7.2450e-06, 6.3928e-06],\n",
      "          [9.0424e-06, 8.2875e-06, 7.6532e-06,  ..., 1.1193e-05,\n",
      "           1.0948e-05, 1.0068e-05],\n",
      "          [1.1024e-05, 1.0933e-05, 1.0252e-05,  ..., 1.4226e-05,\n",
      "           1.2276e-05, 1.2199e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.6315e-05, 3.2275e-05, 2.9947e-05,  ..., 2.4191e-05,\n",
      "           2.8477e-05, 3.8669e-05],\n",
      "          [3.7337e-05, 2.9825e-05, 2.6655e-05,  ..., 2.2941e-05,\n",
      "           2.6997e-05, 3.7055e-05],\n",
      "          [2.0061e-05, 1.9095e-05, 1.8552e-05,  ..., 2.1326e-05,\n",
      "           2.3066e-05, 3.0829e-05],\n",
      "          ...,\n",
      "          [4.2527e-05, 3.2891e-05, 2.3463e-05,  ..., 6.6642e-05,\n",
      "           7.0142e-05, 5.7226e-05],\n",
      "          [4.6250e-05, 3.9304e-05, 2.9205e-05,  ..., 5.8220e-05,\n",
      "           6.6024e-05, 5.5767e-05],\n",
      "          [5.8578e-05, 5.5095e-05, 4.2774e-05,  ..., 6.5691e-05,\n",
      "           7.6049e-05, 5.9421e-05]],\n",
      "\n",
      "         [[2.8715e-05, 2.7111e-05, 2.3351e-05,  ..., 1.6365e-05,\n",
      "           1.9266e-05, 2.4208e-05],\n",
      "          [3.2782e-05, 2.8826e-05, 2.5327e-05,  ..., 1.5794e-05,\n",
      "           1.8092e-05, 2.2527e-05],\n",
      "          [2.2882e-05, 2.1846e-05, 1.8992e-05,  ..., 8.9324e-06,\n",
      "           9.4571e-06, 1.5906e-05],\n",
      "          ...,\n",
      "          [2.2682e-05, 2.2726e-05, 2.5451e-05,  ..., 2.0117e-05,\n",
      "           2.0481e-05, 2.2361e-05],\n",
      "          [2.0931e-05, 2.2168e-05, 2.5469e-05,  ..., 2.0894e-05,\n",
      "           2.0249e-05, 2.1197e-05],\n",
      "          [2.2253e-05, 2.2295e-05, 2.6279e-05,  ..., 2.3372e-05,\n",
      "           2.5259e-05, 2.4222e-05]],\n",
      "\n",
      "         [[2.4010e-05, 2.1701e-05, 2.0021e-05,  ..., 1.7574e-05,\n",
      "           2.0036e-05, 2.7220e-05],\n",
      "          [2.4205e-05, 2.0149e-05, 1.9186e-05,  ..., 1.6527e-05,\n",
      "           1.9389e-05, 2.6871e-05],\n",
      "          [1.7775e-05, 1.6690e-05, 1.4571e-05,  ..., 1.3572e-05,\n",
      "           1.5375e-05, 2.2097e-05],\n",
      "          ...,\n",
      "          [4.4893e-05, 4.0671e-05, 2.9793e-05,  ..., 3.9718e-05,\n",
      "           4.4399e-05, 3.7842e-05],\n",
      "          [4.7525e-05, 4.4556e-05, 3.3979e-05,  ..., 3.8571e-05,\n",
      "           4.3496e-05, 3.7874e-05],\n",
      "          [5.8706e-05, 5.5733e-05, 4.3200e-05,  ..., 4.8331e-05,\n",
      "           5.4690e-05, 4.3656e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[6.5410e-06, 6.3839e-06, 6.9804e-06,  ..., 5.6612e-06,\n",
      "           5.9381e-06, 4.7311e-06],\n",
      "          [6.4988e-06, 6.3877e-06, 6.8716e-06,  ..., 6.1309e-06,\n",
      "           6.8317e-06, 4.8939e-06],\n",
      "          [3.6745e-06, 3.6462e-06, 3.9742e-06,  ..., 5.0323e-06,\n",
      "           5.5727e-06, 4.1634e-06],\n",
      "          ...,\n",
      "          [3.8327e-06, 3.6312e-06, 5.0221e-06,  ..., 6.1792e-06,\n",
      "           5.2908e-06, 4.5147e-06],\n",
      "          [4.0559e-06, 3.7424e-06, 5.0239e-06,  ..., 5.2178e-06,\n",
      "           4.4767e-06, 4.5101e-06],\n",
      "          [9.4121e-06, 9.5677e-06, 1.1121e-05,  ..., 8.6180e-06,\n",
      "           8.9307e-06, 7.6194e-06]],\n",
      "\n",
      "         [[4.5088e-06, 4.4978e-06, 3.4491e-06,  ..., 2.7586e-06,\n",
      "           2.8223e-06, 3.6525e-06],\n",
      "          [4.6769e-06, 4.9266e-06, 3.9152e-06,  ..., 2.9739e-06,\n",
      "           3.0894e-06, 3.7917e-06],\n",
      "          [2.6539e-06, 2.6969e-06, 2.0523e-06,  ..., 2.6724e-06,\n",
      "           2.8663e-06, 3.0347e-06],\n",
      "          ...,\n",
      "          [1.9559e-06, 1.9640e-06, 2.2319e-06,  ..., 2.3031e-06,\n",
      "           2.1297e-06, 2.8387e-06],\n",
      "          [1.9925e-06, 1.9820e-06, 2.2256e-06,  ..., 1.9930e-06,\n",
      "           1.8899e-06, 2.9745e-06],\n",
      "          [6.8505e-06, 7.4427e-06, 9.5286e-06,  ..., 7.8131e-06,\n",
      "           7.5773e-06, 6.7749e-06]],\n",
      "\n",
      "         [[4.6836e-06, 5.0968e-06, 4.7146e-06,  ..., 3.5915e-06,\n",
      "           3.8055e-06, 3.2875e-06],\n",
      "          [5.0840e-06, 5.4807e-06, 5.5090e-06,  ..., 3.7046e-06,\n",
      "           4.0238e-06, 3.4543e-06],\n",
      "          [3.0572e-06, 3.1063e-06, 3.4528e-06,  ..., 3.5758e-06,\n",
      "           3.9777e-06, 3.1178e-06],\n",
      "          ...,\n",
      "          [3.2118e-06, 3.2863e-06, 4.1804e-06,  ..., 4.7236e-06,\n",
      "           4.4937e-06, 3.6192e-06],\n",
      "          [3.2899e-06, 3.3205e-06, 4.1504e-06,  ..., 3.9258e-06,\n",
      "           3.7787e-06, 3.4852e-06],\n",
      "          [7.2007e-06, 7.4750e-06, 8.8401e-06,  ..., 6.9686e-06,\n",
      "           6.8522e-06, 5.6578e-06]]],\n",
      "\n",
      "\n",
      "        [[[2.6772e-05, 2.8258e-05, 2.1497e-05,  ..., 1.8065e-05,\n",
      "           2.0503e-05, 2.0272e-05],\n",
      "          [2.9891e-05, 2.9481e-05, 2.1091e-05,  ..., 1.8328e-05,\n",
      "           2.1240e-05, 1.9673e-05],\n",
      "          [5.3381e-05, 5.5079e-05, 4.1084e-05,  ..., 3.2507e-05,\n",
      "           3.5036e-05, 2.5990e-05],\n",
      "          ...,\n",
      "          [6.0567e-05, 6.0805e-05, 5.1386e-05,  ..., 4.5911e-05,\n",
      "           4.5501e-05, 3.1161e-05],\n",
      "          [6.1496e-05, 6.5046e-05, 5.5860e-05,  ..., 4.7536e-05,\n",
      "           4.6108e-05, 3.0863e-05],\n",
      "          [6.8606e-05, 7.1913e-05, 7.1130e-05,  ..., 6.2631e-05,\n",
      "           5.9394e-05, 4.6601e-05]],\n",
      "\n",
      "         [[2.7637e-05, 2.8097e-05, 1.7941e-05,  ..., 1.5825e-05,\n",
      "           1.6695e-05, 2.1979e-05],\n",
      "          [3.0151e-05, 2.9043e-05, 1.7733e-05,  ..., 1.7359e-05,\n",
      "           1.7766e-05, 2.1632e-05],\n",
      "          [3.8521e-05, 3.9854e-05, 2.8469e-05,  ..., 2.2471e-05,\n",
      "           2.2601e-05, 2.2018e-05],\n",
      "          ...,\n",
      "          [4.2879e-05, 4.1119e-05, 3.0263e-05,  ..., 2.8715e-05,\n",
      "           2.7942e-05, 2.3430e-05],\n",
      "          [4.4524e-05, 4.6467e-05, 3.4367e-05,  ..., 3.0659e-05,\n",
      "           3.0235e-05, 2.4672e-05],\n",
      "          [4.5567e-05, 4.6916e-05, 3.8840e-05,  ..., 3.5653e-05,\n",
      "           3.4481e-05, 3.2333e-05]],\n",
      "\n",
      "         [[1.9546e-05, 1.9463e-05, 1.5575e-05,  ..., 1.4801e-05,\n",
      "           1.4890e-05, 1.5412e-05],\n",
      "          [2.0494e-05, 1.9995e-05, 1.4835e-05,  ..., 1.4573e-05,\n",
      "           1.5607e-05, 1.4677e-05],\n",
      "          [3.6056e-05, 3.7327e-05, 3.0778e-05,  ..., 2.5107e-05,\n",
      "           2.7145e-05, 1.8005e-05],\n",
      "          ...,\n",
      "          [4.3346e-05, 4.4457e-05, 4.2388e-05,  ..., 3.8343e-05,\n",
      "           3.7843e-05, 2.1897e-05],\n",
      "          [4.5493e-05, 4.8664e-05, 4.6185e-05,  ..., 4.0486e-05,\n",
      "           3.9228e-05, 2.3314e-05],\n",
      "          [5.3421e-05, 5.5975e-05, 5.8678e-05,  ..., 5.2179e-05,\n",
      "           5.0742e-05, 3.9388e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.6677e-06, 1.6838e-06, 2.6800e-06,  ..., 5.7667e-06,\n",
      "           5.4382e-06, 3.5767e-06],\n",
      "          [1.6369e-06, 1.6454e-06, 2.8983e-06,  ..., 5.8912e-06,\n",
      "           5.5760e-06, 3.7346e-06],\n",
      "          [2.1777e-06, 2.3601e-06, 6.2523e-06,  ..., 8.0030e-06,\n",
      "           8.2081e-06, 5.8356e-06],\n",
      "          ...,\n",
      "          [2.0544e-06, 1.9974e-06, 3.2308e-06,  ..., 4.8603e-06,\n",
      "           4.1926e-06, 2.8928e-06],\n",
      "          [2.0621e-06, 2.0409e-06, 3.6011e-06,  ..., 4.5342e-06,\n",
      "           3.9419e-06, 2.8431e-06],\n",
      "          [1.9009e-06, 1.8815e-06, 3.5617e-06,  ..., 4.0564e-06,\n",
      "           3.2971e-06, 2.3606e-06]],\n",
      "\n",
      "         [[1.3509e-06, 1.6510e-06, 3.4886e-06,  ..., 6.3542e-06,\n",
      "           5.8960e-06, 3.9445e-06],\n",
      "          [1.2603e-06, 1.4459e-06, 3.5356e-06,  ..., 6.4851e-06,\n",
      "           5.8144e-06, 3.9183e-06],\n",
      "          [2.3748e-06, 2.7372e-06, 6.3462e-06,  ..., 7.3112e-06,\n",
      "           7.2863e-06, 5.4181e-06],\n",
      "          ...,\n",
      "          [2.6503e-06, 2.7192e-06, 4.0137e-06,  ..., 5.7172e-06,\n",
      "           4.5913e-06, 2.2533e-06],\n",
      "          [2.5693e-06, 2.6571e-06, 4.9513e-06,  ..., 5.6069e-06,\n",
      "           3.9730e-06, 2.1532e-06],\n",
      "          [2.4927e-06, 2.5808e-06, 4.9237e-06,  ..., 5.4124e-06,\n",
      "           4.0166e-06, 1.9430e-06]],\n",
      "\n",
      "         [[1.5674e-06, 1.6061e-06, 2.2977e-06,  ..., 4.5061e-06,\n",
      "           4.4555e-06, 3.0166e-06],\n",
      "          [1.6512e-06, 1.6199e-06, 2.3527e-06,  ..., 4.6942e-06,\n",
      "           4.5174e-06, 3.0464e-06],\n",
      "          [2.0274e-06, 2.0596e-06, 4.6373e-06,  ..., 6.1270e-06,\n",
      "           6.3429e-06, 4.5686e-06],\n",
      "          ...,\n",
      "          [2.1550e-06, 2.2703e-06, 3.2677e-06,  ..., 4.5606e-06,\n",
      "           3.8289e-06, 2.3616e-06],\n",
      "          [2.2747e-06, 2.3196e-06, 3.7445e-06,  ..., 4.5406e-06,\n",
      "           3.6662e-06, 2.2381e-06],\n",
      "          [1.8125e-06, 1.8013e-06, 3.1312e-06,  ..., 3.6764e-06,\n",
      "           3.2031e-06, 1.7949e-06]]]])}, 1: {'step': 18912, 'exp_avg': tensor([ 6.9386e-04,  2.5518e-04,  3.2746e-04,  2.3893e-06,  3.0528e-04,\n",
      "         9.9356e-05,  2.2956e-04,  7.6738e-04,  5.5227e-06, -2.2919e-05,\n",
      "        -3.4908e-04,  1.2375e-04,  5.0970e-05,  2.9497e-04,  2.8990e-04,\n",
      "         3.4084e-04,  3.5904e-04, -3.8103e-04, -1.7878e-04, -1.3503e-04,\n",
      "         5.0852e-04,  4.0211e-04, -2.8593e-04, -1.7531e-04, -3.1235e-05,\n",
      "        -1.3186e-05,  4.1141e-04,  8.7291e-05,  1.0612e-04, -1.6654e-04,\n",
      "        -4.2144e-05,  1.6630e-05,  7.8816e-05,  1.2051e-04, -8.3431e-04,\n",
      "        -3.5772e-04,  3.9506e-04,  3.9882e-04,  6.1619e-04,  7.5000e-04,\n",
      "         4.7119e-04,  1.2243e-04,  1.1953e-03, -8.3084e-06, -3.2798e-05,\n",
      "         4.1384e-04, -3.1770e-04, -1.8829e-04, -1.1702e-05,  2.1170e-04,\n",
      "         5.6351e-04,  3.3124e-04,  1.7313e-04, -1.9397e-04, -7.2727e-04,\n",
      "         8.9028e-04, -1.8473e-04,  1.0527e-04, -8.1421e-04,  5.4250e-04,\n",
      "        -1.0453e-04, -2.2357e-05,  1.4084e-04, -8.7987e-06]), 'exp_avg_sq': tensor([5.2210e-05, 4.0420e-06, 1.6697e-05, 4.8416e-06, 1.6383e-05, 5.3683e-06,\n",
      "        2.4673e-06, 1.8352e-05, 1.2519e-07, 8.7246e-07, 7.7756e-06, 1.1724e-05,\n",
      "        5.9626e-06, 5.1644e-06, 9.1117e-06, 2.6802e-05, 1.6016e-05, 6.8867e-06,\n",
      "        7.5858e-06, 2.7305e-07, 1.0966e-05, 1.1506e-05, 1.8134e-06, 4.6545e-06,\n",
      "        1.6777e-06, 5.0386e-06, 1.2933e-05, 1.2280e-06, 3.8050e-06, 2.0439e-06,\n",
      "        1.6185e-06, 3.3943e-05, 2.6152e-06, 7.1967e-06, 6.1691e-06, 3.6580e-06,\n",
      "        7.5929e-05, 2.2563e-06, 5.1519e-05, 4.1363e-05, 1.1401e-05, 3.9178e-06,\n",
      "        1.6959e-05, 3.5501e-06, 1.5423e-05, 1.1940e-05, 4.5517e-06, 8.2282e-06,\n",
      "        7.1745e-06, 6.6476e-06, 6.3498e-06, 9.1958e-07, 1.3851e-04, 3.9922e-06,\n",
      "        1.1170e-05, 3.1235e-05, 6.6382e-06, 1.2106e-05, 1.4449e-04, 3.6815e-05,\n",
      "        1.0400e-06, 2.2164e-06, 1.4539e-05, 2.3217e-06])}, 2: {'step': 18912, 'exp_avg': tensor([[[[-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-2.8785e-14,  5.6128e-14,  3.1795e-09, -7.7153e-08, -2.2219e-06],\n",
      "          [-3.3575e-14,  2.4045e-14, -3.1952e-07, -1.4499e-06, -1.5195e-06],\n",
      "          [-3.1870e-17, -5.1789e-08,  6.7383e-05,  5.8437e-05,  1.3109e-04],\n",
      "          [ 1.2573e-21,  1.9488e-06,  1.3560e-04,  2.3835e-04,  2.7182e-04],\n",
      "          [ 2.4699e-20, -4.0362e-07,  1.1461e-04,  8.5378e-05,  3.0720e-05]],\n",
      "\n",
      "         [[ 1.0273e-18, -2.0518e-13, -3.2264e-14,  1.7321e-13,  8.2975e-11],\n",
      "          [-1.1883e-16,  2.9272e-10,  6.7431e-10, -8.7115e-09, -4.1917e-07],\n",
      "          [-1.3375e-12, -1.1617e-07, -1.0063e-07,  3.1838e-07, -1.0455e-07],\n",
      "          [-1.5504e-12,  1.6153e-06,  6.0159e-07, -1.9218e-06, -4.5401e-06],\n",
      "          [-2.3183e-13,  5.1960e-06,  3.7128e-06,  5.4858e-07,  3.9949e-05]],\n",
      "\n",
      "         [[-4.1539e-12,  4.8001e-11, -2.7592e-07, -1.7409e-06, -8.1367e-07],\n",
      "          [-2.9797e-12,  1.0393e-10, -3.5266e-07, -3.8320e-06, -3.5551e-06],\n",
      "          [-6.1624e-13, -3.1340e-08,  1.1853e-04,  1.5471e-05,  1.2923e-04],\n",
      "          [-2.7085e-17, -2.9415e-07,  1.0599e-04,  6.8591e-05,  2.7873e-04],\n",
      "          [-2.1726e-17,  2.0598e-07,  8.6128e-05,  1.2547e-04,  2.2363e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9538e-12, -2.9218e-12,  1.8139e-08, -3.0365e-07, -1.6301e-06],\n",
      "          [-3.0139e-12, -2.9529e-12,  1.1364e-12,  4.7537e-10, -5.3561e-09],\n",
      "          [-1.3014e-11, -1.0919e-08,  3.5853e-05, -6.9585e-06,  2.8130e-05],\n",
      "          [-1.2947e-11,  4.0250e-07, -1.4093e-06,  1.7567e-04,  1.8939e-04],\n",
      "          [ 4.5033e-24, -1.5414e-12,  3.1865e-07, -1.1155e-05, -1.8287e-05]],\n",
      "\n",
      "         [[-6.0385e-12,  9.6392e-11, -1.0525e-07, -3.5372e-06, -7.1816e-06],\n",
      "          [-2.8297e-12,  1.0235e-12, -4.7930e-07, -1.4542e-06, -1.2007e-06],\n",
      "          [-5.5913e-12, -9.7573e-08,  1.4576e-04,  1.2612e-04,  1.9354e-04],\n",
      "          [-5.5883e-12,  1.4890e-06,  6.4335e-05,  3.5348e-04,  4.5154e-04],\n",
      "          [ 4.2310e-21, -6.9714e-07,  4.4805e-05,  2.9545e-05, -1.1000e-05]],\n",
      "\n",
      "         [[-8.1815e-13, -8.1815e-13,  6.7332e-19,  6.6363e-18,  1.3637e-13],\n",
      "          [-8.1815e-13, -8.1815e-13, -8.5670e-20,  2.2036e-11,  1.9512e-11],\n",
      "          [-6.8353e-13, -2.8591e-16, -8.7553e-07, -2.0318e-06, -2.3787e-06],\n",
      "          [-5.6052e-45, -3.6608e-08, -7.5562e-07,  2.8993e-05, -2.6365e-05],\n",
      "          [ 5.6052e-45, -3.6608e-08,  1.0526e-07,  3.3524e-05, -2.7464e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]]]]), 'exp_avg_sq': tensor([[[[3.5971e-14, 2.7185e-14, 1.9694e-14, 1.2368e-14, 1.3840e-14],\n",
      "          [1.2923e-14, 5.5359e-14, 5.5180e-14, 1.0608e-14, 9.8523e-15],\n",
      "          [1.2503e-14, 4.3194e-14, 4.2535e-14, 8.0471e-15, 1.1804e-14],\n",
      "          [1.2338e-14, 9.4661e-15, 8.1340e-15, 8.4145e-15, 1.2481e-14],\n",
      "          [1.3285e-14, 1.0231e-14, 8.7893e-15, 9.7763e-15, 1.1492e-14]],\n",
      "\n",
      "         [[1.9467e-12, 1.9701e-12, 1.9527e-12, 1.8116e-12, 2.0865e-12],\n",
      "          [1.6262e-12, 1.6836e-12, 1.7435e-12, 1.6134e-12, 1.8989e-12],\n",
      "          [1.8702e-12, 1.9293e-12, 2.1297e-12, 1.8033e-12, 2.1441e-12],\n",
      "          [2.2297e-12, 2.3249e-12, 2.4133e-12, 2.2285e-12, 2.7124e-12],\n",
      "          [2.2939e-12, 2.4121e-12, 2.5186e-12, 2.3511e-12, 2.7978e-12]],\n",
      "\n",
      "         [[4.4973e-15, 6.2828e-15, 5.4843e-15, 5.3653e-15, 1.3570e-15],\n",
      "          [9.0103e-15, 3.3668e-15, 6.5937e-15, 6.0610e-15, 1.2648e-15],\n",
      "          [1.8933e-14, 9.6695e-15, 5.2025e-15, 1.1951e-15, 2.9799e-16],\n",
      "          [1.1225e-14, 1.5880e-14, 1.0166e-14, 2.5032e-15, 1.4894e-15],\n",
      "          [3.3795e-15, 8.7133e-15, 3.9445e-15, 1.8965e-15, 7.5738e-16]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3533e-14, 5.4348e-16, 2.4120e-16, 1.1657e-16, 4.3687e-16],\n",
      "          [2.7552e-14, 2.2719e-14, 2.3973e-14, 1.3424e-15, 2.2801e-16],\n",
      "          [2.2088e-14, 2.8676e-14, 2.9720e-14, 4.3929e-15, 1.6967e-15],\n",
      "          [4.2627e-15, 1.2249e-14, 1.4919e-14, 9.5797e-15, 3.4518e-15],\n",
      "          [4.1015e-15, 5.0092e-15, 1.0388e-14, 9.1346e-15, 4.9407e-15]],\n",
      "\n",
      "         [[6.5725e-14, 6.1129e-14, 6.2442e-14, 5.7559e-14, 6.1010e-14],\n",
      "          [5.7394e-14, 5.8995e-14, 5.2954e-14, 4.7571e-14, 5.5570e-14],\n",
      "          [2.0633e-14, 2.8197e-14, 2.7387e-14, 1.8188e-14, 2.6993e-14],\n",
      "          [8.0100e-14, 6.7272e-14, 6.6956e-14, 6.7027e-14, 7.9659e-14],\n",
      "          [1.1888e-13, 1.1582e-13, 1.0818e-13, 1.2562e-13, 1.5113e-13]],\n",
      "\n",
      "         [[6.5776e-16, 1.9155e-16, 1.1697e-16, 5.8040e-17, 2.9834e-17],\n",
      "          [4.1511e-16, 1.9987e-16, 1.4859e-15, 1.5102e-15, 1.3931e-17],\n",
      "          [2.5869e-16, 2.3483e-16, 1.2227e-15, 1.2455e-15, 2.8496e-17],\n",
      "          [1.7955e-16, 1.3166e-16, 2.0602e-16, 2.0854e-16, 5.2316e-17],\n",
      "          [1.6871e-16, 1.0350e-16, 1.3554e-16, 1.2066e-16, 5.5872e-17]]],\n",
      "\n",
      "\n",
      "        [[[4.9146e-11, 1.5938e-11, 1.5088e-11, 6.0590e-11, 8.3472e-12],\n",
      "          [5.8176e-11, 9.5743e-12, 5.9706e-12, 1.0748e-11, 7.9265e-12],\n",
      "          [2.9835e-11, 1.1488e-11, 1.2410e-11, 4.6038e-11, 1.4484e-11],\n",
      "          [1.6535e-11, 8.7632e-12, 6.9272e-12, 3.4460e-11, 1.4129e-11],\n",
      "          [6.6466e-12, 5.4939e-12, 5.5536e-12, 1.3806e-11, 1.2259e-11]],\n",
      "\n",
      "         [[3.5572e-13, 2.0412e-12, 2.1746e-12, 5.5380e-13, 7.6750e-13],\n",
      "          [3.8502e-13, 7.2249e-12, 1.0028e-12, 4.8215e-13, 1.0388e-12],\n",
      "          [1.2524e-13, 7.0215e-12, 8.2692e-13, 6.8519e-13, 7.7923e-13],\n",
      "          [2.3370e-13, 3.4248e-13, 8.5005e-13, 1.0764e-12, 6.5543e-13],\n",
      "          [2.3226e-13, 2.6760e-13, 4.4841e-13, 5.6239e-13, 5.1845e-13]],\n",
      "\n",
      "         [[4.3996e-11, 9.5414e-12, 2.1791e-11, 2.6541e-11, 6.5543e-12],\n",
      "          [3.8537e-11, 1.1439e-11, 3.2033e-11, 3.8556e-11, 4.9045e-12],\n",
      "          [5.7753e-11, 1.3161e-11, 1.7750e-11, 2.2359e-11, 2.9980e-12],\n",
      "          [4.8554e-11, 4.6138e-11, 9.0438e-12, 9.8794e-12, 5.1182e-12],\n",
      "          [1.2343e-12, 8.3930e-13, 9.0185e-13, 4.8046e-12, 3.0762e-12]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6122e-12, 3.8202e-12, 3.2856e-12, 8.4376e-12, 8.6419e-12],\n",
      "          [2.1501e-12, 2.4831e-12, 2.1399e-12, 8.0927e-13, 1.3289e-12],\n",
      "          [5.8564e-12, 1.5882e-11, 1.6237e-11, 1.9505e-11, 1.5474e-11],\n",
      "          [5.0456e-12, 1.3518e-11, 1.6013e-11, 1.9499e-11, 1.5805e-11],\n",
      "          [6.9479e-14, 1.1576e-13, 1.9347e-13, 9.3449e-13, 2.4008e-12]],\n",
      "\n",
      "         [[1.3476e-11, 1.3095e-11, 9.2977e-12, 1.3901e-11, 6.2707e-12],\n",
      "          [5.3441e-11, 1.2532e-11, 1.2365e-11, 9.7458e-12, 9.0899e-12],\n",
      "          [3.6988e-11, 1.3348e-11, 2.6385e-11, 3.0926e-11, 8.3625e-12],\n",
      "          [6.5242e-12, 3.4372e-12, 6.1939e-12, 1.5046e-11, 5.2582e-12],\n",
      "          [1.3735e-13, 8.0549e-14, 4.4175e-14, 1.8953e-12, 4.8265e-12]],\n",
      "\n",
      "         [[2.0573e-12, 4.9530e-12, 4.1862e-12, 1.1721e-12, 3.1273e-12],\n",
      "          [1.5816e-12, 4.0768e-12, 3.5864e-12, 7.1200e-13, 3.8565e-12],\n",
      "          [1.8122e-12, 1.6603e-12, 1.5946e-12, 9.7029e-13, 1.5902e-12],\n",
      "          [5.6628e-13, 5.2072e-13, 5.4205e-13, 8.7995e-13, 3.4916e-13],\n",
      "          [1.4967e-15, 2.3019e-15, 2.1024e-15, 1.0080e-13, 8.0458e-14]]],\n",
      "\n",
      "\n",
      "        [[[2.6609e-04, 2.7260e-04, 2.5659e-04, 2.5872e-04, 3.4702e-04],\n",
      "          [2.8742e-04, 2.7386e-04, 2.5165e-04, 2.5104e-04, 3.3638e-04],\n",
      "          [2.8462e-04, 2.6804e-04, 2.4896e-04, 2.4748e-04, 3.1986e-04],\n",
      "          [2.5103e-04, 2.5067e-04, 2.3709e-04, 1.5273e-04, 2.3826e-04],\n",
      "          [3.0366e-04, 2.7728e-04, 2.3488e-04, 2.0920e-04, 3.2593e-04]],\n",
      "\n",
      "         [[2.5593e-08, 1.0203e-09, 8.2819e-12, 4.6222e-09, 5.2996e-10],\n",
      "          [7.3105e-10, 1.3913e-09, 1.1086e-10, 7.9439e-11, 5.5683e-10],\n",
      "          [7.2954e-09, 1.0155e-09, 6.2271e-10, 2.2192e-09, 2.2876e-08],\n",
      "          [1.7519e-10, 8.0547e-10, 1.0324e-09, 1.6348e-08, 1.8089e-08],\n",
      "          [3.6814e-09, 1.0258e-09, 1.5578e-09, 1.3583e-08, 7.3648e-08]],\n",
      "\n",
      "         [[1.2818e-09, 3.5703e-08, 8.2150e-09, 4.9460e-07, 1.2690e-08],\n",
      "          [1.8880e-07, 1.1667e-07, 4.2609e-08, 9.4889e-07, 7.4883e-08],\n",
      "          [5.1842e-08, 7.7876e-08, 1.2155e-07, 1.0968e-06, 1.0140e-07],\n",
      "          [3.9314e-08, 3.1316e-07, 6.5407e-07, 1.5215e-05, 1.0931e-05],\n",
      "          [3.8799e-08, 4.5324e-07, 5.7125e-07, 1.5127e-05, 1.2605e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.9789e-09, 1.4497e-09, 1.5593e-10, 3.2914e-10, 1.1125e-09],\n",
      "          [1.1437e-08, 3.1557e-10, 4.5248e-11, 9.1180e-11, 1.6619e-09],\n",
      "          [1.4290e-08, 2.0215e-10, 3.4789e-09, 7.3971e-09, 1.4559e-08],\n",
      "          [2.9091e-08, 3.2857e-10, 3.3374e-09, 1.9287e-07, 6.0134e-08],\n",
      "          [2.4607e-08, 1.1871e-08, 7.1613e-09, 5.2421e-08, 3.3810e-06]],\n",
      "\n",
      "         [[4.9783e-09, 3.6900e-09, 2.3353e-08, 1.5982e-07, 3.1003e-07],\n",
      "          [5.4552e-07, 8.1174e-08, 4.0567e-08, 9.2717e-08, 1.1372e-07],\n",
      "          [3.7482e-09, 1.2011e-08, 2.0112e-07, 4.9461e-07, 5.2573e-07],\n",
      "          [2.6493e-07, 3.8435e-07, 3.3923e-07, 3.1822e-05, 4.1186e-05],\n",
      "          [8.6413e-07, 1.0348e-07, 3.0232e-08, 1.0695e-06, 3.5483e-07]],\n",
      "\n",
      "         [[4.5100e-11, 1.5548e-11, 9.3241e-14, 1.1083e-11, 1.9236e-10],\n",
      "          [7.0495e-10, 2.3281e-10, 1.0206e-13, 1.0099e-10, 8.9236e-11],\n",
      "          [1.5226e-09, 1.9246e-11, 6.8775e-11, 6.0235e-10, 4.8900e-10],\n",
      "          [7.0962e-11, 4.6944e-11, 1.1177e-09, 9.7254e-09, 1.0739e-08],\n",
      "          [2.6666e-13, 1.1899e-13, 1.8293e-10, 2.0240e-09, 6.7847e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[9.5083e-15, 9.9778e-15, 1.0954e-14, 1.2790e-14, 8.3478e-15],\n",
      "          [1.0041e-14, 1.1233e-14, 1.3376e-14, 1.8265e-14, 1.5530e-14],\n",
      "          [9.5642e-15, 1.0272e-14, 1.1774e-14, 1.2813e-14, 1.3099e-14],\n",
      "          [6.5768e-15, 6.9548e-15, 8.1138e-15, 9.4282e-15, 8.1541e-15],\n",
      "          [6.4583e-15, 6.7928e-15, 7.5623e-15, 9.8753e-15, 8.8644e-15]],\n",
      "\n",
      "         [[4.6816e-13, 4.5583e-13, 4.5934e-13, 4.5905e-13, 8.3207e-13],\n",
      "          [5.5557e-13, 5.5179e-13, 5.8435e-13, 5.6961e-13, 1.0710e-12],\n",
      "          [5.5977e-13, 5.6272e-13, 5.7485e-13, 5.6072e-13, 1.0152e-12],\n",
      "          [3.4299e-13, 3.2350e-13, 3.4014e-13, 3.1049e-13, 6.7295e-13],\n",
      "          [3.3443e-13, 3.1660e-13, 3.3014e-13, 2.9938e-13, 6.1711e-13]],\n",
      "\n",
      "         [[4.1775e-15, 7.5206e-15, 1.8037e-14, 1.0358e-14, 4.3793e-15],\n",
      "          [3.4686e-15, 6.3270e-15, 1.7158e-14, 1.5247e-14, 1.2748e-14],\n",
      "          [3.3545e-15, 5.4769e-15, 1.3783e-14, 1.2170e-14, 1.0607e-14],\n",
      "          [3.3334e-15, 4.8131e-15, 1.1691e-14, 1.6887e-14, 1.2790e-14],\n",
      "          [3.3006e-15, 3.3695e-15, 3.8565e-15, 7.1772e-15, 5.5577e-15]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3359e-17, 8.9611e-17, 9.2943e-16, 1.0275e-14, 1.3692e-14],\n",
      "          [1.7689e-17, 1.4015e-16, 1.4628e-15, 1.3097e-14, 1.9979e-14],\n",
      "          [4.8864e-17, 4.9368e-16, 5.4069e-15, 1.2679e-14, 1.9257e-14],\n",
      "          [5.8321e-17, 4.7776e-16, 5.2047e-15, 1.1928e-14, 1.6449e-14],\n",
      "          [5.7833e-17, 5.5009e-16, 2.9110e-15, 1.7756e-14, 2.6200e-14]],\n",
      "\n",
      "         [[1.3055e-14, 1.6959e-14, 2.0643e-14, 2.9323e-14, 3.2623e-14],\n",
      "          [1.4882e-14, 2.1198e-14, 2.8396e-14, 6.2777e-14, 7.3092e-14],\n",
      "          [3.3736e-14, 4.0602e-14, 4.5438e-14, 6.0009e-14, 5.8557e-14],\n",
      "          [9.6464e-15, 9.9611e-15, 1.1092e-14, 1.1980e-14, 7.3628e-15],\n",
      "          [7.2660e-15, 8.1881e-15, 1.1139e-14, 1.1005e-14, 1.2627e-14]],\n",
      "\n",
      "         [[5.9110e-19, 9.8534e-18, 1.0243e-16, 4.5260e-16, 4.1914e-16],\n",
      "          [6.4731e-19, 1.1747e-17, 8.4056e-17, 5.1145e-16, 8.3243e-16],\n",
      "          [8.6767e-19, 1.4663e-17, 6.6789e-17, 2.9942e-16, 6.2537e-16],\n",
      "          [3.0902e-18, 1.2148e-17, 4.8823e-17, 1.0480e-16, 2.2065e-16],\n",
      "          [3.2684e-18, 1.3454e-17, 2.4184e-17, 1.5570e-16, 1.4689e-16]]],\n",
      "\n",
      "\n",
      "        [[[6.7643e-16, 7.8366e-16, 4.0509e-15, 1.5170e-15, 1.2782e-15],\n",
      "          [4.8629e-16, 3.8897e-16, 3.9045e-15, 1.4564e-15, 4.4419e-16],\n",
      "          [6.8665e-16, 8.4760e-16, 3.2714e-15, 8.0909e-16, 3.8366e-16],\n",
      "          [3.6306e-16, 4.5452e-16, 8.8755e-16, 2.0912e-16, 2.0457e-16],\n",
      "          [8.5815e-16, 1.3567e-15, 5.5027e-16, 2.7892e-16, 3.4372e-16]],\n",
      "\n",
      "         [[7.0920e-15, 7.4579e-15, 5.2799e-15, 1.4432e-14, 1.2088e-14],\n",
      "          [3.1420e-15, 3.4255e-15, 2.7891e-15, 8.6337e-15, 8.9244e-15],\n",
      "          [7.0448e-15, 6.6117e-15, 2.4151e-13, 3.5203e-15, 3.6061e-15],\n",
      "          [3.2927e-15, 3.1951e-15, 8.9479e-15, 1.6853e-15, 1.8612e-15],\n",
      "          [4.4900e-15, 3.9448e-15, 9.0360e-15, 1.8781e-15, 1.7934e-15]],\n",
      "\n",
      "         [[1.5526e-17, 6.3419e-17, 1.2218e-15, 3.2859e-16, 6.5693e-16],\n",
      "          [2.7728e-17, 6.7793e-17, 1.1099e-15, 1.9927e-16, 2.5607e-16],\n",
      "          [4.9495e-16, 6.2010e-17, 1.4162e-15, 7.6367e-16, 7.0601e-17],\n",
      "          [9.7679e-16, 1.4646e-16, 3.3105e-16, 3.2262e-16, 6.8626e-20],\n",
      "          [9.9015e-16, 6.6739e-16, 2.2100e-16, 7.6469e-17, 1.7595e-17]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0724e-17, 6.8660e-18, 6.6657e-18, 6.4522e-17, 3.4565e-16],\n",
      "          [2.1199e-16, 7.5075e-17, 3.9636e-18, 2.9180e-16, 1.0855e-15],\n",
      "          [6.2613e-16, 2.5426e-16, 1.9507e-17, 9.9244e-16, 2.8029e-15],\n",
      "          [5.2696e-16, 3.3059e-16, 2.8540e-17, 2.0827e-16, 5.0452e-16],\n",
      "          [5.5697e-15, 4.4998e-15, 5.3059e-16, 3.2932e-16, 1.8145e-16]],\n",
      "\n",
      "         [[3.9722e-16, 4.2969e-16, 2.0884e-16, 4.4418e-16, 5.2117e-16],\n",
      "          [3.8381e-15, 3.1151e-15, 2.3194e-16, 5.0967e-16, 8.9811e-16],\n",
      "          [2.5406e-11, 2.5405e-11, 3.1490e-11, 7.2788e-17, 2.2467e-16],\n",
      "          [2.5403e-11, 2.5403e-11, 3.1491e-11, 2.5564e-16, 2.1971e-16],\n",
      "          [2.5404e-11, 2.5406e-11, 3.1495e-11, 4.3145e-15, 3.9219e-15]],\n",
      "\n",
      "         [[1.6281e-18, 4.3865e-17, 1.0205e-18, 9.9662e-18, 9.5405e-17],\n",
      "          [8.9973e-17, 1.0807e-16, 2.7842e-19, 1.6376e-16, 1.6034e-16],\n",
      "          [1.7158e-16, 9.4828e-17, 5.1522e-18, 1.1960e-15, 1.4277e-15],\n",
      "          [2.0967e-16, 1.5093e-16, 9.9445e-18, 4.4924e-16, 5.8389e-16],\n",
      "          [3.3959e-16, 3.0174e-16, 8.3632e-17, 4.1629e-17, 5.6331e-17]]],\n",
      "\n",
      "\n",
      "        [[[1.9901e-14, 3.8772e-14, 2.0077e-14, 2.0084e-14, 2.5030e-14],\n",
      "          [1.4320e-14, 1.8443e-14, 8.1772e-15, 8.6085e-15, 1.0120e-14],\n",
      "          [1.5278e-14, 2.2209e-14, 1.2548e-14, 1.2175e-14, 1.2613e-14],\n",
      "          [1.6859e-14, 2.7496e-14, 1.6184e-14, 1.8409e-14, 1.7155e-14],\n",
      "          [1.6328e-14, 2.3986e-14, 1.7152e-14, 1.6937e-14, 1.9921e-14]],\n",
      "\n",
      "         [[2.9070e-13, 3.6442e-13, 3.4373e-13, 5.3693e-13, 1.9276e-13],\n",
      "          [2.2068e-13, 3.0045e-13, 2.8946e-13, 4.9255e-13, 1.4671e-13],\n",
      "          [2.2467e-13, 3.0464e-13, 2.9484e-13, 4.9648e-13, 1.6469e-13],\n",
      "          [2.3046e-13, 3.1312e-13, 3.0378e-13, 5.0916e-13, 1.8313e-13],\n",
      "          [1.9082e-13, 2.6919e-13, 2.6731e-13, 4.6701e-13, 1.6581e-13]],\n",
      "\n",
      "         [[7.3137e-15, 4.1623e-14, 6.0947e-15, 7.6450e-15, 9.5887e-15],\n",
      "          [6.5111e-15, 4.3679e-14, 7.4771e-15, 9.3006e-15, 1.1075e-14],\n",
      "          [5.4036e-15, 4.3807e-14, 1.1012e-14, 9.7362e-15, 1.0814e-14],\n",
      "          [1.2647e-14, 4.3836e-14, 2.1037e-14, 1.6858e-14, 1.2228e-14],\n",
      "          [6.6814e-15, 2.3842e-14, 2.1815e-14, 1.8840e-14, 1.8406e-14]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.2361e-16, 3.9578e-16, 1.8915e-15, 2.4245e-15, 1.5530e-15],\n",
      "          [1.2720e-16, 1.9457e-16, 9.2117e-16, 1.2588e-15, 9.0030e-16],\n",
      "          [1.1205e-14, 1.7250e-14, 2.3254e-14, 2.1421e-14, 1.1520e-14],\n",
      "          [1.3154e-14, 3.1186e-14, 6.1953e-14, 6.0518e-14, 4.6238e-14],\n",
      "          [1.4170e-15, 8.0810e-15, 2.7417e-14, 2.7566e-14, 2.7757e-14]],\n",
      "\n",
      "         [[1.0500e-14, 4.0619e-14, 5.1084e-14, 5.0854e-14, 4.1261e-14],\n",
      "          [7.8587e-15, 1.2244e-14, 1.4210e-14, 1.3222e-14, 7.5598e-15],\n",
      "          [7.5684e-15, 1.0933e-14, 1.3999e-14, 1.4981e-14, 7.1259e-15],\n",
      "          [8.2853e-15, 1.0439e-14, 1.3307e-14, 1.6220e-14, 8.7863e-15],\n",
      "          [2.1338e-14, 1.7016e-14, 1.6421e-14, 1.6312e-14, 1.3313e-14]],\n",
      "\n",
      "         [[3.2831e-16, 7.4372e-16, 1.4935e-15, 1.2917e-15, 8.7719e-16],\n",
      "          [1.6915e-16, 2.8635e-16, 6.2732e-16, 6.4938e-16, 4.8768e-16],\n",
      "          [1.5404e-16, 1.8541e-16, 2.5807e-16, 4.6796e-16, 4.4075e-16],\n",
      "          [1.4178e-16, 1.6712e-16, 2.0637e-16, 4.3218e-16, 3.8113e-16],\n",
      "          [1.5995e-16, 8.7778e-17, 9.3228e-17, 1.7883e-16, 1.6089e-16]]]])}, 3: {'step': 18912, 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  2.2391e-05,  5.6052e-45,  5.6052e-45,\n",
      "         8.6802e-10,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -6.3159e-07, -1.2597e-05, -1.2585e-04,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -1.0015e-05,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -1.1995e-18,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -1.2449e-04,  5.6052e-45,  2.3189e-05, -6.3224e-05,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  3.4204e-05, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  1.9758e-43,  5.6052e-45, -1.1396e-06,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -6.8444e-14, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.0875e-07, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -1.7081e-31,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -2.4006e-06,  5.6052e-45,  5.6052e-45,  1.7427e-05,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  3.6756e-25,  2.4861e-05, -1.2442e-04,\n",
      "        -1.1622e-04,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  3.2230e-43,  5.6052e-45, -3.3667e-33,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -1.5961e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -7.6818e-05,  5.6052e-45,  5.6052e-45, -1.2576e-15,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -1.1899e-26,  5.6052e-45,  1.7481e-05,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -3.6854e-43,  1.6617e-05,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -4.6097e-06, -4.5408e-05,  1.6975e-04,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -3.6070e-05,\n",
      "         5.6052e-45,  5.6052e-45,  1.9776e-36,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -1.1705e-07,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([1.6939e-13, 9.8239e-13, 8.3242e-05, 4.9027e-18, 2.6345e-13, 3.9448e-12,\n",
      "        9.8167e-12, 2.6622e-11, 3.1316e-14, 9.6958e-17, 2.2524e-14, 1.5537e-07,\n",
      "        2.1776e-07, 1.8645e-06, 5.8095e-15, 6.7019e-14, 1.9045e-14, 4.6674e-13,\n",
      "        2.0477e-14, 4.1635e-07, 2.6098e-16, 7.6576e-13, 1.4699e-13, 5.0036e-15,\n",
      "        1.5748e-13, 5.2007e-14, 3.1235e-14, 9.8536e-10, 1.2431e-14, 2.8101e-12,\n",
      "        2.5556e-14, 7.4157e-07, 4.6028e-14, 5.1758e-07, 1.6045e-07, 2.3466e-13,\n",
      "        9.8485e-13, 4.1633e-14, 7.3330e-14, 9.4656e-25, 1.0149e-14, 3.3644e-16,\n",
      "        2.2527e-12, 5.1572e-13, 2.2743e-12, 5.8055e-14, 1.1176e-15, 9.0192e-14,\n",
      "        1.1774e-07, 1.0895e-13, 1.4000e-11, 1.3654e-10, 3.6842e-11, 1.2471e-13,\n",
      "        6.6612e-10, 2.5776e-13, 1.0748e-14, 1.0559e-14, 8.2986e-15, 4.7508e-14,\n",
      "        2.8912e-15, 5.0147e-13, 6.7112e-14, 1.0009e-15, 5.2485e-13, 5.4143e-14,\n",
      "        6.4634e-15, 6.4856e-10, 3.0889e-07, 1.3760e-13, 8.9126e-16, 1.1734e-14,\n",
      "        1.2430e-14, 2.1037e-11, 8.6554e-14, 2.2865e-15, 1.3341e-14, 6.1724e-15,\n",
      "        5.7610e-14, 1.1850e-15, 6.7013e-10, 3.0319e-12, 1.0768e-14, 1.8236e-14,\n",
      "        5.2759e-14, 4.3883e-14, 1.2194e-14, 1.4639e-13, 2.8857e-15, 3.1201e-14,\n",
      "        5.6513e-14, 2.2014e-10, 1.9142e-12, 2.0471e-14, 8.1129e-15, 5.9769e-14,\n",
      "        1.2680e-15, 2.3300e-15, 2.3952e-14, 6.3284e-13, 3.1494e-07, 1.3237e-09,\n",
      "        2.0912e-14, 2.0775e-05, 3.9523e-14, 9.5720e-14, 1.8001e-16, 2.2305e-12,\n",
      "        9.4024e-07, 2.4362e-07, 1.9966e-07, 1.7066e-14, 1.0591e-14, 8.9665e-16,\n",
      "        2.1447e-13, 7.3355e-13, 3.6321e-12, 2.3550e-12, 1.4955e-15, 5.6786e-13,\n",
      "        6.4281e-16, 1.6466e-13, 1.3916e-14, 7.4636e-16, 2.3586e-15, 1.1391e-16,\n",
      "        1.2004e-10, 2.2207e-14, 2.1613e-13, 1.8550e-09, 2.0663e-14, 2.3492e-12,\n",
      "        6.5304e-13, 1.5960e-14, 1.0782e-15, 4.6356e-06, 3.9106e-11, 5.0021e-12,\n",
      "        5.9413e-16, 5.5672e-17, 9.9697e-07, 3.0228e-14, 4.3885e-14, 4.4266e-10,\n",
      "        5.6318e-17, 2.6355e-14, 5.7152e-14, 1.5101e-15, 2.2650e-15, 7.5873e-14,\n",
      "        1.2751e-12, 8.2246e-11, 5.0096e-12, 3.6376e-07, 6.8916e-14, 5.4078e-14,\n",
      "        1.6433e-11, 1.7859e-13, 3.0440e-12, 5.6931e-08, 2.0365e-09, 4.7575e-15,\n",
      "        8.6744e-12, 3.4020e-15, 4.0856e-13, 3.1890e-23, 2.3513e-08, 1.7153e-07,\n",
      "        8.0122e-07, 2.8532e-14, 1.5773e-14, 9.5562e-14, 1.0799e-15, 2.2755e-14,\n",
      "        5.7308e-16, 6.1511e-15, 4.1632e-15, 5.9218e-15, 2.4245e-15, 3.0472e-07,\n",
      "        2.9227e-14, 3.2792e-14, 1.6954e-15, 1.1844e-14, 2.8047e-15, 5.8470e-16,\n",
      "        1.6997e-13, 1.1485e-15, 7.3218e-07, 5.3731e-14, 6.7175e-13, 2.7603e-14])}, 4: {'step': 18912, 'exp_avg': tensor([[[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -2.0749e-28, -5.6052e-45],\n",
      "          [-5.6052e-45, -6.3530e-26, -1.1555e-27],\n",
      "          [-1.1027e-31, -4.9110e-26, -1.8545e-27]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]]]]), 'exp_avg_sq': tensor([[[[2.4770e-15, 8.9890e-15, 5.6971e-15],\n",
      "          [7.1305e-16, 4.6621e-15, 4.7655e-15],\n",
      "          [1.7681e-16, 1.6714e-16, 8.8216e-16]],\n",
      "\n",
      "         [[1.4738e-15, 1.4583e-15, 3.1272e-15],\n",
      "          [9.5802e-16, 1.9722e-15, 5.2034e-15],\n",
      "          [9.7369e-15, 1.0111e-14, 6.2872e-15]],\n",
      "\n",
      "         [[5.7392e-16, 5.6352e-17, 7.7087e-15],\n",
      "          [4.5276e-16, 1.8194e-16, 6.6959e-15],\n",
      "          [1.0800e-15, 9.6382e-16, 5.3898e-15]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3383e-14, 1.7491e-15, 6.2502e-15],\n",
      "          [1.4628e-14, 3.7146e-15, 8.7854e-15],\n",
      "          [6.2524e-15, 1.9466e-15, 1.0530e-14]],\n",
      "\n",
      "         [[1.0971e-17, 5.9451e-16, 8.8037e-15],\n",
      "          [5.7846e-17, 4.7823e-17, 1.2666e-15],\n",
      "          [4.0102e-16, 2.4944e-16, 2.9703e-16]],\n",
      "\n",
      "         [[1.2475e-16, 2.4705e-16, 1.0605e-15],\n",
      "          [6.0076e-16, 8.3888e-16, 1.2720e-15],\n",
      "          [3.4827e-15, 3.6804e-15, 2.1713e-15]]],\n",
      "\n",
      "\n",
      "        [[[3.8332e-15, 1.3461e-14, 3.5579e-15],\n",
      "          [8.3361e-15, 3.4358e-14, 7.7464e-15],\n",
      "          [2.3471e-15, 9.3305e-15, 1.3305e-15]],\n",
      "\n",
      "         [[9.0244e-17, 9.5153e-16, 2.7622e-16],\n",
      "          [7.8579e-17, 1.1612e-15, 3.3034e-16],\n",
      "          [7.3180e-15, 2.5206e-14, 3.5612e-16]],\n",
      "\n",
      "         [[1.3708e-19, 3.1892e-17, 3.9494e-17],\n",
      "          [6.3186e-20, 1.3309e-17, 3.2716e-16],\n",
      "          [4.1736e-21, 3.4338e-19, 9.7409e-17]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.6664e-16, 3.9826e-15, 1.4729e-15],\n",
      "          [2.9362e-15, 1.4362e-14, 4.0522e-15],\n",
      "          [5.2359e-16, 1.6250e-15, 3.0879e-16]],\n",
      "\n",
      "         [[1.7505e-17, 1.4662e-14, 2.6952e-17],\n",
      "          [1.0371e-16, 2.6968e-14, 5.6163e-16],\n",
      "          [2.5280e-21, 1.4406e-14, 4.6168e-17]],\n",
      "\n",
      "         [[3.4764e-14, 1.3943e-13, 2.9024e-14],\n",
      "          [5.9527e-14, 2.2488e-13, 5.2011e-14],\n",
      "          [2.5366e-14, 1.1300e-13, 1.7252e-14]]],\n",
      "\n",
      "\n",
      "        [[[4.8639e-14, 4.2185e-14, 4.6465e-14],\n",
      "          [4.7574e-14, 3.1025e-14, 3.8788e-14],\n",
      "          [4.1837e-14, 4.1694e-14, 5.3177e-14]],\n",
      "\n",
      "         [[8.3805e-17, 4.4482e-16, 5.3277e-15],\n",
      "          [5.1338e-17, 6.2990e-17, 2.5321e-15],\n",
      "          [1.5039e-16, 6.1597e-17, 1.5002e-15]],\n",
      "\n",
      "         [[3.1623e-15, 4.2253e-17, 3.6347e-15],\n",
      "          [1.4344e-15, 2.4483e-16, 1.0551e-16],\n",
      "          [1.0555e-16, 1.7446e-16, 1.6670e-15]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.9642e-15, 1.7846e-14, 8.0299e-14],\n",
      "          [9.9043e-16, 3.2762e-15, 5.7913e-14],\n",
      "          [8.2967e-15, 4.1137e-15, 6.7491e-14]],\n",
      "\n",
      "         [[1.8290e-15, 3.1864e-15, 4.0171e-14],\n",
      "          [1.9985e-16, 7.1571e-16, 2.6936e-14],\n",
      "          [1.1400e-17, 1.9226e-16, 2.0877e-14]],\n",
      "\n",
      "         [[6.6535e-13, 6.5105e-13, 6.8829e-13],\n",
      "          [6.3925e-13, 6.2190e-13, 6.6666e-13],\n",
      "          [5.5315e-13, 5.4503e-13, 5.5465e-13]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[9.6777e-17, 6.6490e-16, 3.6249e-16],\n",
      "          [2.9244e-16, 1.4412e-15, 3.2531e-16],\n",
      "          [6.0758e-16, 3.4670e-16, 4.2014e-16]],\n",
      "\n",
      "         [[1.7432e-16, 1.6437e-17, 9.2596e-18],\n",
      "          [2.8163e-16, 2.3466e-17, 4.1291e-18],\n",
      "          [1.0278e-16, 3.9149e-17, 1.7177e-17]],\n",
      "\n",
      "         [[3.6676e-15, 3.5757e-16, 1.1791e-18],\n",
      "          [3.3495e-15, 5.9339e-16, 2.9382e-17],\n",
      "          [2.0016e-16, 1.6236e-15, 2.6689e-16]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.3403e-16, 8.6277e-17, 5.8047e-16],\n",
      "          [1.0106e-16, 5.9329e-17, 3.5549e-16],\n",
      "          [1.0176e-15, 7.4553e-16, 9.3543e-16]],\n",
      "\n",
      "         [[6.4882e-16, 6.7940e-17, 3.5108e-17],\n",
      "          [4.0281e-16, 9.8044e-16, 2.7258e-16],\n",
      "          [4.5558e-17, 2.9147e-16, 2.0534e-16]],\n",
      "\n",
      "         [[1.8645e-15, 1.4347e-15, 3.0165e-16],\n",
      "          [1.2220e-15, 2.9411e-15, 6.6016e-16],\n",
      "          [1.4645e-14, 4.8330e-15, 8.5134e-15]]],\n",
      "\n",
      "\n",
      "        [[[1.7365e-15, 5.0638e-15, 1.1954e-14],\n",
      "          [3.0341e-15, 5.5628e-15, 9.7119e-15],\n",
      "          [2.8587e-15, 4.3677e-15, 7.7177e-15]],\n",
      "\n",
      "         [[5.8932e-16, 8.5113e-16, 5.6744e-16],\n",
      "          [5.1219e-16, 1.9309e-15, 1.1604e-15],\n",
      "          [2.4524e-16, 1.7758e-15, 1.2584e-15]],\n",
      "\n",
      "         [[7.4707e-18, 2.0287e-18, 6.8045e-17],\n",
      "          [1.7937e-18, 6.6780e-19, 2.2565e-17],\n",
      "          [9.2120e-19, 1.6482e-20, 2.4713e-18]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0601e-14, 3.8719e-14, 4.5437e-15],\n",
      "          [3.0261e-14, 4.4771e-14, 9.1226e-15],\n",
      "          [2.1920e-14, 4.8278e-14, 1.6864e-14]],\n",
      "\n",
      "         [[7.2667e-18, 2.0392e-15, 1.4945e-17],\n",
      "          [6.2070e-17, 5.0003e-15, 5.1502e-17],\n",
      "          [1.1364e-16, 4.7759e-15, 1.0620e-15]],\n",
      "\n",
      "         [[1.6231e-14, 1.0681e-14, 2.7462e-15],\n",
      "          [2.5056e-14, 2.1470e-14, 3.5524e-15],\n",
      "          [2.2719e-14, 2.0163e-14, 4.2567e-15]]],\n",
      "\n",
      "\n",
      "        [[[5.4476e-17, 5.8944e-17, 5.7098e-17],\n",
      "          [2.6724e-17, 9.4836e-17, 7.0585e-17],\n",
      "          [4.1360e-17, 4.2663e-17, 2.4733e-17]],\n",
      "\n",
      "         [[8.5784e-18, 3.0469e-18, 7.2311e-18],\n",
      "          [2.0235e-17, 2.9907e-17, 6.2449e-17],\n",
      "          [8.4838e-18, 4.2302e-17, 1.1599e-16]],\n",
      "\n",
      "         [[4.4033e-18, 1.1015e-17, 1.8337e-16],\n",
      "          [1.0256e-21, 8.6537e-18, 2.9299e-16],\n",
      "          [5.0392e-18, 1.3082e-17, 3.4943e-16]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.3427e-16, 1.4017e-16, 9.5214e-18],\n",
      "          [6.7253e-16, 2.2221e-16, 4.6007e-17],\n",
      "          [8.9146e-16, 3.2555e-16, 1.0654e-16]],\n",
      "\n",
      "         [[4.7653e-20, 2.7741e-17, 2.4500e-16],\n",
      "          [2.0659e-19, 3.1439e-17, 1.8316e-16],\n",
      "          [7.0820e-18, 1.6312e-17, 7.6466e-17]],\n",
      "\n",
      "         [[4.5178e-20, 3.5031e-20, 5.6167e-18],\n",
      "          [1.0543e-19, 4.7975e-19, 6.8638e-18],\n",
      "          [2.8795e-18, 4.7111e-18, 5.7723e-18]]]])}, 5: {'step': 18912, 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -2.2226e-15, -4.2724e-08, -5.6052e-45,\n",
      "        -5.6052e-45, -7.5934e-11,  3.2286e-17,  5.6052e-45, -5.6052e-45,\n",
      "         4.8159e-05,  4.9772e-07,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -2.4857e-10,  5.6052e-45, -5.6052e-45, -1.9877e-06, -5.6052e-45,\n",
      "        -2.6499e-08,  5.6052e-45, -1.0891e-31, -2.0230e-28,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  3.1950e-42, -5.6052e-45, -1.7172e-20, -5.6052e-45,\n",
      "        -3.7172e-08, -5.6052e-45,  5.6052e-45, -1.4067e-11,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -2.0058e-13,  5.6052e-45, -6.7925e-07,\n",
      "         1.0581e-11,  5.6052e-45, -5.6052e-45, -8.9262e-22,  5.6052e-45,\n",
      "         5.6052e-45, -2.4879e-06, -5.6052e-45,  3.9456e-10,  5.6052e-45,\n",
      "        -2.1141e-05, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  4.8949e-08, -1.1341e-06,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -2.1699e-06,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  2.8026e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -3.2632e-34,  2.2590e-12,  5.6052e-45,\n",
      "        -2.6583e-21,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.7075e-13, -2.5356e-05, -3.9071e-12,\n",
      "        -9.9582e-06,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         6.0539e-06,  5.6052e-45,  5.1216e-08,  5.6052e-45,  5.6052e-45,\n",
      "        -6.0983e-10, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -4.8996e-08, -6.6099e-06,\n",
      "        -1.5393e-06,  5.6052e-45,  5.6052e-45,  1.2312e-31, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -8.1180e-11, -5.6052e-45,  1.2147e-05,\n",
      "        -1.7099e-11, -5.2231e-35,  5.6052e-45, -5.1726e-17, -1.0409e-19,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -2.4936e-30,  5.6678e-05,  5.9602e-06,\n",
      "        -1.8217e-44,  5.6052e-45,  5.6052e-45, -4.8933e-09, -5.6298e-08,\n",
      "         5.6052e-45, -3.8237e-10,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -2.7228e-29,  3.6434e-07, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.0309e-16, -2.4631e-08,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  4.9699e-05,\n",
      "        -5.2913e-17,  5.6052e-45, -1.8918e-42, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  1.5050e-16, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -9.7352e-09,\n",
      "         5.6052e-45, -9.5327e-08, -5.6052e-45,  8.9510e-09, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -4.8239e-22,  5.6052e-45,\n",
      "         7.1582e-09,  5.6052e-45, -3.6465e-05, -2.4074e-15,  5.6052e-45,\n",
      "        -5.6052e-45, -5.7614e-14, -5.6052e-45, -8.0140e-07,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  2.2863e-05,\n",
      "         3.1287e-07, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  8.8128e-05,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -2.2966e-16,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -7.3452e-09, -8.6178e-25,\n",
      "        -1.1643e-06,  5.6052e-45,  5.6052e-45,  5.6052e-45, -1.2581e-05,\n",
      "        -5.3384e-06,  5.6052e-45, -3.9816e-24,  5.6052e-45, -2.0379e-06,\n",
      "         1.8915e-05,  5.6052e-45,  4.6085e-07,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -3.6204e-08, -4.4251e-06,\n",
      "        -5.6052e-45,  5.6052e-45, -2.0790e-07, -4.0170e-26,  5.6052e-45,\n",
      "         9.1206e-06,  5.6052e-45,  5.6052e-45,  5.6052e-45,  1.7387e-05,\n",
      "        -2.4930e-19,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.3229e-09,\n",
      "        -1.6281e-06, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  3.8936e-10,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  1.3466e-42, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -3.3695e-10, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -8.4343e-06,  7.6043e-39,  5.6052e-45, -5.6052e-45,\n",
      "         9.3989e-18, -5.6052e-45,  2.1489e-06, -5.6052e-45, -6.2367e-25,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -1.3917e-12,  5.6052e-45, -5.6052e-45,  3.5664e-05, -1.3215e-05,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  3.8084e-06, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -3.6199e-06,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -1.9889e-05,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([3.7221e-13, 2.0781e-13, 1.2247e-09, 4.4565e-08, 6.3977e-11, 1.5870e-15,\n",
      "        1.2252e-08, 5.8078e-11, 4.4812e-14, 2.5387e-16, 4.1320e-07, 2.5081e-08,\n",
      "        2.0225e-16, 1.5067e-14, 2.6163e-16, 1.8954e-10, 3.4795e-14, 2.5404e-15,\n",
      "        4.3047e-09, 3.0210e-13, 7.8792e-10, 5.0442e-14, 1.0667e-14, 1.0132e-11,\n",
      "        1.4103e-15, 3.0257e-13, 7.1776e-14, 1.1351e-13, 1.0229e-13, 3.2600e-13,\n",
      "        1.4797e-11, 4.1748e-10, 9.1808e-12, 4.1708e-14, 6.4520e-14, 5.7109e-10,\n",
      "        6.1088e-14, 5.1995e-14, 5.6673e-10, 1.4748e-13, 3.8812e-15, 4.5981e-16,\n",
      "        3.5930e-15, 1.2835e-13, 5.9207e-12, 6.2106e-14, 1.4537e-15, 1.4539e-12,\n",
      "        1.9895e-13, 2.3882e-09, 1.7811e-12, 7.9618e-13, 1.5266e-13, 2.1895e-10,\n",
      "        2.6551e-11, 5.0226e-16, 5.7179e-09, 4.9009e-15, 6.7076e-08, 2.5058e-14,\n",
      "        1.3774e-05, 2.7712e-11, 2.8701e-15, 4.2767e-13, 2.2183e-14, 3.6508e-15,\n",
      "        1.3785e-16, 4.3564e-10, 1.5695e-09, 6.1848e-15, 1.9420e-12, 2.0570e-14,\n",
      "        1.7544e-15, 5.0200e-17, 4.0198e-15, 2.0454e-13, 2.5766e-12, 3.4269e-07,\n",
      "        2.7895e-12, 3.1211e-13, 3.0840e-15, 1.8869e-14, 1.3938e-16, 2.3685e-16,\n",
      "        8.3793e-15, 3.8292e-14, 2.0348e-11, 3.1191e-13, 3.8515e-16, 2.1697e-15,\n",
      "        6.2105e-15, 5.8500e-14, 5.6080e-14, 1.8521e-11, 1.2052e-14, 3.7247e-14,\n",
      "        1.3630e-14, 4.0524e-15, 1.7353e-13, 2.0294e-14, 9.8746e-14, 6.8298e-11,\n",
      "        3.0590e-14, 1.2240e-13, 6.3173e-15, 2.8463e-14, 2.4097e-13, 1.7122e-11,\n",
      "        2.0118e-05, 7.2700e-10, 1.7204e-07, 6.5643e-13, 1.3189e-15, 5.4678e-15,\n",
      "        2.5022e-15, 5.0126e-08, 1.1147e-12, 1.5296e-09, 9.0013e-13, 1.9592e-13,\n",
      "        5.7954e-09, 2.9642e-13, 6.5160e-14, 3.2415e-15, 4.1439e-15, 6.2444e-13,\n",
      "        1.3618e-12, 1.0299e-11, 1.9440e-08, 4.5304e-07, 1.2048e-09, 1.8309e-14,\n",
      "        2.8065e-12, 2.6889e-13, 2.4111e-15, 4.1053e-14, 2.7762e-17, 3.4980e-13,\n",
      "        1.6227e-11, 1.6346e-07, 1.0917e-08, 9.0137e-14, 7.6472e-16, 6.0043e-09,\n",
      "        2.1702e-09, 1.5005e-12, 1.9934e-09, 1.1903e-13, 3.7108e-15, 1.4453e-14,\n",
      "        7.4503e-16, 8.8917e-15, 6.1986e-12, 5.3307e-07, 1.7415e-09, 7.9808e-14,\n",
      "        8.4511e-14, 2.3758e-12, 4.9326e-10, 3.3135e-09, 3.5084e-15, 8.2206e-10,\n",
      "        1.1961e-14, 3.0797e-15, 1.4337e-14, 2.8065e-13, 9.7100e-14, 1.1724e-13,\n",
      "        2.1524e-13, 1.3831e-13, 5.0761e-14, 8.4239e-14, 9.4723e-14, 2.7853e-13,\n",
      "        3.2544e-13, 5.0088e-11, 1.0045e-09, 5.0538e-14, 1.9864e-13, 1.7852e-15,\n",
      "        1.0357e-14, 7.2489e-16, 2.1666e-10, 2.7925e-10, 2.2282e-14, 2.8675e-13,\n",
      "        1.5159e-13, 5.1752e-13, 1.4747e-12, 1.3689e-07, 1.1388e-10, 6.9601e-15,\n",
      "        1.1332e-10, 1.5904e-14, 1.1189e-14, 3.7703e-13, 1.8993e-09, 3.9968e-12,\n",
      "        1.3094e-14, 3.8554e-13, 1.5476e-13, 1.5626e-15, 1.1674e-13, 3.8439e-15,\n",
      "        1.0618e-07, 2.8092e-14, 4.8757e-07, 5.8293e-13, 5.6737e-09, 1.8687e-13,\n",
      "        1.5412e-15, 4.6389e-15, 1.7897e-13, 8.1052e-07, 2.9051e-14, 2.2820e-09,\n",
      "        2.6740e-15, 1.3080e-06, 2.6715e-08, 1.6899e-13, 4.4414e-17, 5.9378e-07,\n",
      "        3.4887e-15, 3.4014e-09, 6.5441e-14, 2.4226e-14, 1.7357e-12, 2.1999e-14,\n",
      "        5.9299e-13, 4.2812e-08, 2.1098e-09, 2.6136e-13, 2.3893e-14, 3.1008e-16,\n",
      "        1.0132e-14, 2.5288e-15, 2.9730e-12, 2.9388e-13, 2.6048e-14, 5.9672e-07,\n",
      "        5.8873e-14, 8.3347e-15, 1.1837e-10, 6.6289e-16, 8.3974e-12, 2.5257e-14,\n",
      "        4.0670e-15, 3.6312e-13, 3.2992e-12, 8.9969e-13, 3.4048e-13, 2.7930e-13,\n",
      "        2.7904e-13, 1.2883e-07, 7.4973e-11, 1.6784e-09, 1.2584e-13, 8.8776e-13,\n",
      "        8.3170e-14, 3.1968e-08, 3.7572e-08, 4.7450e-16, 6.4325e-13, 3.0083e-14,\n",
      "        4.6396e-06, 2.1947e-09, 7.0596e-11, 3.3180e-10, 3.1876e-17, 1.4267e-14,\n",
      "        1.1170e-14, 5.7679e-13, 2.2590e-14, 1.6563e-13, 8.3313e-14, 1.9133e-14,\n",
      "        2.2908e-13, 7.9254e-11, 1.6279e-08, 2.2301e-08, 2.7116e-13, 1.0014e-14,\n",
      "        7.9092e-08, 5.4557e-12, 1.9741e-13, 3.9722e-06, 1.0922e-15, 2.2225e-14,\n",
      "        2.5137e-13, 7.6630e-06, 7.9729e-14, 4.4670e-17, 7.1762e-13, 2.2585e-13,\n",
      "        6.8097e-15, 4.3859e-13, 2.5037e-17, 3.2180e-11, 4.4958e-14, 7.0029e-10,\n",
      "        2.7630e-14, 2.9792e-13, 6.2344e-16, 1.8183e-13, 1.1407e-10, 1.0758e-09,\n",
      "        2.1525e-16, 7.8350e-13, 1.1941e-13, 2.7047e-14, 5.8888e-14, 4.6026e-10,\n",
      "        1.3910e-15, 1.8156e-15, 6.3099e-14, 1.1456e-16, 9.9368e-15, 4.4890e-09,\n",
      "        1.9121e-10, 3.5435e-15, 7.5545e-13, 1.5520e-10, 1.3058e-13, 2.1132e-14,\n",
      "        7.1137e-16, 6.8033e-13, 4.9832e-06, 1.4380e-12, 2.2776e-13, 3.6678e-13,\n",
      "        5.9004e-14, 8.2389e-14, 6.6112e-10, 2.9065e-15, 2.4602e-10, 1.3817e-13,\n",
      "        3.5668e-14, 6.3367e-12, 1.5019e-15, 1.3316e-10, 3.7586e-10, 4.4957e-17,\n",
      "        1.1089e-13, 1.2912e-06, 1.7841e-07, 3.7991e-15, 9.7661e-13, 2.3736e-15,\n",
      "        9.9116e-09, 1.4925e-15, 1.1500e-15, 4.0561e-16, 2.7113e-14, 2.2378e-14,\n",
      "        1.9172e-14, 9.3986e-14, 6.8614e-16, 3.9077e-14, 1.1686e-17, 2.0577e-13,\n",
      "        6.2000e-14, 1.1232e-12, 3.3317e-13, 1.9102e-14, 2.2565e-16, 2.0447e-15,\n",
      "        2.0005e-08, 5.2407e-15, 5.7339e-14, 9.0891e-17, 6.7570e-12, 1.3340e-14,\n",
      "        7.3077e-09, 1.3802e-13, 1.1962e-13, 3.0787e-13, 2.5133e-10, 4.7304e-15,\n",
      "        7.8428e-15, 8.2145e-16, 7.5454e-14, 3.1216e-16, 2.1473e-15, 3.1664e-17])}, 6: {'step': 18912, 'exp_avg': tensor([[[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 0.0000e+00,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  0.0000e+00, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]]]]), 'exp_avg_sq': tensor([[[[1.6212e-16, 7.1086e-16, 7.8514e-16],\n",
      "          [1.7691e-16, 2.5590e-16, 1.2324e-16],\n",
      "          [6.0363e-17, 3.4529e-17, 6.6915e-18]],\n",
      "\n",
      "         [[2.7149e-17, 2.2469e-17, 2.7047e-17],\n",
      "          [3.4289e-18, 4.7346e-18, 5.9573e-18],\n",
      "          [4.0335e-18, 5.8276e-18, 4.7461e-18]],\n",
      "\n",
      "         [[3.9654e-17, 6.4666e-17, 4.9560e-16],\n",
      "          [6.9465e-17, 6.3029e-17, 1.7179e-16],\n",
      "          [1.9604e-17, 1.4615e-17, 6.6241e-18]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.7023e-19, 2.1709e-17, 6.0708e-18],\n",
      "          [2.7358e-18, 8.9117e-18, 1.3055e-18],\n",
      "          [1.3574e-18, 6.9898e-18, 3.4258e-21]],\n",
      "\n",
      "         [[1.6445e-17, 4.6970e-18, 1.0693e-16],\n",
      "          [5.6654e-18, 2.4368e-18, 7.2282e-18],\n",
      "          [6.0534e-18, 4.6529e-19, 2.1671e-17]],\n",
      "\n",
      "         [[1.6759e-17, 8.3300e-18, 7.9173e-18],\n",
      "          [2.0718e-17, 2.0283e-18, 2.8929e-18],\n",
      "          [8.1356e-21, 2.6786e-18, 2.9741e-18]]],\n",
      "\n",
      "\n",
      "        [[[4.0562e-14, 3.7683e-13, 3.5723e-14],\n",
      "          [2.2977e-14, 4.8063e-14, 5.5042e-14],\n",
      "          [5.8149e-15, 1.9691e-14, 3.9323e-14]],\n",
      "\n",
      "         [[5.4212e-19, 4.3117e-19, 4.8590e-18],\n",
      "          [9.8109e-18, 8.3300e-18, 9.5357e-18],\n",
      "          [3.6682e-18, 9.6674e-16, 1.6073e-16]],\n",
      "\n",
      "         [[2.2827e-13, 2.3680e-13, 1.3901e-13],\n",
      "          [4.3526e-13, 5.5580e-13, 3.2519e-13],\n",
      "          [4.6018e-13, 6.5905e-13, 4.2627e-13]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6179e-14, 1.8361e-14, 7.3785e-15],\n",
      "          [5.0557e-15, 5.1890e-15, 1.6819e-15],\n",
      "          [2.6764e-15, 5.6953e-16, 2.5919e-16]],\n",
      "\n",
      "         [[1.5992e-15, 5.6513e-17, 2.5583e-17],\n",
      "          [1.5492e-15, 6.9537e-17, 3.8122e-17],\n",
      "          [4.3457e-15, 4.5198e-16, 6.6070e-18]],\n",
      "\n",
      "         [[2.1480e-17, 3.0844e-17, 1.0147e-18],\n",
      "          [4.7526e-17, 4.5838e-17, 1.9671e-18],\n",
      "          [3.4374e-17, 3.5974e-17, 1.7742e-17]]],\n",
      "\n",
      "\n",
      "        [[[1.8415e-16, 3.9157e-16, 8.9122e-16],\n",
      "          [1.0577e-16, 1.2456e-16, 1.1465e-16],\n",
      "          [7.7048e-18, 1.4800e-17, 1.4673e-17]],\n",
      "\n",
      "         [[1.7872e-17, 3.4896e-17, 4.7999e-17],\n",
      "          [1.0913e-17, 2.7593e-17, 2.6962e-17],\n",
      "          [1.6064e-17, 1.0915e-17, 8.8437e-18]],\n",
      "\n",
      "         [[8.6982e-19, 5.8465e-18, 1.1559e-18],\n",
      "          [9.4817e-18, 8.8552e-17, 3.5245e-11],\n",
      "          [1.2349e-17, 9.5800e-17, 1.8201e-10]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.2198e-17, 1.1260e-20, 5.0912e-19],\n",
      "          [8.6092e-17, 1.2131e-19, 1.1594e-18],\n",
      "          [4.9736e-17, 6.7287e-20, 8.8666e-20]],\n",
      "\n",
      "         [[5.3884e-18, 4.3282e-16, 2.2694e-18],\n",
      "          [5.0725e-18, 1.2411e-16, 2.1847e-18],\n",
      "          [1.3999e-18, 4.4066e-19, 3.6426e-19]],\n",
      "\n",
      "         [[5.2036e-23, 6.9898e-24, 1.0852e-20],\n",
      "          [3.8962e-21, 9.3149e-21, 6.0984e-20],\n",
      "          [6.0973e-19, 2.2050e-18, 9.8854e-19]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[6.4828e-16, 2.5688e-16, 3.6727e-16],\n",
      "          [1.4110e-17, 2.5829e-16, 1.8283e-16],\n",
      "          [7.3506e-18, 5.0274e-16, 4.3397e-16]],\n",
      "\n",
      "         [[8.9407e-16, 1.1172e-16, 3.5099e-17],\n",
      "          [8.7083e-15, 2.1119e-15, 3.6173e-15],\n",
      "          [6.1070e-15, 8.1546e-15, 3.9436e-15]],\n",
      "\n",
      "         [[5.8240e-14, 2.4906e-13, 1.1258e-13],\n",
      "          [7.1539e-14, 2.2654e-13, 8.9429e-14],\n",
      "          [5.6188e-14, 2.1521e-13, 7.5840e-14]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3368e-15, 1.6774e-15, 1.0969e-15],\n",
      "          [1.7365e-15, 1.3926e-15, 2.5768e-15],\n",
      "          [3.5194e-15, 4.0043e-16, 1.1003e-15]],\n",
      "\n",
      "         [[1.0266e-15, 2.2833e-15, 1.6164e-16],\n",
      "          [3.4471e-17, 1.6290e-16, 1.8155e-15],\n",
      "          [3.1245e-17, 3.5362e-16, 4.7091e-17]],\n",
      "\n",
      "         [[8.1360e-18, 2.4634e-18, 7.7867e-18],\n",
      "          [3.7706e-18, 1.8867e-17, 5.3058e-19],\n",
      "          [2.4925e-19, 7.6811e-18, 1.1034e-18]]],\n",
      "\n",
      "\n",
      "        [[[5.4453e-13, 1.7432e-12, 4.3919e-14],\n",
      "          [2.1823e-13, 6.5468e-13, 1.7671e-13],\n",
      "          [7.5775e-15, 1.5316e-14, 1.8334e-15]],\n",
      "\n",
      "         [[0.0000e+00, 6.7631e-20, 4.0154e-24],\n",
      "          [9.9581e-20, 2.4270e-20, 2.9414e-22],\n",
      "          [2.3678e-19, 1.0393e-17, 3.5956e-18]],\n",
      "\n",
      "         [[6.7064e-17, 1.1367e-16, 5.6618e-17],\n",
      "          [6.7613e-17, 1.3509e-16, 5.7565e-17],\n",
      "          [3.9202e-18, 1.8057e-17, 6.7622e-18]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.8312e-20, 1.7270e-21, 1.3701e-22],\n",
      "          [6.8430e-22, 5.2409e-20, 3.8815e-20],\n",
      "          [4.8277e-21, 7.0602e-21, 1.1671e-20]],\n",
      "\n",
      "         [[4.0751e-16, 1.6730e-16, 2.9478e-17],\n",
      "          [4.8636e-16, 2.3661e-16, 5.3912e-17],\n",
      "          [2.2996e-16, 2.0210e-16, 7.7656e-17]],\n",
      "\n",
      "         [[2.3361e-16, 2.5840e-16, 3.5360e-16],\n",
      "          [5.5734e-17, 9.9685e-17, 2.7802e-16],\n",
      "          [1.1992e-17, 4.7100e-20, 3.0855e-18]]],\n",
      "\n",
      "\n",
      "        [[[2.3408e-17, 5.2038e-17, 2.4544e-17],\n",
      "          [1.8921e-17, 5.7094e-17, 5.6755e-17],\n",
      "          [1.2802e-17, 7.1285e-17, 3.8578e-16]],\n",
      "\n",
      "         [[6.0016e-19, 2.1441e-19, 1.1198e-19],\n",
      "          [5.8100e-19, 1.4048e-19, 2.7985e-21],\n",
      "          [5.0813e-19, 2.8513e-19, 1.3096e-18]],\n",
      "\n",
      "         [[5.8253e-19, 1.2420e-18, 4.3372e-18],\n",
      "          [1.5411e-19, 3.8734e-18, 4.3857e-18],\n",
      "          [2.0746e-19, 3.1696e-18, 1.7665e-18]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.3686e-18, 1.9647e-18, 1.0807e-18],\n",
      "          [1.0357e-17, 3.6212e-18, 1.3254e-18],\n",
      "          [1.3959e-19, 2.8337e-19, 6.4083e-21]],\n",
      "\n",
      "         [[8.5315e-19, 5.8178e-19, 1.4300e-20],\n",
      "          [7.1469e-19, 1.2701e-19, 1.3584e-20],\n",
      "          [6.0590e-18, 4.1282e-18, 8.0635e-19]],\n",
      "\n",
      "         [[2.5473e-24, 0.0000e+00, 7.0065e-43],\n",
      "          [3.8231e-20, 1.8460e-21, 1.9563e-22],\n",
      "          [7.8440e-20, 1.6665e-19, 1.8785e-19]]]])}, 7: {'step': 18912, 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -4.7035e-34,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -1.3755e-21, -2.0129e-22,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  0.0000e+00,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  6.8025e-06,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  9.7034e-13, -5.6052e-45,\n",
      "        -5.6052e-45, -9.9134e-06, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  6.4196e-35,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -6.2454e-33,  5.6052e-45,\n",
      "        -5.6128e-35,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         3.9281e-30,  2.3412e-05, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6161e-08,\n",
      "        -1.1289e-05,  5.6052e-45, -3.7408e-06,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.7022e-05, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  8.1396e-31,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.3593e-23,  5.6052e-45, -5.0131e-24,  5.6052e-45, -2.4306e-10,\n",
      "        -1.4921e-29,  5.6052e-45,  5.6052e-45, -6.6846e-21,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -2.4364e-05,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  1.4204e-04,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -1.8831e-07,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -4.3134e-09,  5.6052e-45, -1.3913e-09,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -1.2763e-24,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  2.9988e-43, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -1.6954e-14,\n",
      "         5.6052e-45, -3.9909e-42, -4.5484e-09,  5.6052e-45,  5.6052e-45,\n",
      "        -7.4929e-14, -4.5606e-08, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  3.5162e-30,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -1.7752e-19, -5.0753e-19,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -2.5053e-18, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45]), 'exp_avg_sq': tensor([3.1650e-15, 2.2352e-13, 4.8486e-08, 4.1909e-10, 8.2381e-16, 2.7100e-12,\n",
      "        1.6307e-14, 1.0661e-13, 1.0465e-14, 1.8344e-11, 3.9614e-11, 1.8525e-15,\n",
      "        3.8458e-18, 6.4678e-17, 9.7528e-12, 2.9125e-16, 2.7161e-17, 7.2924e-09,\n",
      "        5.1148e-16, 1.4497e-14, 1.4504e-14, 2.4537e-17, 2.5157e-16, 2.3102e-09,\n",
      "        2.1287e-12, 3.9752e-16, 1.1160e-13, 3.1264e-15, 4.9233e-15, 3.1899e-13,\n",
      "        6.1618e-15, 4.9838e-18, 4.1286e-14, 9.1005e-12, 3.5216e-14, 1.3296e-15,\n",
      "        9.6611e-16, 1.9322e-18, 6.4010e-14, 4.4941e-15, 3.9256e-15, 2.6675e-15,\n",
      "        1.5547e-11, 6.8539e-14, 3.6264e-13, 8.5432e-21, 7.0109e-15, 1.1330e-15,\n",
      "        4.4865e-15, 2.7167e-14, 7.8139e-17, 9.0941e-14, 3.0625e-10, 3.5584e-13,\n",
      "        1.8473e-14, 1.1133e-15, 1.2217e-14, 4.2332e-08, 3.9608e-09, 2.0219e-16,\n",
      "        2.0641e-14, 1.3584e-09, 1.7309e-14, 2.0576e-13, 8.6078e-14, 2.6430e-14,\n",
      "        1.0004e-17, 7.5589e-14, 1.3026e-14, 2.1882e-14, 1.1757e-16, 3.6325e-07,\n",
      "        1.4732e-14, 4.2859e-14, 4.7902e-14, 3.1756e-14, 3.0153e-13, 2.5165e-12,\n",
      "        3.0175e-10, 3.8786e-12, 6.7962e-14, 1.0403e-07, 1.4131e-12, 2.4736e-17,\n",
      "        8.4275e-16, 5.6877e-13, 1.6781e-16, 6.6261e-16, 1.5110e-12, 2.6244e-14,\n",
      "        7.4432e-17, 1.6602e-16, 2.9974e-15, 4.4927e-12, 2.6889e-14, 1.1182e-13,\n",
      "        6.4390e-13, 2.3682e-12, 2.7999e-09, 1.1594e-07, 6.7290e-12, 6.4343e-11,\n",
      "        6.5205e-14, 1.5319e-14, 4.5801e-14, 5.4190e-13, 1.6021e-10, 2.8872e-14,\n",
      "        5.9028e-16, 1.4582e-10, 4.7695e-17, 1.7710e-12, 4.5382e-19, 2.2995e-16,\n",
      "        1.4985e-16, 3.3354e-11, 6.4537e-06, 2.2646e-17, 1.4680e-10, 1.1382e-14,\n",
      "        3.8513e-12, 7.3798e-18, 6.5191e-15, 1.1853e-14, 9.1634e-09, 3.4416e-07,\n",
      "        4.1761e-17, 1.5339e-07, 1.4703e-16, 2.0942e-15, 9.5530e-13, 2.0649e-13,\n",
      "        8.7608e-17, 1.6924e-15, 6.8789e-19, 1.9047e-07, 1.1427e-10, 1.2842e-13,\n",
      "        3.4665e-11, 5.1125e-17, 5.9282e-14, 2.5020e-11, 6.3253e-14, 2.5777e-15,\n",
      "        7.7020e-13, 1.3561e-10, 1.3936e-11, 7.4762e-07, 5.5795e-17, 9.1671e-10,\n",
      "        2.6428e-12, 3.0078e-14, 5.8406e-20, 1.0307e-13, 3.2743e-16, 1.5236e-16,\n",
      "        1.8555e-12, 1.8869e-07, 2.8762e-13, 1.8884e-14, 1.1413e-12, 2.3231e-15,\n",
      "        4.1382e-12, 1.9119e-06, 1.8339e-17, 7.1213e-16, 7.1642e-16, 2.1631e-13,\n",
      "        7.8082e-14, 1.3776e-13, 1.8964e-14, 7.0915e-14, 3.0774e-13, 2.3128e-11,\n",
      "        3.0183e-07, 1.1405e-11, 1.0976e-15, 3.3408e-12, 2.5037e-12, 6.1565e-15,\n",
      "        7.7048e-16, 8.1346e-12, 3.6106e-06, 3.2550e-16, 3.0574e-07, 2.7179e-09,\n",
      "        1.7501e-15, 4.1353e-15, 7.5045e-17, 1.3437e-13, 3.1127e-12, 2.5847e-10,\n",
      "        4.0775e-17, 3.5110e-12, 6.6138e-13, 7.0523e-13, 2.5035e-12, 2.1395e-09,\n",
      "        9.5985e-13, 7.7553e-14, 3.7678e-15, 4.7711e-16, 1.5422e-14, 1.6196e-14,\n",
      "        4.9757e-10, 6.3912e-09, 8.5865e-13, 1.3181e-08, 2.0851e-19, 1.2127e-12,\n",
      "        2.5420e-09, 1.4729e-09, 5.4080e-14, 5.5175e-10, 8.7970e-14, 2.0429e-12,\n",
      "        1.6008e-10, 1.9866e-10, 2.6993e-12, 3.1853e-14, 1.5974e-15, 1.6545e-10,\n",
      "        2.1929e-11, 3.7101e-14, 8.7197e-13, 1.1888e-11, 4.2355e-14, 2.7800e-14,\n",
      "        5.8559e-12, 1.5788e-14, 1.7779e-15, 7.3286e-16, 1.8637e-15, 4.0872e-15,\n",
      "        7.3862e-20, 5.9305e-15, 1.9550e-09, 1.4214e-14, 6.0064e-13, 7.9352e-12,\n",
      "        5.1441e-14, 2.3341e-11, 3.5672e-13, 5.7128e-15, 2.7059e-14, 3.4303e-15,\n",
      "        3.1947e-16, 2.7950e-15, 1.5387e-13, 6.7359e-15, 4.4825e-16, 2.6637e-18,\n",
      "        1.6208e-13, 4.9432e-14, 9.6776e-13, 5.7922e-12])}, 8: {'step': 18912, 'exp_avg': tensor([[[[ 5.6052e-45, -5.6052e-45,  0.0000e+00],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  0.0000e+00, -5.6052e-45],\n",
      "          [ 5.6052e-45,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.6052e-45,  5.6052e-45,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  0.0000e+00, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 0.0000e+00, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 0.0000e+00, -5.6052e-45, -5.6052e-45],\n",
      "          [ 0.0000e+00,  0.0000e+00, -5.6052e-45],\n",
      "          [ 0.0000e+00, -5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 0.0000e+00,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  0.0000e+00],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 0.0000e+00,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  0.0000e+00,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 0.0000e+00, -5.6052e-45,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45]]]]), 'exp_avg_sq': tensor([[[[5.0672e-20, 2.1898e-24, 0.0000e+00],\n",
      "          [1.4142e-18, 3.1757e-19, 1.4833e-21],\n",
      "          [4.3322e-19, 8.2622e-20, 1.0002e-18]],\n",
      "\n",
      "         [[2.2290e-17, 6.7691e-16, 2.2795e-15],\n",
      "          [3.4432e-17, 5.1393e-16, 7.1967e-17],\n",
      "          [4.6900e-16, 1.8058e-16, 4.3886e-17]],\n",
      "\n",
      "         [[1.6155e-19, 0.0000e+00, 2.1957e-20],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 8.6011e-19, 0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.5933e-17, 5.2349e-19, 2.8349e-18],\n",
      "          [6.7531e-17, 0.0000e+00, 4.5908e-17],\n",
      "          [4.9866e-16, 4.4975e-17, 9.8061e-17]],\n",
      "\n",
      "         [[5.3501e-19, 1.1451e-18, 1.2408e-20],\n",
      "          [4.0079e-18, 6.7088e-18, 4.3082e-18],\n",
      "          [4.6861e-18, 1.5742e-17, 1.3195e-17]],\n",
      "\n",
      "         [[0.0000e+00, 2.0721e-20, 1.1682e-19],\n",
      "          [5.0321e-20, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[6.6781e-17, 1.2005e-15, 1.1450e-14],\n",
      "          [2.1833e-20, 4.5342e-18, 2.2668e-16],\n",
      "          [3.7896e-19, 1.3670e-18, 1.0037e-17]],\n",
      "\n",
      "         [[1.1122e-14, 3.6313e-14, 8.4687e-14],\n",
      "          [1.1789e-14, 2.4931e-14, 4.7448e-14],\n",
      "          [5.7401e-15, 8.0206e-15, 1.4004e-14]],\n",
      "\n",
      "         [[3.7745e-08, 2.3319e-07, 1.7631e-07],\n",
      "          [1.9944e-07, 9.1773e-07, 6.4285e-07],\n",
      "          [2.1845e-07, 1.1159e-06, 5.5104e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.3543e-15, 7.3829e-19, 5.2269e-18],\n",
      "          [3.4895e-15, 1.2370e-18, 1.3686e-17],\n",
      "          [4.1864e-15, 1.9319e-18, 1.6043e-17]],\n",
      "\n",
      "         [[8.1486e-20, 3.6439e-17, 2.2975e-17],\n",
      "          [3.5046e-16, 2.3726e-16, 6.7209e-17],\n",
      "          [7.8674e-16, 4.5340e-16, 1.4335e-16]],\n",
      "\n",
      "         [[0.0000e+00, 4.2708e-21, 2.5309e-17],\n",
      "          [0.0000e+00, 0.0000e+00, 5.6963e-16],\n",
      "          [0.0000e+00, 4.8715e-21, 2.8585e-21]]],\n",
      "\n",
      "\n",
      "        [[[7.1533e-16, 2.7416e-15, 7.2060e-16],\n",
      "          [5.6136e-15, 1.1064e-14, 3.1826e-15],\n",
      "          [1.2763e-15, 2.2104e-15, 3.4039e-16]],\n",
      "\n",
      "         [[1.8822e-18, 1.2322e-16, 2.5844e-17],\n",
      "          [4.8125e-17, 9.0092e-15, 1.7272e-14],\n",
      "          [4.5303e-15, 1.1528e-14, 1.9647e-14]],\n",
      "\n",
      "         [[7.3176e-32, 8.1055e-31, 2.9911e-22],\n",
      "          [2.3027e-15, 2.8101e-24, 6.2923e-22],\n",
      "          [2.2915e-16, 6.7124e-17, 2.3838e-16]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3592e-19, 2.4759e-17, 1.2344e-16],\n",
      "          [2.4821e-23, 2.7663e-18, 4.2926e-17],\n",
      "          [0.0000e+00, 4.4462e-20, 3.1498e-17]],\n",
      "\n",
      "         [[6.6449e-19, 6.6465e-19, 2.6811e-22],\n",
      "          [7.9802e-18, 1.2696e-17, 1.2893e-17],\n",
      "          [7.8020e-20, 6.8024e-18, 7.7320e-20]],\n",
      "\n",
      "         [[3.9588e-21, 6.3499e-20, 2.1328e-22],\n",
      "          [1.5334e-24, 3.0748e-19, 6.1385e-25],\n",
      "          [2.4948e-20, 3.5864e-20, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[4.6988e-17, 4.2051e-18, 3.6059e-17],\n",
      "          [2.0018e-17, 3.8193e-19, 2.3697e-18],\n",
      "          [2.3360e-17, 8.9197e-19, 1.0558e-17]],\n",
      "\n",
      "         [[1.2314e-13, 1.3480e-13, 8.4786e-14],\n",
      "          [3.6031e-13, 3.1668e-13, 1.6493e-13],\n",
      "          [1.2928e-12, 1.0279e-12, 6.1687e-13]],\n",
      "\n",
      "         [[1.2410e-09, 2.7335e-10, 1.4205e-09],\n",
      "          [9.7675e-09, 2.3539e-09, 1.7584e-08],\n",
      "          [1.5838e-10, 1.5725e-09, 8.5802e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5931e-17, 3.4705e-18, 4.9117e-17],\n",
      "          [1.7853e-18, 3.8919e-19, 1.6421e-17],\n",
      "          [5.9677e-18, 2.0026e-18, 7.6858e-20]],\n",
      "\n",
      "         [[1.6101e-19, 1.9442e-18, 2.4958e-27],\n",
      "          [5.5539e-18, 2.8004e-15, 2.8584e-17],\n",
      "          [2.6166e-17, 7.5328e-16, 4.4924e-15]],\n",
      "\n",
      "         [[2.4770e-25, 2.1303e-20, 4.4698e-18],\n",
      "          [2.5661e-22, 1.5388e-17, 2.2718e-17],\n",
      "          [4.7332e-17, 1.8061e-16, 1.5760e-16]]],\n",
      "\n",
      "\n",
      "        [[[8.3157e-17, 8.4762e-15, 3.7472e-14],\n",
      "          [1.2354e-19, 1.5601e-16, 2.0264e-16],\n",
      "          [1.2640e-18, 3.4297e-19, 1.8486e-19]],\n",
      "\n",
      "         [[6.4118e-16, 2.6022e-14, 0.0000e+00],\n",
      "          [2.9572e-17, 1.4299e-14, 2.6087e-25],\n",
      "          [3.8149e-35, 4.4120e-19, 4.0514e-22]],\n",
      "\n",
      "         [[6.6676e-09, 3.6428e-09, 8.1780e-10],\n",
      "          [1.5739e-08, 8.1239e-10, 5.3825e-09],\n",
      "          [8.3488e-10, 9.0814e-10, 3.0162e-11]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.8139e-23, 5.3620e-20, 1.5274e-19],\n",
      "          [0.0000e+00, 2.1073e-23, 2.4370e-18],\n",
      "          [1.4485e-19, 5.4014e-19, 4.5792e-19]],\n",
      "\n",
      "         [[2.3773e-19, 0.0000e+00, 7.5882e-22],\n",
      "          [7.2946e-19, 1.0582e-19, 2.8644e-11],\n",
      "          [0.0000e+00, 1.2524e-19, 0.0000e+00]],\n",
      "\n",
      "         [[1.2114e-20, 3.0880e-20, 6.5898e-16],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.2310e-18]]],\n",
      "\n",
      "\n",
      "        [[[1.1266e-17, 3.3968e-18, 6.6747e-17],\n",
      "          [1.9414e-18, 3.1457e-18, 1.4433e-18],\n",
      "          [2.8955e-17, 2.2190e-18, 2.8894e-17]],\n",
      "\n",
      "         [[9.4481e-14, 9.3262e-14, 1.3036e-13],\n",
      "          [1.5854e-13, 2.1465e-13, 1.5577e-13],\n",
      "          [3.4372e-14, 6.3650e-14, 4.7237e-14]],\n",
      "\n",
      "         [[1.2878e-21, 6.1209e-25, 3.7836e-24],\n",
      "          [1.2260e-22, 2.0258e-24, 5.8188e-23],\n",
      "          [5.0852e-25, 5.4874e-24, 6.0115e-22]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.9499e-13, 4.1644e-13, 4.7147e-13],\n",
      "          [5.1672e-13, 8.9530e-13, 1.0425e-12],\n",
      "          [3.0196e-13, 5.2522e-13, 5.6743e-13]],\n",
      "\n",
      "         [[5.7004e-25, 3.1085e-18, 1.4200e-11],\n",
      "          [7.6738e-16, 6.7218e-14, 1.6650e-12],\n",
      "          [3.5989e-16, 1.6614e-14, 1.9206e-13]],\n",
      "\n",
      "         [[3.0949e-18, 5.6839e-17, 2.4706e-18],\n",
      "          [1.4120e-21, 1.1668e-17, 5.3098e-18],\n",
      "          [9.5100e-18, 8.9548e-17, 6.4049e-19]]]])}, 9: {'step': 18912, 'exp_avg': tensor([ 5.6052e-45, -3.0373e-06,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -1.7567e-17,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -1.9571e-33,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -4.7443e-08, -3.0746e-05,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -4.3137e-05, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -2.0260e-17,  5.6052e-45,  1.1617e-42,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -6.6239e-26,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -6.6782e-35,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -2.8348e-25,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -1.0294e-39,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -1.0312e-11,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  1.8777e-43,\n",
      "        -9.9556e-06, -5.6052e-45, -5.6052e-45, -5.6052e-45, -1.4422e-18,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -2.8105e-06, -2.7325e-10,\n",
      "        -5.6052e-45, -1.4214e-05,  5.6612e-43,  4.6803e-43, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -4.2039e-45,  5.6052e-45,\n",
      "        -4.8416e-13, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         6.2105e-19,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -2.4683e-24, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         2.1907e-18,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -7.0038e-08,  5.6052e-45, -5.8697e-04,\n",
      "        -5.6052e-45, -1.1397e-41, -1.7138e-07,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -4.6623e-05,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.4062e-42,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         2.8857e-24, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  1.0318e-32,  5.6052e-45, -4.2417e-29,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  2.4467e-42, -2.0197e-32,\n",
      "        -5.6052e-45,  5.6052e-45, -1.2085e-12, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -4.9382e-42,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  1.1248e-16,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -7.5276e-41, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -6.2268e-16,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -9.0846e-24,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  3.6522e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.9142e-28,  4.0594e-23, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -1.1655e-17,\n",
      "        -1.5486e-40]), 'exp_avg_sq': tensor([2.3496e-16, 3.0073e-07, 1.5849e-12, 3.3783e-13, 2.7854e-15, 3.0540e-17,\n",
      "        2.1842e-11, 1.5961e-15, 5.9559e-10, 4.6967e-10, 2.0181e-10, 7.4404e-12,\n",
      "        1.7739e-16, 1.0600e-14, 4.8147e-15, 2.0223e-09, 4.5567e-12, 5.7795e-15,\n",
      "        1.1271e-07, 1.1080e-13, 1.7097e-12, 1.8408e-13, 3.8865e-11, 1.7552e-07,\n",
      "        4.3360e-06, 5.4347e-12, 2.6585e-10, 4.3681e-15, 1.8868e-14, 7.1491e-14,\n",
      "        5.5195e-06, 1.7124e-10, 3.5724e-11, 9.8725e-13, 2.8603e-15, 1.3100e-13,\n",
      "        1.1266e-12, 2.2217e-07, 1.4929e-13, 1.6311e-08, 1.5690e-06, 1.2940e-12,\n",
      "        5.6543e-14, 2.7816e-13, 4.1465e-13, 7.2368e-14, 3.4863e-14, 7.9757e-13,\n",
      "        1.1218e-10, 6.5949e-16, 9.7231e-14, 2.9443e-12, 3.1389e-13, 8.0533e-08,\n",
      "        5.6317e-11, 1.3007e-12, 3.4700e-14, 9.6527e-08, 4.9967e-14, 1.8869e-22,\n",
      "        1.6336e-12, 3.0894e-15, 2.7569e-08, 6.7068e-13, 1.0286e-09, 2.3911e-14,\n",
      "        1.2338e-20, 3.0918e-13, 3.9719e-13, 1.8075e-17, 7.5318e-19, 2.5204e-14,\n",
      "        2.2413e-10, 7.8827e-11, 5.4900e-07, 1.9481e-15, 1.0871e-07, 9.1388e-11,\n",
      "        5.8191e-13, 6.1660e-11, 8.0523e-07, 1.0492e-13, 1.4312e-10, 5.2264e-11,\n",
      "        8.9477e-08, 9.0646e-15, 2.0835e-11, 4.5244e-12, 1.9288e-07, 5.7108e-09,\n",
      "        2.0449e-08, 3.1773e-06, 5.8909e-10, 6.3983e-07, 3.0841e-14, 2.4031e-12,\n",
      "        1.1684e-14, 3.6094e-12, 7.4327e-14, 9.3780e-14, 1.4544e-07, 2.9977e-15,\n",
      "        8.0638e-15, 1.0612e-13, 1.5980e-19, 4.9950e-13, 3.2655e-12, 2.4869e-13,\n",
      "        1.3501e-11, 4.0990e-22, 1.8411e-11, 1.0439e-13, 4.3850e-11, 1.2973e-12,\n",
      "        3.4182e-13, 1.3092e-13, 8.9161e-14, 3.0048e-08, 1.5173e-13, 2.1315e-17,\n",
      "        1.6634e-15, 1.4055e-08, 6.3305e-11, 4.7864e-16, 2.5815e-19, 5.4919e-10,\n",
      "        7.7764e-14, 5.6887e-15, 1.5829e-15, 1.7165e-12, 2.6352e-15, 9.3912e-14,\n",
      "        5.9587e-13, 2.5394e-16, 2.1875e-14, 4.4111e-10, 4.7724e-07, 5.6021e-07,\n",
      "        5.3094e-10, 6.8825e-06, 1.1029e-08, 1.2910e-12, 2.3888e-07, 2.1175e-12,\n",
      "        1.7620e-10, 1.0566e-12, 2.9974e-14, 3.1774e-11, 6.8780e-17, 1.5803e-12,\n",
      "        9.0400e-07, 6.9697e-13, 4.1423e-13, 1.6461e-15, 3.5429e-12, 5.2571e-18,\n",
      "        7.8868e-08, 8.9937e-17, 7.4444e-12, 1.4315e-11, 6.0720e-12, 2.8133e-12,\n",
      "        2.4609e-12, 3.1184e-09, 2.5022e-10, 8.0582e-11, 7.3102e-11, 1.2545e-14,\n",
      "        3.6207e-10, 1.1248e-13, 1.0569e-08, 5.8557e-15, 4.7441e-13, 9.8580e-16,\n",
      "        1.5025e-14, 1.9166e-10, 1.0327e-08, 8.4632e-15, 1.5382e-08, 4.6272e-09,\n",
      "        7.8289e-19, 2.4237e-13, 4.2696e-13, 3.7939e-08, 1.2119e-14, 2.0359e-11,\n",
      "        1.9197e-15, 1.0455e-06, 3.6422e-14, 1.8315e-13, 1.1948e-17, 2.2559e-09,\n",
      "        1.0113e-07, 2.6620e-16, 1.1147e-16, 4.1246e-11, 1.8265e-10, 4.4957e-15,\n",
      "        1.1281e-11, 2.7795e-12, 7.5628e-11, 6.0180e-13, 1.0819e-10, 1.2002e-11,\n",
      "        3.1993e-18, 4.9038e-16, 4.5086e-14, 1.3629e-09, 3.2956e-15, 1.3262e-12,\n",
      "        2.7625e-10, 1.6301e-10, 1.6083e-12, 3.8689e-08, 5.5172e-14, 1.3331e-11,\n",
      "        1.1474e-12, 9.3542e-15, 5.3180e-14, 2.9010e-09, 3.2008e-14, 1.2207e-14,\n",
      "        2.6340e-16, 2.1219e-12, 3.7320e-09, 4.2542e-14, 4.4948e-14, 3.4542e-09,\n",
      "        1.0902e-09, 5.3201e-12, 4.8744e-14, 2.2069e-07, 2.8369e-17, 5.0126e-12,\n",
      "        1.6623e-13, 1.4259e-10, 6.8796e-14, 6.5133e-15, 6.5005e-18, 2.6868e-09,\n",
      "        7.4650e-14, 4.0568e-06, 1.5379e-11, 7.5292e-15, 2.7671e-16, 6.3544e-09,\n",
      "        1.1149e-13, 6.5101e-13, 2.2430e-08, 3.1917e-13, 7.1465e-13, 4.6296e-14,\n",
      "        2.7240e-10, 1.0032e-09, 7.3114e-10, 5.2731e-13])}, 10: {'step': 18912, 'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -5.6052e-45,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.4605e-39,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1577e-15, 3.9998e-15,\n",
      "         4.4098e-15],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0902e-19, 5.2846e-20,\n",
      "         9.8067e-19],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3891e-17, 2.0939e-17,\n",
      "         1.1944e-17],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2386e-16, 1.4230e-16,\n",
      "         1.9332e-16],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6496e-16, 2.3649e-16,\n",
      "         1.6276e-16]])}, 11: {'step': 18912, 'exp_avg': tensor([-8.6143e-07, -5.3798e-08,  7.2277e-07,  ...,  9.0010e-07,\n",
      "         3.5581e-08, -5.7204e-07]), 'exp_avg_sq': tensor([9.0646e-11, 9.1255e-11, 3.7818e-11,  ..., 3.1832e-10, 9.3455e-12,\n",
      "        3.9556e-11])}, 12: {'step': 7092, 'exp_avg': tensor([[-5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        ...,\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[5.5593e-13, 5.2668e-11, 3.3830e-12,  ..., 1.5901e-12, 1.2850e-12,\n",
      "         9.6305e-13],\n",
      "        [3.6168e-13, 5.5068e-11, 1.5990e-11,  ..., 7.3179e-12, 6.6322e-11,\n",
      "         2.1667e-11],\n",
      "        [6.3985e-12, 4.8798e-10, 5.8482e-12,  ..., 1.9716e-11, 3.1717e-11,\n",
      "         1.7391e-11],\n",
      "        ...,\n",
      "        [1.9947e-11, 1.2179e-09, 6.6754e-13,  ..., 4.0100e-12, 8.1150e-11,\n",
      "         1.6240e-11],\n",
      "        [1.0632e-11, 2.7031e-10, 1.2568e-11,  ..., 9.7917e-12, 5.3217e-11,\n",
      "         1.4614e-11],\n",
      "        [5.8370e-13, 9.3626e-12, 3.9270e-14,  ..., 1.5265e-14, 9.7359e-13,\n",
      "         4.2926e-14]])}, 13: {'step': 7092, 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 2.5597e-20,  ..., 5.6052e-45, 4.1331e-32,\n",
      "        5.6052e-45]), 'exp_avg_sq': tensor([2.2800e-11, 2.5366e-10, 2.0995e-10,  ..., 1.7939e-10, 2.5642e-10,\n",
      "        1.6658e-12])}, 14: {'step': 7092, 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45,  2.7929e-20,  ..., -5.6052e-45,\n",
      "         -2.3607e-31,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -2.7929e-20,  ...,  5.6052e-45,\n",
      "          2.3607e-31, -5.6052e-45]]), 'exp_avg_sq': tensor([[1.4080e-06, 1.7004e-06, 7.8220e-06,  ..., 6.1529e-09, 4.3786e-08,\n",
      "         1.0185e-07],\n",
      "        [1.4080e-06, 1.7004e-06, 7.8220e-06,  ..., 6.1529e-09, 4.3786e-08,\n",
      "         1.0185e-07]])}, 15: {'step': 7092, 'exp_avg': tensor([-0.0029,  0.0029]), 'exp_avg_sq': tensor([0.0007, 0.0007])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in alexnet_loaded.state_dict():\n",
    "    print(param_tensor, \"\\t\", alexnet_loaded.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer_loaded.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer_loaded.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize parameters for second phase of training (optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 more epochs...\n"
     ]
    }
   ],
   "source": [
    "# learning parameters\n",
    "batch_size = 64\n",
    "new_epochs = 1\n",
    "# lr = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# train for more epochs\n",
    "epochs = new_epochs\n",
    "print(f\"Train for {epochs} more epochs...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 000, Training: Loss: 0.0363, Accuracy: 98.8539%, \n",
      "\t\tValidation : Loss : 9.0862, Accuracy: 54.9504%, \n",
      " Time (train+val): 3955.4353s\n"
     ]
    }
   ],
   "source": [
    "history_loaded = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "#     print(\"Epoch: {}/{}\".format(epoch, epochs))\n",
    "     \n",
    "    # Set to training mode\n",
    "    alexnet_loaded.train()\n",
    "     \n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    " \n",
    "    # Iterate through all batches of training data\n",
    "    for i, (inputs, labels) in enumerate(train_data):\n",
    " \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "         \n",
    "        # Clean existing gradients\n",
    "        optimizer_loaded.zero_grad()\n",
    "         \n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        outputs = alexnet_loaded(inputs)\n",
    "        \n",
    "#         print(\"predictions\")\n",
    "#         print(outputs)\n",
    "         \n",
    "        # Compute loss\n",
    "        loss = criterion_loaded(outputs, labels)\n",
    "         \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "         \n",
    "        # Update the parameters\n",
    "        optimizer_loaded.step()\n",
    "         \n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "         \n",
    "        # Compute the accuracy\n",
    "        ret, predictions = torch.max(outputs.data, 1)\n",
    "#         print(\"ret\")\n",
    "#         print(ret)\n",
    "#         print(\"predictions\")\n",
    "#         print(predictions)\n",
    "\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "#         print(\"correct counts\")\n",
    "#         print(correct_counts)\n",
    "         \n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "#         print(\"acc\")\n",
    "#         print(acc)\n",
    "         \n",
    "        # Compute total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "         \n",
    "#         print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "        \n",
    "\n",
    "    # Validation is carried out in each epoch immediately after the training loop\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Set to evaluation mode\n",
    "        alexnet_loaded.eval()\n",
    "\n",
    "        # Validation loop\n",
    "        # Iterate through all batches of validation data\n",
    "        for j, (inputs, labels) in enumerate(valid_data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = alexnet_loaded(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion_loaded(outputs, labels)\n",
    "\n",
    "            # Compute the total loss for the batch and add it to valid_loss\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Compute total accuracy in the whole batch and add to valid_acc\n",
    "            valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "\n",
    "#             print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "    # Find average training loss and training accuracy\n",
    "    avg_train_loss = train_loss/train_data_size\n",
    "    avg_train_acc = train_acc/float(train_data_size)\n",
    "\n",
    "    # Find average training loss and training accuracy\n",
    "    avg_valid_loss = valid_loss/valid_data_size\n",
    "    avg_valid_acc = valid_acc/float(valid_data_size)\n",
    "\n",
    "    history_loaded.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "    epoch_end = time.time()\n",
    "\n",
    "    print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, \\n Time (train+val): {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model based on test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.5409013152359853\n",
      "precision = 0.41994902687673774\n",
      "recall = 0.5328139927978246\n",
      "f1 = 0.4696964788960513\n",
      "Test : Loss : 9.0055, Accuracy: 54.0901%, \n",
      " Time : 290.7825s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "test_start = time.time()\n",
    "\n",
    "# Loss and Accuracy within the epoch\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "\n",
    "# Initialize an empty tensor. This will store all the predictions and will be used for metrics.\n",
    "tot_predictions = torch.Tensor()\n",
    "# Initialize an empty tensor. This will store all the ground truth labels and will be used for metrics.\n",
    "tot_labels = torch.Tensor()\n",
    "\n",
    "# Validation is carried out in each epoch immediately after the training loop\n",
    "# Validation - No gradient tracking needed\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Set to evaluation mode\n",
    "    alexnet_loaded.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    # Iterate through all batches of validation data\n",
    "    for j, (inputs, labels) in enumerate(test_data):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Add values to ground truth\n",
    "        tot_labels = torch.cat((tot_labels, labels))\n",
    "\n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        outputs = alexnet_loaded(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion_loaded(outputs, labels)\n",
    "\n",
    "        # Compute the total loss for the batch and add it to valid_loss\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        ret, predictions = torch.max(outputs.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "        tot_predictions = torch.cat((tot_predictions, predictions))\n",
    "\n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "        # Compute total accuracy in the whole batch and add to valid_acc\n",
    "        test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "#             print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "\n",
    "\n",
    "# Find average testing loss and accuracy\n",
    "avg_test_loss = test_loss/test_data_size\n",
    "avg_test_acc = test_acc/float(test_data_size)\n",
    "\n",
    "accuracy = accuracy_score(tot_labels.to(device), tot_predictions.to(device))\n",
    "\n",
    "# The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "precision = precision_score(tot_labels.to(device), tot_predictions.to(device), average='binary')\n",
    "\n",
    "# The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "recall = recall_score(tot_labels.to(device), tot_predictions.to(device), pos_label=1, average='binary')\n",
    "\n",
    "# The F1 score can be interpreted as a weighted average of the precision and recall\n",
    "f1 = f1_score(tot_labels.to(device), tot_predictions.to(device), average='binary')\n",
    "\n",
    "# history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "test_end = time.time()\n",
    "print(f\"accuracy = {accuracy}\")\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "print(f\"f1 = {f1}\")\n",
    "print(\"Test : Loss : {:.4f}, Accuracy: {:.4f}%, \\n Time : {:.4f}s\".format(avg_test_loss, avg_test_acc*100, test_end-test_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_test = []\n",
    "\n",
    "alexnet.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_data:\n",
    "#         X_batch = X_batch.to(device)\n",
    "        y_test_pred = alexnet(X_batch[0])\n",
    "#         y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        labels = X_batch[1]\n",
    "        y_test.append(labels) \n",
    "#         print(type(X_batch[0]))\n",
    "#         break\n",
    "        \n",
    "        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "y_test = [a.squeeze().tolist() for a in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
